#!/bin/bash
#Sébastien Clément
#Created 5/2/2016

version="20230330"

#-----------------------------------------------------------------------------------------------------------------------------------------------------------
#General description
#-----------------------------------------------------------------------------------------------------------------------------------------------------------
#For .dat and .sum files from Quintek densitometry only
#	Script to calculate the transition from early to late wood based on the the mid-range or median density method
#	..using .dat and .sum files generated by densitometry
#	Ring number: obtained from .SUM files. Ring number from .DAT files is simply IGNORED.
#	Transition: calculated by the script. Transition (E, L or N) from the .DAT file is IGNORED.
# 	The *_corr_reads.txt files can be used to import data into TreeSource's x_ray_dens_msmts_per_read.
#
#Note: reads are made from bark to pith, hence the position 0.000 is the first read of the sample at bark side, and is not related to pith centre in any way.
#	Hence, ring start position is always greater than end position.
#	That is why this script also adds a position relative to the first read encountered at pith side, taken from the corrected rings stats file (*_corr_ring_stats.txt).

#-----------------------------------------------------------------------------------------------------------------------------------------------------------
#USAGE:
#-----------------------------------------------------------------------------------------------------------------------------------------------------------
#	Create a folder for all infiles
#	Put both the .sum and .dat files in there
#	Launch the script with:
#		bash script_recalc_Quintek_densitometry_files_from_dat_sumXXXXXXXX.txt [infiles_folder] [sample_name_eq_list]
#
#		WHERE:  
#			[infiles_folder]: contains raw .dat and .sum files
#			[sample_name_eq_list]:	Equivalency table between original sample name and germplasm_id + data_source_id + growth year + harvested in growing season
#			


#-----------------------------------------------------------------------------------------------------------------------------------------------------------
#What the script does
#-----------------------------------------------------------------------------------------------------------------------------------------------------------
#Generally:
#	- Adds line numbering to .dat files, increasing from pith to bark.
#	- Uses .sum file (more reliable ring demarcations) to extract proper lines from .dat files.
#		Note that the .sum files keep only valid ring data from .dat files. Thus, there is often large chunks of reads that are left out from .dat files. 
#			Example: A284 sample (2016): 196 and 52 lines of data excluded from .sum file at pith and bark ends, respectively. 
#			Also, this is why in the corrected reads file, line numbering never starts at 1.
#	- Calculates the transition from early to latewood based on the selected method (mid-range or median). IGNORES the early/latewood values already in .sum and .dat files.
#	- Calculates a wealth of other stats (ring/ew/lw: start/end pos from bark/pith, number of read, width, average/min/max/mid-range/median density. ew/lw: % of ring width.
#
#Specifically:
#
#	For each .dat file:
#		cleans it						---> reads_tmp.txt
#		performs several checks:
#			if positions are replicated
#			if positions are not sorted
#			if file is empty
#			.etc.
#		add line numbers (pith to bark). NOTE: based on all raw .dat lines. Since some lines will be excluded from the final file, reads might not be consecutive.
#		cleans the corresponding .sum file 			---> rings_tmp.txt
#		checks
#			if file is empty
#			if positions are ordered
#			etc.
#	From each line (ring) of the cleaned .sum file, gets:
#		ring end pos	(since read from bark to pith, this will have a lower value than ring start pos)
#		ring start pos (will be calculated as: previous ring end pos - step size (e.g. 0.04), to avoid having current ring start pos = previous ring end pos.
#		year
#		ring no (pith to bark)
#		sample name
#	Extracts all lines from cleaned .dat file within these positions (ring end pos and ring start pos, inclusive)
#	Calculates:
#		number of reads, min/max/median/average density, late wood start pos. (transition), early wood reads number, ring width
#	DOESN'T calculate ew/lw transition in the following cases:
#		- transition not found (median density method)
#		- early wood proportion too low (< min_ew_proportion)
#		- not enough reads in the ring (< min_reads_for_transition)
#		- if there are no reads at all for that ring in the corresponding .dat file
#	Calculates transition, but sends a warning if there are low values (< min_allowed_density).
#	Adds the calculated stats for that ring to a new, corrected ring stats file.
#	Adds to *_corr_reads.txt and *_corr_ring_stats.txt the positions relative to the first read pithwise (pos=0.00), which is ring 1's start position from file _corr_ring_stats.txt
#		This will be essential to insert into TreeSource, which stores data on a pith-to-bark basis.
#	Keeps only columns required for x_ray_dens_msmts_per_read, replaces sample names with germplasm_id's and adds data_source_id's, both from a provided equivalency table.
#	Reorders the file by germplasm_id and position.


#-----------------------------------------------------------------------------------------------------------------------------------------------------------
#Examples of input files
#-----------------------------------------------------------------------------------------------------------------------------------------------------------
#NOTES:  
#	field separators are not constant from file to file, especially in .sum files, which are often separated by several spaces, and sometimes by tabulations.
#	Worse, sometimes the sample names in .sum files contain spaces, and no easy way to discriminate between field separator spaces and sample name space.
#	This script ASSUMES THAT THE FIELDS WILL ALWAYS BE THE SAME IN ALL .dat OR .sum FILES.
#	header markers are REQUIRED in input .dat ([SAMPLE DATA]) and .sum  (Study) files

#[.dat file]
	#004.dat
		#[SAMPLE PARAMETERS]
		#Time/Date of Scan,          14-Jan-2015   11:26:30
		#	(...)
		#Number of data points,         2875
		#[SAMPLE DATA]
		#  0.000,   0.00, -1,N
		#  0.040,   0.00, -1,N
		#  0.080,   0.00, -1,N
		#  0.120,   0.00, -1,N
		#  0.160,   0.00, -1,N
		#  0.200,   0.00, -1,N
		#  0.240,   4.09, -1,N
		#  0.280,   0.00, -1,N
		#  0.320,   0.00, -1,N

		#WHERE:
		#	Column #1: read position (mm) from bark 	(ESSENTIAL)
		#	Column #2: Wood density				(ESSENTIAL)
		#	Column #3: Ring number, from pith to bark 						===> WILL BE IGNORED, the ring number from the .SUM file will be used. Used only to detect any missing ring number (E4).
		#	Column #4: wood type: E = early wood, L = late wood, N = undetermined. 	===> WILL BE IGNORED, the transition will be calculated by the current script.

		#NOTE: all 4 original columns are kept, but only the first 2 (position, density) will be used.

#[.sum file]
	#002.sum
		#                                                    						Late
		#                                                     						Wood	Ring    	Late    	Early   	Late    	Ring
		#                        			Ring        	End		Start   	Width	Width   	Wood    	Wood    	Wood   	Average
		#Study ID     	Sample ID  No.  	Year  mm		mm		mm		mm    	Percent 	Density 	Density 	Density
		# E560A3_2018        	14  	34  	2018 	19.98		20.94    	0.40    	0.96   	41.67		349.94  	498.54  	411.86
		# E560A3_2018           	14 	33  	2017	20.94	22.86    	0.76    	1.92   	39.58  	299.87  	620.00  	426.59
		# E560A3_2018           	14  	32  	2016	22.86   	24.78    	0.64    	1.92   	33.33  	344.51  	612.24  	433.75
		# E560A3_2018           	14  	31  	2015	24.78   	27.14    	0.96    	2.36   	40.68  	354.62  	602.99  	455.65
		# E560A3_2018           	14  	30  	2014	27.14   	29.32    	0.88    	2.18   	40.37  	361.82  	627.49  	469.06
		# E560A3_2018           	14  	29  	2013	29.32   	31.28    	0.76    	1.96   	38.78  	354.88  	640.51  	465.63
		# E560A3_2018           	14  	28  	2012	31.28   	33.08    	0.84    	1.80   	46.67  	372.57  	617.20  	488.01
		#	(...)

		#WHERE:
		#	Column #1: Study ID
		#	Column #2: Sample ID (name)
		#	Column #3: Ring number, from pith to bark			===> REQUIRED
		#	Column #4: Ring year							===> REQUIRED
		#	Column #5: Ring end position, from bark to pith, mm.	===> REQUIRED
		#	Column #6: Ring start position, from bark to pith, mm.	===> REQUIRED
		#	Column #7: Late wood width, mm.
		#	Column #8: Ring width, mm.
		#	Column #9: Late wood %.
		#	Column #10: Early wood density, kg/m3.
		#	Column #11: Late wood density, kg/m3.
		#	Column #12: Ring wood density, kg/m3.

		#NOTE: only columns 3 to 6 are KEPT. All other are discarded and/or calculated, including the sample name, extracted from the filenames.
		#	[20220405]: this works with .sum files generated by the Excel VBA script regroup_data_from_sm_density_files20220404.bas, which have no "Study ID" and "Sample ID" fields.
		#	It it CRUCIAL that Ring Nos. are ordered (E7 error if not) and consecutive (E8 error if not), and that positions are also ordered (end pos < start pos barkwise, E10 if not) and consecutive (previous ring end position SHOULD ALWAYS EQUAL next ring start position, W8).
		#	THUS, KEEP ALL RINGS BETWEEN PITH AND BARK:
		#		Even when large chunks of the core have been removed at the center, leaving near-zero densities (air) for the rings within,
		#		...keep ring numbers, years and end/start positions (the two latter do not need to be exact).
		#		
		#	DO NOT remove rows from the .sum file, unless they represent extra rings after the pith, when the full radius has been scanned up to pith center.

#[sample_name_eq_list]
	#e560a3_eqtable_dendrono_sampleid_dsi_gy_higs.txt
		#	1	544353	523	2018	t
		#	2	544307	523	2018	t
		#	3	544352	523	2018	t
		#	4	544350	523	2018	t
		#	5	544338	523	2018	t
		#	6	544339	523	2018	t
		#	7	544324	523	2018	t
		#	8	544321	523	2018	t
		#	9	544418	523	2018	t
		
		#WHERE
		#	Column #1: Sample name
		#	Column #2: germplasm_id
		#	Column #3: data_source_id
		#	Column #4: growth year at harvest 
		#		e.g. harvest on 2019-01-02 --> growth year = 2018
		#		e.g. harvest on 2018-10-01 --> growth year = 2018
		#	Column #5: was harvested during growing season ? (boolean)
		#		t if harvested durant growing season (typically May 15th to September 30th around Québec City).


#-----------------------------------------------------------------------------------------------------------------------------------------------------------
#Principal output files:
#-----------------------------------------------------------------------------------------------------------------------------------------------------------
#corrected reads file (1 file per sample):
#---------------------------------------------
	#Example: A6_corr_reads.txt ("P:\___0TreeSource\___0Requetes_utilisateurs\20160425_(TODO)_PatrickLenz_GAPP_density\Génération_de_sum_corrigés_avec_dat_20170612\RealRun20170614\density_outfiles_201706141607\A6_corr_reads.txt")
	#	sample_name	ring_year_sum	ring_no_sum	pos_dat	density_dat	ring_no_dat	transition_dat	line_no	transition	pos_p2b
	#	A6	2014	8	2.320	971.92	8	L	  1342	2	43.88
	#	A6	2014	8	2.360	864.14	8	L	  1341	2	43.84
	#	A6	2014	8	2.400	766.36	8	L	  1340	2	43.8
	#	A6	2014	8	2.440	671.85	8	L	  1339	2	43.76
	#	A6	2014	8	2.480	596.93	8	L	  1338	2	43.72
	#	A6	2014	8	2.520	575.69	8	L	  1337	2	43.68
	#	A6	2014	8	2.560	560.68	8	E	  1336	2	43.64
	#	A6	2014	8	2.600	515.34	8	E	  1335	2	43.6
	#	A6	2014	8	2.640	493.41	8	E	  1334	2	43.56
	#	A6	2014	8	2.680	478.53	8	E	  1333	2	43.52

	#Column:
	#1. sample_name 				(from .dat file name)					
	#2. ring_year_sum 				(from .sum file)						
	#3. ring_no_sum: 				ring number from PITH to bark (from .sum file)	===> x_ray_dens_msmts_per_read.ring_pith_to_bark
	#4. pos_dat: 					position, mm from BARK to pith (from .dat file)	===> WILL BE IGNORED. Will use pos_p2b (field #9 below) instead.
	#5. density_dat: 					wood density, kg/m3 (from .dat file)			===> x_ray_dens_msmts_per_read.density
	#6. ring_no_dat:														===> WILL BE IGNORED, the ring number from the .SUM file will be taken instead.
	#6. transition_dat: 				original wood type: E=Early, L=Late (from .dat file). ===> WILL BE IGNORED. Calculated transition (field #8 below) will be used instead.
	#7. line_no:					line number, from PITH to bark, based on .dat file.	===> x_ray_dens_msmts_per_read.read_no
	#							In the current file, there might be missing line numbers, because lines were excluded from the original .dat files based on .sum files ring delimitations.
	#8. transition: 					transition calculated by current script. 			===> x_ray_dens_msmts_per_read.transition
	#							1= Early wood, 2= Late wood, \N=no transition could be calculated.
	#9. pos_p2b:					position, mm from PITH to bark. 				===> x_ray_dens_msmts_per_read.position
	#							Calculated from current script, based on the highest value for the first ring start position of the *_corr_ring_stats.txt file.

#Formatted corrected reads file (1 file for all samples):
#---------------------------------------------
#Grouping of all *_corr_reads.txt files above. Ready to import into x_ray_dens_msmts_per_read
#Example: all_samples_ready4import.txt
	#	538301	    23	0	606.02	2	1	513
	#	538301	    24	0.04	616.12	2	1	513
	#	538301	    25	0.08	638.38	2	1	513
	#	538301	    26	0.12	644.97	2	1	513
	#	538301	    27	0.16	640.66	2	1	513
	#	538301	    28	0.2	658.40	2	1	513
	#1. germplasm_id
	#2. line_no
	#3. pos_p2b
	#4. density_dat
	#5. ring_no_sum
	#6. transition
	#7. data_source_id


#corrected rings file
#---------------------------------------------
	#Example: A1_corr_ring_stats.txt
	#	sample_name	ring_year	ring_no	ring_start_pos	ring_end_pos	number_of_reads	ring_width	ring_dens_avg	ring_dens_min	ring_dens_max	ring_dens_median	ew_start_pos	ew_end_pos	reads_ew	ew_width	ew_dens_avg	ew_dens_min	ew_dens_max	ew_pct	lw_start_pos	lw_end_pos	reads_lw	lw_width	lw_dens_avg	lw_dens_min	lw_dens_max	lw_pct	note	ring_start_pos_inv	ring_end_pos_inv	ew_start_pos_inv	ew_end_pos_inv	lw_start_pos_inv	lw_end_pos_inv
	#	A1	2014	9	6.16	2.16	101	4.04	348.42	216.69	677.84	355.80	6.160	3.640	64	2.560	299.77	216.69	380.15	.633	3.600	2.160	37	1.480	432.571	341.22	677.84	.366		49.92	53.92	49.92	52.44	52.48	53.92
	#	A1	2013	8	11.36	6.20	130	5.20	321.512	255.53	707.70	284.285	11.360	8.120	82	3.280	274.249	255.53	304.65	.630	8.080	6.200	48	1.920	402.252	272.44	707.70	.369		44.72	49.88	44.72	47.96	48	49.88
	#	A1	2012	7	17.36	11.40	150	6.00	338.203	233.07	744.83	307.015	17.360	13.960	86	3.440	284.538	233.07	326.00	.573	13.920	11.400	64	2.560	410.317	286.41	744.83	.426		38.72	44.68	38.72	42.12	42.16	44.68
	#	A1	2011	6	25.20	17.40	196	7.84	314.03	230.69	679.39	293.590	25.200	19.360	147	5.880	283.286	230.69	325.45	.750	19.320	17.400	49	1.960	406.261	256.57	679.39	.250		30.88	38.68	30.88	36.72	36.76	38.68
	#	A1	2010	5	33.52	25.24	208	8.32	363.854	270.96	693.56	348.065	33.520	28.000	139	5.560	332.497	270.96	450.43	.668	27.960	25.240	69	2.760	427.023	281.00	693.56	.331		22.56	30.84	22.56	28.08	28.12	30.84
	#	A1	2009	4	39.92	33.56	160	6.40	355.46	267.17	683.28	310.560	39.920	35.680	107	4.280	301.452	267.17	399.74	.668	35.640	33.560	53	2.120	464.494	308.84	683.28	.331		16.16	22.52	16.16	20.4	20.44	22.52
	#	A1	2008	3	46.28	39.96	159	6.36	343.844	268.54	664.42	311.42	46.280	41.640	117	4.680	308.114	268.54	389.53	.735	41.600	39.960	42	1.680	443.379	305.41	664.42	.264		9.8	16.12	9.8	14.44	14.48	16.12
	#	A1	2007	2	51.92	46.32	141	5.64	380.792	306.59	619.06	361.53	51.920	48.440	88	3.520	344.993	306.59	411.92	.624	48.400	46.320	53	2.120	440.232	318.21	619.06	.375		4.16	9.76	4.16	7.64	7.68	9.76
	#	A1	2006	1	56.08	51.96	104	4.16	423.891	332.94	647.53	388.910	56.080	54.040	52	2.080	366.763	332.94	393.90	.500	54.000	51.960	52	2.080	481.019	362.96	647.53	.500		0	4.12	0	2.04	2.08	4.12

	#Column:
	#1. sample_name		(from .dat file name)
	#2. ring_year: 		(from .sum file)
	#3. ring_no: 			ring number from pith to bark (from .sum file)
	#4. ring_start_pos: 		ring starting position, BARK to PITH (calculated from .sum file)
	#5. ring_end_pos		ring ending position, BARK to PITH (from .sum file)
	#6. number_of_reads	number of reads in ring (calculated from .dat and .sum files)
	#7. ring_width		ring width (calculated from .sum file)
	#8. ring_dens_avg		average ring density (calculated from .dat and .sum files)
	#9. ring_dens_min		minimum ring density (calculated from .dat and .sum files)
	#10. ring_dens_max		maximum ring density (calculated from .dat and .sum files)
	#11. ring_dens_median	median ring density (calculated from .dat and .sum files)
	#12. ew_start_pos		early wood stating position, BARK to PITH (calculated from .dat and .sum files)
	#13. ew_end_pos		early wood ending position, BARK to PITH (calculated from .dat and .sum files)
	#14. reads_ew		number of reads in early wood (calculated from .dat and .sum files)
	#15. ew_width		early wood width (calculated from .dat and .sum files)
	#16. ew_dens_avg		average early wood density (calculated from .dat and .sum files)
	#17. ew_dens_min		minimum early wood density (calculated from .dat and .sum files)
	#18. ew_dens_max		maximum early wood density (calculated from .dat and .sum files)
	#19. ew_pct			early wood percentage (calculated from .dat and .sum files)
	#20. lw_start_pos		late wood
	#21. lw_end_pos
	#22. reads_lw
	#23. lw_width
	#24. lw_dens_avg
	#25. lw_dens_min
	#26. lw_dens_max
	#27. lw_pct
	#28. note			message when error in transition calculation
	#Columns 29-34 are inverted positions, from PITH to BARK.
	#29. ring_start_pos_inv	
	#30. ring_end_pos_inv
	#31. ew_start_pos_inv
	#32. ew_end_pos_inv
	#33. lw_start_pos_inv
	#34. lw_end_pos_inv


# .dat files parameters
#---------------------------------------------
#	Example: 20181126165554_dat_parameters.txt
#	file					Time/Date of Scan		Sample ID		Study Name		Operator	Description	Is pith present	No. pith rings missing	Sample moisture content
#	ASS_1_2508_2_A.dat		16-Apr-2018   11:00:44		1_2508_2_A	ASS_1_2508_2_A	JeffL					Yes			0	12.00
#	ASS_1_2748_1_A.dat		16-Apr-2018   11:29:36		1_2748_1_A	ASS_1_2748_1_A	JeffL					Yes			0	12.00
#	ASS_1_2748_2_A.dat		16-Apr-2018   11:45:55		1_2748_2_A	ASS_1_2748_2_A	JeffL					Yes			0	12.00
#	ASS_1_2748_3_A.dat		16-Apr-2018   11:59:32		1_2748_3_A	ASS_1_2748_3_A	JeffL					Yes			0	12.00
#






#-----------------------------------------------------------------------------------------------------------------------------------------------------------
#TODO:
#-----------------------------------------------------------------------------------------------------------------------------------------------------------
	#1. Get team_id from ts_pi and use it to add to comments_on_germplasms_utf.txt [2019-07-17]
	#2. Use find in density_infiles, to have all files in sub-folders as well.
	


#-----------------------------------------------------------------------------------------------------------------------------------------------------------
#Modifications
#-----------------------------------------------------------------------------------------------------------------------------------------------------------
#	20160630:
#		Now handles the #&@%! file AND sample names containing spaces in .sum files.
#		Also corrects those sample and file names in the generated files.
#	20160706:
#		Found out that there can be multiple EW/LW transition points within a single ring.
#		Now keeps the list of all transitions found, and chooses according to the method selected in the multiple_transitions_option parameter (1= last transition found, 2=first transition found).
#		A notification is done when >1 transitions are found.
#	20160707
#		Now checks that all .dat files:
#			1. have the header [SAMPLE DATA]
#			2. have an uniform number of columns in data
#			If not, warn and exit.
#		Also added messages to know where the script is at.
#
#	20160713
#		Now dos2unixes .dat files before checking the number of columns to avoid false error reports because of CR's.
#
#	20160714
#		Now also considers commas as decimals in .sum files for recognition of data rows.
#		Also checks that the positions are ordered, and that no lines of data are duplicated. This happened a lot in files from Martin Girardin's projects.
#			...see: "P:\___0TreeSource\___0Requetes_utilisateurs\20160707_(TODO)_MartinGirardin_densité_E353\SébastienClément20160714_erreurs_lignes_dupliquées.msg"
#			When this occurs, warn and exit. In the future, we may simply remove those lines from the files and proceed.
#	20170613
#		Infiles folder now passed in a parameter
#		Names changed for clarity:
#			ring_first_pos ===> ring_start_pos
#			ring_last_pos ===> ring_end_pos
#			ew_first_pos ===> ew_start_pos
#			ew_last_pos ===> ew_end_pos
#			lw_first_pos ===> lw_start_pos
#			lw_last_pos ===> lw_end_pos
#		Now adds inverted position by substracting to each position the highest value from the ring_start_pos field (typically, ring 1) in the corrected rings file.
#		Headers are only calculated once.
#	20170614
#		Adds line numbering to corrected reads file
#		Adds the corrected file prefix in the all_samples_stats.txt file, now also separated by tabs.
#	20170615
#		When combining all corrected reads (e.g. tail -q -n+2 ${temp_f}/*_corr_reads.txt) or rings files, now puts them in a file with a suffix different than _corr_reads.txt (e.g. all_samples_corr_reads_ZZZ.txt), to avoid the file copying itself indefinitely.
#		Now puts all log and summary files into a subfolder named ${temp_f}/logs_and_summaries/
#		Creates a file from all_samples.txt, listing only the lines with errors: all_samples_with_errors.txt
#		Creates a file listing the year for the last ring on the bark side, for all samples.
#		Lists last scanned ring year for all samples
#		Auto-logging of STDOUT and STERR into a file.
#	20170628
#		1. Added the script duration function (taken from script_run_all_gs3_analyses11.txt).
#		2. Now warns when there are inconsistencies between current ring's end position and next ring's start position
			#In theory, the current ring end position should be offset from the next ring's start position by the space between reads (0.04),
			#...as A SINGLE READ CANNOT THEORETICALLY be in two separate rings.
			#Actually, most of the current ring end positions are equal to the next ring's start position, but some are not, for no apparent reason. This could not be explained by Shawn Mansfield's team.
			#Example: 004.sum

			#Position of end of current ring = position of start of next ring (most cases)
			#				END		START
			#	4	45	2011	3.28		3.88
			#	4	44	2010	3.88		4.44
			#	4	43	2009	4.44		4.88
			#	4	42	2008	4.88		5.68
			#	4	41	2007	5.68		6.68


			#Position of end of current ring = 0.04 mm offset from position of start of next ring (some cases)
			#				END		START
			#	4	4	1970	82.12		83.64
			#	4	3	1969	83.68		86.92

				#NOTE: since we substract 0.04 (=step = distance between 2 consecutive reads) from the current ring starting position in original .sum files...
				#	...to avoid it being = to the previous ring's ending position (see: ring_start_pos around line 544) in the corrected file, 
				#	...when there is already a 0.04 offset in the original .sum file, this causes a 0.08 gap in the corrected file!
				# EXAMPLE:
			
				#A 4.sum	===> 0.04 gap between end of ring 1 and start of ring 2
				#	11      2014    4.00    1.32
				#	10      2013    6.64    4.00
				#	9       2012    9.20    6.64
				#	8       2011    11.32   9.20
				#	7       2010    13.60   11.32
				#	6       2009    17.16   13.60
				#	5       2008    23.04   17.16
				#	4       2007    28.40   23.04
				#	3       2006    32.88   28.40
				#	2       2005    37.24   32.88	<=== 37.24...
				#	1       2004    41.08   37.28	<=== ...to 37.28


				#A4_corr_ring_stats.txt	===> 0.08 gap between end of ring 1 and start of ring 2
				
				#sample_name     ring_year       ring_no ring_start_pos  ring_end_pos
				#	A4      2014    11      3.96    1.32
				#	A4      2013    10      6.60    4.00
				#	A4      2012    9       9.16    6.64
				#	A4      2011    8       11.28   9.20
				#	A4      2010    7       13.56   11.32
				#	A4      2009    6       17.12   13.60
				#	A4      2008    5       23.00   17.16
				#	A4      2007    4       28.36   23.04
				#	A4      2006    3       32.84   28.40
				#	A4      2005    2       37.20   32.88	<===37.20...
				#	A4      2004    1       41.04   37.28	<===...to 37.28
				#	NOTE that in this case, the read at position 37.24 will have been removed in this file (A4_corr_ring_stats.txt).
#		3. Variable name change: transition_calc_error ---> error_message
#		4. in addition to error messages displayed onscreen (and captured in the log), instead of the generic message "...problematic ring(s). See the density_outfiles_201706141607/F108_corr_ring_stats.txt file."
#			... in all_samples_stats.txt, there is a specific message:
#				Ring errors/warnings: E6 (3,4,5), W1 (7,8), W2 (1,2)
#			Error codes:
#				E6.	No reads found between end and start positions in .dat file corresponding to .sum file ring. ***THE WHOLE .sum FILE SHOULD BE REDONE.***
#				W1.	There are only too few reads in the ring.
#				W2.	No clear shift in density could be found.
#				W3.	No early wood reads at the start of the ring.
#				W4.	Number of early wood reads is too low.
#				W5.	There are density values of less than the minimal value.
#				W6f.	There is inconsistency between the ring's end position and the next ring's start position.
#				W6r.	There is inconsistency between the ring's start position and the provious ring's end position.
#				W7.	Several early to late wood transitions were found throughout the ring.
#
#	20170629
#		1. Variable name change: file_prefix_corrected ---> sample_name
#		2. Variable name change: error_message ---> ring_error_message
#		3. Each time a ring error is detected, a line (sample name, ring number, error code, error message) is added to a sample-specific file (/dev/shm/current_sample_ring_error_messages.txt).
#			a. if that file is not empty, the summary of errors detected will be added to ${temp_f}/logs_and_summaries/all_samples_stats.txt (see line ~ 1235).
#				The sample_error is thus no longer required.
#		4. Every sample's /dev/shm/current_sample_ring_error_messages.txt file is added to ${temp_f}/logs_and_summaries/all_samples_ring_errors_and_warnings.txt
#		5. Samples from all_samples_stats.txt with ERRORS (SKIPPED, E6), not warnings (W1-W7) are sent to all_samples_with_errors.txt
#
#	20170703, 20170704
#		1. New variable: min_reads_per_ring_dat=5. Allows to check for a minimum of reads in each .dat file.
#		2. Function fnct_write_warning_and_errors_to_stats_files added to contain the concatenation of error/warning codes (from /dev/shm/current_sample_ring_error_messages.txt) and writing to ${temp_f}/logs_and_summaries/all_samples_stats.txt.
#			This allows to have error messages written even when the rest for the "for...do...done" loop is escaped with "continue", without having to recopy tho whole code that was previously run after each ring was passed.
#		3. All whole sample errors (e.g. empty .dat file, disordered or duplicated positions in .dat file) are now logged also to /dev/shm/current_sample_ring_error_messages.txt (see point 2).
#		4. New whole sample checks and error messages:
#			E4 Missing ring in the .dat file
#			E5 Major gaps between reads in .dat file
#			E6 Empty/no header .sum file
#			E7 Disordered ring numbers in .sum file
#			E8 Missing rings in .sum file
#			E9 Rings in .dat not in .sum, or the opposite.
#			E10 Rings with start pos < end pos in .sum file
#			E11 Ring width > max_ring_width_factor x median current sample ring width
#			E12 Ring numbers replicated in .sum file
#		5. Now, median value (density or other) is calculated by a function called fnct_get_median_value
#		6. Previous error/warning messages renamed:
#			E6. ---> E12	No reads found between end and start positions in .dat file corresponding to .sum file ring. ***THE WHOLE .sum FILE SHOULD BE REDONE.***
#			W1. ---> W3	There are only too few reads in the ring.
#			W2. ---> W4	No clear shift in density could be found.
#			W3. ---> W5	No early wood reads at the start of the ring.
#			W4. ---> W6	Number of early wood reads is too low.
#			W5. ---> W7	There are density values of less than the minimal value.
#			W6f. ---> W8f	There is inconsistency between the ring's end position and the next ring's start position.
#			W6r. ---> W8r	There is inconsistency between the ring's start position and the provious ring's end position.
#			W7. ---> W9	Several early to late wood transitions were found throughout the ring.
#
#	20170705
#		1. Now relies solely on fnct_get_median_value
#		2. Now uses a timestamp prefix (precise to the second) for all /dev/shm/ temporary files to avoid conflicts during concurrent script executions.
#		3. Also puts that timestamp at the end of the temporary folder (which was previously at the minute precision) to avoid putting several runs started within the same minute under the same folder
#			temp_f=density_outfiles_${ts}
#		4. E9a.	Rings from .dat file are missing in .sum file. ---> now W10
#			...car il est possible que ce cerne ait délibérément été omis du fichier .sum car il n'était pas bon.
#		5. 
#			${temp_f}/logs_and_summaries/all_analyses_start_timestamp.txt	---> /dev/shm/${ts}_all_analyses_start_timestamp.txt
#			${temp_f}/logs_and_summaries/all_analyses_end_timestamp.txt	---> /dev/shm/${ts}_all_analyses_end_timestamp.txt
#	20170908
#		Now maximal width compared to median ring width is specified into a variable: max_ring_width_factor
#	20170918
#		Corrected the condition for calculation of EW/LW stats (line ~ 1630).
#		E11 has been transformed into W11 (warning only), and max_ring_width_factor set to 3.
#	20170919
#		Now prints script name in the header.
#	20170920
#		Minor correction to grep on line ~ 717:
#			grep -rEL "${dat_file_data_tag}" ./${infiles_folder}|grep ".dat$"|awk -F "/" '{print $NF}' > /dev/shm/${ts}_dat_files_wo_data_headers.txt
#		
#	20170921
#		Now check for replicated headers in .dat files
#		Now also uses find -exec grep to find dat files, then those without headers, instead of the old grep -rEL "${dat_file_data_tag}" ./${infiles_folder}|grep ".dat$", which found files without headers, then searched which ones were dat files.
#	20170926
#		After range specified in cleaned ring file extracted from cleaned reads file...
#		...first (pith) and last (bark) rings are checked to ensure there are no remaining low density (< ${min_allowed_density}, usually 100 kg/m3) reads in the ~20 reads at both ends (specified by ${reads_to_check_for_density_pithside} and ${reads_to_check_for_density_barkside}).
#		This avoids having too many low density reads remaining in final files.
#		Reads removed that way can be found in: all_reads_rejected_for_low_density.txt
#		Note that low density reads within the sample are left untouched.
#	20171002
#		Now removes all the lines before (bark side) or after (pith side) low-density (<100) reads for rings at either ends of the sample
#		An option to remove only the <100 density reads (option 2) or all reads up to the last <100 density (option 1, default) is added.
#	20171003
#		Now removes all current ring-specific files for each ring analysis, to avoid interference from ring to ring.
#	20171004
#		Refined the low-density reads removal with 4 options:
#			1. Reject the last read below the GRADUAL density threshold, and all previous reads
#			2. Reject the last read below the FIXED density threshold, and all previous reads
#			3. Reject only reads below the GRADUAL density threshold
#			4. Reject only reads below the FIXED density threshold	
#			Also see below.
#		Renamed script_recalc_densitometry_sum_files_from_dat_sum20171004.txt ---> 	script_recalc_Quintek_densitometry_files_from_dat_sum20171004.txt
#	20180629
#		Renamed script_recalc_Quintek_densitometry_files_from_dat_sum20171004.txt ---> 	recalc_Quintek_densitometry_files_20171004.txt
#	20180703
#		- changed the following variable names:
#			avg				--->	avg_dens
#			min				--->	min_dens
#			max				--->	max_dens
#			min_ew			--->	min_ew_dens
#			min_lw			--->	min_lw_dens
#			max_ew			--->	max_ew_dens
#			max_lw			--->	max_lw_dens
#			avg_ew			--->	avg_ew_dens
#			avg_lw			--->	avg_lw_dens
#			min_density_limit	--->	min_allowed_density
#		- addded max_allowed_density
#
#	20180704
#		- transition_choice	--renamed-->	multiple_transitions_option
#		- Added mid-range density calculation		
#		- min_allowed_density and max_allowed_density now used to remove outside-range densities before calculating density stats (min/max/avg/mid-range and median).
#			- these out-of-range densities will STILL be kept in the final density files.
#			- only when there are at least 2 density reads remaining once these outside-range densities were removed will stats and transition be calculated
#		- Regrouped density stats calculation
#		- Added ewlw_transition_method, with default value being 1 (mid-range)
#
#	20180705
#		- Now requires transition_dens to exist (!= "\N") before looking for a transition point (line ~1972): if [ ${number_of_reads} -ge ${min_reads_for_transition} ] && [ ${transition_dens} != "\N" ]
#		- No more screen_log settings, now always displaying all warnings and erros on screen.
#		- Error/warning onscreen reporting improved.
#
#	20180706
#		- Various error/warning reporting corrections
#
#	20181122
#		- The total number and position of essential columns in the .dat files are now specified into the following variables:
#			dat_file_data_cols
#			col_pos_b2p
#			col_dens
#			col_ringno_p2b
#			col_wood
#		- The .dat files field separator is now specified in dat_fs
#		- The .dat file parameters section header is now specified in dat_file_parameters_tag
#		- .dat files parameters presence is checked.
#	20181123
#		- Several paramaters' values are now extracted from .dat files [SAMPLE PARAMETERS] section
#			- The list is indicated in the array parameters_to_keep
#		- All .dat and .sum files are dos2unix'ed together
#		- Check of .dat files column counts is now improved (faster)
#		- Specific columns (specified by col_pos_b2p, col_dens, col_ringno_p2b and col_wood) are now extracted when cleaning the .dat files
#		- The homogeneity of columns count is now checked when cleaning .sum files, to avoid errors caused by partial rows removal.
#	20181126
#		- Now requires an equivalency list between sample names and germplasm_id's and data_source_id's
#		- It checks that this list has 3 columns, and that all samples are within the list
#		- *_corr_reads.txt file regrouping is now automatic (no longer an option), and final file is formatted to be readily importable into x_ray_dens_msmts_per_read
#			1. germplasm_id
#			2. line_no
#			3. pos_p2b
#			4. density_dat
#			5. ring_no_sum
#			6. transition
#			7. data_source_id
#		- *_corr_ring_stats.txt regrouping is no longer done.
#	20181127
#		- Now lists at the end of the script the critical errors (E) requiring .dat/.sum files rebuilding
#		- Minor corrections to parameters extraction
#		- Now all corrected files are moved to /corrected_files, and all other files to /logs_and_summaries
#		- all_samples_last_bark_ring_year.txt replaced with all_samples_ring_nos_and_years.txt, listing not only the last ring year, but the first/last ring number/year.
#		- parameters from .dat files:
#			- some are extracted as variables (operators, moisture contents)
#			- some (scan dates, presence of pith, comments, and missing rings pithside) are put into a file: samples_pith_missing_rings_comments.txt
#		- print stats about sampling date, operator and moisture contents at the end.
#		- all_samples_ring_nos_and_years.txt and samples_pith_missing_rings_comments.txt are joined to form sample_rings_and_comments.txt
#			- This file allows to see abnormal last ring (bark) years, wether pith is present or not, and comments on the samples.
#		- names of summary files changed:
#			- all_samples_stats.txt ---> samples_errors_and_warnings.txt
#			- all_samples_ring_errors_and_warnings.txt ---> rings_errors_and_warnings.txt
#			- all_samples_with_errors.txt ---> samples_with_errors.txt
#	20181128
#		- minor bugs correction in stats display at the end
#		- dat_parameters.txt is the new name for params_per_file.txt
#		- It now contains:
#			- Correctly formatted dates (YYYY-MM-DD), obtained from "Time/Date of Scan" and added to the file
#			- Full operator names (not just abbreviations) are also added as a new field to the file
#				- The addition is based on a reference associative array named "operators_abbrev_fullname"
#				- Whenever an operator name from .dat files is not in the array, script warns, asks to add it, and stops
#		- samples_pith_missing_rings_comments.txt ---> samples_info_from_dat_parameters.txt
#			- Now includes correctly formatted dates and operator names, ready for insertion into TreeSource
#			- Position of fields to create that file are not hardcoded, but dynamically found using original field names
#
#	20181130
#		- Minor corrections to reporting files pathways at the end of the script.
#
#	20181206
#		- Correction to path preventing generation of final file for import (all_samples_ready4import.txt)
#		- Error and warning codes are now in a separate file called error_and_warning_codes.txt.
#		- Now generates a file with error/warning stats per sample and ring, including the codes descriptions (sample_and_ring_w_e_stats.txt)
#	20190529
#		- Deleted the following line around ~2845 (a forgotten piece of code hanging there for no other reason than an oblivion): grep -E '^(E|W)[0-9]' ${temp_f}/logs_and_summaries/error_and_warning_codes.txt|sort -k1,1
#		- now there are new subfolders named "intermediate" and "for_import" within /logs_and_summaries/, to avoid file overcrowding.
#		- sample_rings_and_comments.txt --renamed--> sample_stats_and_comments.txt
#		- generate a description of fields for sample_stats_and_comments.txt, named sample_stats_and_comments_fields.txt
#	20190617
#		- Ring numbers present in .sum but not in .dat ---> no longer considered an irrecuperable error (E9 previously)
#			- Now triggers a W18 warning.
#		- Ring start/end positions and number of reads also displayed in the stats
#			- a) from original .sum files
#			- b) when low-density reads were removed
#	20190618
#		Cores with missing pieces are now properly dealt with, as long as the missing rings are still properly recorded (number, year, end pos., start pos.) in the .sum file:
#		- Proportion of extreme density reads (<200 or > 2000 kg/m3) is now used to flag those invalid rings. 
#			Note that any ring can fall under that category, including first and last rings, even if this is unlikely because those rings have already had their bad reads removed at the extremities.
#		- If proportion is > extreme_densities_max_pct_allowed (typically 20%, see below), the ring is added to a list of invalid rings (invalid_rings.txt).
#		- Stats are also shown whenever such extreme density reads are encountered
#
#	20190619
#		After looking at 45 rings (pictures of cores, average density of extreme density reads, and % of extreme reads) flagged as invalid according to the min_allowed_density (actually at 200)  and extreme_densities_max_pct_allowed variables (actually at 20)
#		...it was decided that the new values should be: min_allowed_density=100 and extreme_densities_max_pct_allowed=50. This will better allow to raise a flag only when they are large parts of missing wood in the rings, giving an unusually low density (air).
#		For reference, see: "P:\___0TreeSource\___0Requetes_utilisateurs\20190111_(TODO)_Claire_nouvelles_mesures_Mastigouche_pour_projet_isotopes\int\invalid_rings_simpler_stats_annotées.txt"
#
#	20190621
#		Now includes the "Commentaires" parameter from .dat files to be extracted
#		Also, uses a left join and missing-columns filling command to add each new parameter in the *_dat_parameters_temp.txt file.
#			This makes sure adding new columns doesn't messes up the file, as it would do with a paste command (before) when fields are missing.
#
#	20190625
#		Corrected the parameters extraction from .dat files and added the "Commentaires" parameter.
#		Now counts the number of invalid rings per sample (current_sample_invalid_rings), and flags the sample as invalid (germplasms.sample_is_invalid, germplasms.sample_invalidity_reason) if there are more than max_pct_invalid_rings_for_invalid_sample % invalid rings within it.
#			A file named 'SQL_UPDATE_invalid_samples.txt' is created.
#		Regrouped the "files to import" comments under a single section.
#		.dat comments are now formatted into a directly importable tab file
#
#	20190626
#		[sample_name_eq_list]: must now include growth year of the sample and harvest during growing season 
#			They will be used to label last rings in file as genuine last growth rings or past year rings in be included in last_ring_year_in_densitometry_data.
#		Removal of an surnumerous copy of E6-flagging
#		Renaming of error/warning reporting files and function.
#
#	20190627
#		Automatically creates a list for last_ring_year_in_densitometry_data when last ring year in .sum file is less than last ring year expected from harvested date
#		Also checks for possible last ring year in .sum data that is > than expected year (impossible condition) ---> Error E9
#		Regorganized sections on warning/error stats
#		Reorganized section on files for import
#		Now prints the ring year at the beginning of each ring analysis
#
#	20190711
#		Now automatically creates a list of incomplete rings for all last growth rings (ring year in .sum=expected ring year from harvest date) when sample harvest was done during growing season
#		Automatically creates a file to update phys_msmt_experiments: SQL_UPDATE_phys_msmt_experiments.txt with parameters.
#		Makes sure only one data_source_id is provided in $eq_list, and that it is an integer.
#
#	20190712
#		Now checks for existing tabulations after .dat file parameter values. If any, warn and exit. This would otherwise introduce an additional column when uniformizing column numbers in the ${ts}_dat_parameters.txt file.
#		New variable: rist_ring_is_pith: automatically adds first rings to invialid_rings.txt with is_pith=TRUE.
#			This is useful when the pith is systematically kept in results, as it is the case for analyses made at the Laurentian Forestry Centre.
#		
#	20190715
#		- Completion of pith rings put in invalid rings (from first_ring_is_pith above)
#		- To avoid too much text and redundancy, removed the onscreen display of all rings >=3x larger than median ring width at beginning of each sample (W11), as this error was also displayed after each ring.
#		- invalid_rings.txt now made of pith + extreme density reads rings
#		- Today's date (date +%Y-%m-%d) is now put into a variable: pgf_date	
#		- A flagging date is added at the end of each ring flagging table: invalid_rings.txt, incomplete_rings.txt and  last_ring_year_in_densitometry_data.
#		- A description of all error/warning files is provided at the end of the script, under the header "Errors and warnings reporting"
#		- max_pct_invalid_rings_for_invalid_sample now set to 30%, and that threshold must be passed, an equality will not qualify.
#
#	20190716
#		- Now removes ANSI color codes from script_log.txt for better readability.
#
#	20190717
#		- Slight corrections to files for import and suggested commands:
#			- NULL ---> \N
#			- In : psql -U cleseb -h 132.156.208.30 -d ts_d -c "SQL_UPDATE_invalid_samples.txt"
#				the "-c" option should have been "-f"
#			- Added commands to disable triggers before inserting into invalid_rings, incomplete_rings and ast_ring_year_in_densitometry_data, and enabling them after.
#		- Now suggests commands to import comments in comments_on_germplasms
#		- Converts comments_on_germplasms.txt, SQL_INSERT_INTO_phys_msmt_experiments.txt and SQL_UPDATE_phys_msmt_experiments.txt to UTF-8 to avoid the following error: ERROR:  invalid byte sequence for encoding "UTF8"
#		- Script now copies itself to ${temp_f}
#
#	20190909
#		Ligne 1293, on a ajouté l'option -H au grep, pour s'assurer qu'il affiche le chemin du fichier, même lorsqu'il n'y en a qu'un seul (défaut: n'affiche le chemin que lorsqu'il y a >1 fichier), sinon cela cause une erreur.
#
#	20190910
#		Now auto-detects the type of data (position, density, ring no or wood type) for .dat files! See line ~ 1606
#		This takes over the original values specified for col_pos_b2p, col_dens, col_ringno_p2b and col_wood (line ~ 854)
#
#	20191001
#		Now detects any abnormal step between reads. Previously, only steps larger than expected (e.g. 0.04) were flagged. See lines 1815+.
#			Detects cases where reads are systematically spaced differently than expected from the step parameter (0.04)
#
#	20210719
#		Script auto-determination of data types (lines 1637+) in .dat files was buggy when files had extra columns such as an incremented line number column like below:
#			[SAMPLE DATA]
#			    0,   0.780, 811.42, 30,L, 5.1645
#			    1,   0.790, 803.79, 30,L, 5.1886
#			    2,   0.800, 865.14, 30,L, 4.9979
#			    3,   0.810, 843.08, 30,L, 5.0656
#			    4,   0.820, 697.76, 30,L, 5.5356
#			    5,   0.830, 622.84, 30,L, 5.7947
#			    6,   0.840, 565.79, 30,L, 6.0001
#		Now, the dat_column_pos_determination_method variable determines if column positions are fixed (1, default) or automatically-detected (2).
#		See line ~876+
#
#	20220405
#		Simply added comments in the script about eligibility of .sum files generated by Excel VBA script regroup_data_from_sm_density_files20220404.bas.
#	20220406
#		Split in two separate checks (lines ~1505+):
#			Cases where the number of columns is inconsistent throughout all .dat files
#			Cases where the number of columns is different than that specified in ${dat_file_data_cols} 
#		For the second check above, it is now performed only if check_for_expected_nb_of_columns <> 0
#		Now dat_column_pos_determination_method=2 (automatic column type determination)
#
#	20220407
#		- Now only 2 columns are required in the .dat files: position and density.
#		- The other 2 (ring number and wood type). which were kept in the *_reads_tmp.txt file, were not used anyway in later calculations but were rather kept for information purposes.
#		- When any one of the other 2 columns is absent, it is filled with "\N" in the *_reads_tmp.txt file (line ~ 1844).
#		- Inconsistencies in column numbers between all .dat files now only triggers a warning instead of an abortion of the script, to allow for datasets with .dat files having different column counts.
#
#	20230217
#		- Added Christine Simard as operator
#
#	20230221
#		Changed description for E14 to more accurately represent the problem:  The .sum file contains incomplete rows --> The .sum file has an irregular number of columns
#		Now adds calculation of median valuefrom function fnct_get_median_value when auto determining the columns type (variable $dat_column_pos_determination_method), around line 1724.
#			This ensures better identification of the density column.
#
#	20230309
#		Now flags differently the .sum rings that have no corresponding .dat reads
#			New: if both ring start and ring end positions = 0 ---> W23: assumes that it's operator filled following dendrochronology analyses showing that rings actually existed for those years, but that they cannot be seem in desitometry.
#				---> in that case, rings are added to invalid_rings.txt
#			Otherwise: classique E12 error ---> no reads found between start/end positions.
#			
#	20230313
#		E4 (.dat files missing some rings) turned into W24, because rng numbers from .dat files are NOT used.
#		Now removes any trailing spaces/tabs when cleaning the .sum file (line  ~2203) to avoid adding a column inadvertently at the end.
#		When checking for zero-width rings in .sum file, doesn't look anymore for 0 at both start and end position, but rather if the two are equal, which will also work for zero-width rings of non-zero positions (e.g. start=1.36, end=1.36)
#
#	20230315
#		Minor correction on line ~3347:
#							Before: printf "${sample_name}\t${ring_no}\t${ring_error_message} Auto-flagged by $0 on ${pgf_date}.\t9\tFALSE\tNULL\n" >> /dev/shm/${ts}_other_invalid_rings.txt
#							After: printf "${sample_name}\t${ring_no}\t${ring_error_message} Auto-flagged by $0 on ${pgf_date}.\t9\tFALSE\t\\N\n" >> /dev/shm/${ts}_other_invalid_rings.txt
#		Now uses the grep -a option (line ~ 1539) to extract parameters from the .dat file, to avoid the occasionnal "Binary file" returned by grep when it encounters accents.
#
#	20230323
#		Automatically gets the TreeSource team_id for the operator's name in the .dat file, to prepare a ready-to-import comments_on_germplasms.txt file.
#		Also, for some datasets (e.g. E60A densitometry from 2017 wood cores), observations about cores and missing rings are often put into the "Description" rather than into the "Commentaires" .dat field.
#			---> the script makes sure to distinguish and save both.
#
#	20230330
#		Corrections to the SQL_INSERT_INTO_phys_msmt_experiments_utf.txt and SQL_UPDATE_phys_msmt_experiments_utf.txt files to include:
#		- The version (date) of the script
#		- The tring_dating_method_id (set by default to 999)
#		
#================================================================================================================================================
#VARIABLES
#================================================================================================================================================

#Timestamp to add as a prefix for all temporary files in /dev/shm/, to avoid conflics during concurrent script runs.
ts=$(date +%Y%m%d%H%M%S)	#e.g. 20190717112047

#Today's date in PostgreSQL format
pgf_date=$(date +%Y-%m-%d)	#e.g. 2019-07-17


#Colors
red_color="\033[1;31m"
green_color="\033[1;32m"
yellow_color="\033[1;33m"
blue_color="\033[1;34m"
normal_color="\033[0m"

#Internal field separator (newline)
IFS='
'

#[NEW20230316]: check if running from s-que-vdq100156 server.
#Linux server variables
db_server_address="132.156.208.78"
linux_server_name="s-que-vdq100156"	#Name of the Linux server used for running the script
req_files_linux_server="/home/team/shared_scripts/REQs_script_extract_wholesite" #Location of required files on that server

#Test if running locally or on Linux s-que-vdq100156 server
#Running from Linux server (note: it is assumed that the /home/seclemen/ folder is NOT accessible, as the current script might be run by anybody.
if [ $(uname -n|grep -i ${linux_server_name}|wc -l) -eq 1 ];
then 
	echo "Running from ${linux_server_name}"
	echo "Will use files in ${req_files_linux_server}/, which are shared with the current script."
	req_files_folder="${req_files_linux_server}"
else 
	echo "NOT running from ${linux_server_name}"
	echo "Will use files in current directory"
	req_files_folder="."
	
	#If ./xtraksites132.156.208.78.txt doesn't exist, warn and exit!
	if [ ! -e ./xtraksites132.156.208.78.txt ]
	then 
		printf "${red_color}The required file xtraksites132.156.208.78.txt was NOT FOUND!\nPlease copy it from ${db_server_address}:/home/team/shared_scripts/REQs_script_extract_wholesite/ to the current folder.\nSCRIPT ABORTED${normal_color}\n\n"
		exit
	fi
fi

#[NEW20230316]: Parameters to connect to TreeSource as xtraksites
	#This will be used to extract and insert codes in observatioon_codes
	PGPASSWORD=$(cat ${req_files_folder}/xtraksites132.156.208.78.txt)
	PGHOST=${db_server_address}
	PGUSER="xtraksites"
	export PGUSER PGPASSWORD PGHOST
	database_name="ts_pi"




#Associative array for operator abbreviations in .dat files
#----------------------------------------------------------------
#Updated: 3/6/2019
declare -A operators_abbrev_fullname
operators_abbrev_fullname=(
[jeffl]="Jean-François Légaré" 
[jfl]="Jean-François Légaré" 
[eduss]="Éric Dussault"
[foster-francis]="Foster Hart, Francis de Araujo"
[foster]="Foster Hart"
[vseigner]="Vincent Seigner"
[jfleagre]="Jean-François Légaré"
[jflegare]="Jean-François Légaré"
[erm]="Edouard Reed-Métayer"
[ini]="Ioan Nicolae"
[csimard]="Christine Simard"
)


#[2023-03-16]: Get the team_id's from TreeSource for each operator from the above associative array.
printf "" > /dev/shm/${ts}_operators_ref_list.txt
for operators_abbrev in "${!operators_abbrev_fullname[@]}"
do 
	op_abbrev=${operators_abbrev}
	op_fullname=${operators_abbrev_fullname[$operators_abbrev]}
	#Get team_id from TreeSource
	op_team_id=$(PGOPTIONS='--client-min-messages=warning' psql -d ${database_name} -A -F "___" -t -c "select fnct_get_team_id_from_employee_names('$(echo ${op_fullname}|iconv -f iso-8859-1 -t utf-8)')" |perl -pe 's/___/\t/g')
	#Do it also for ts_d to have the same team_id's in case new teams are created above by the function. The output doesn't need to be kept.
	PGOPTIONS='--client-min-messages=warning' psql -d ts_d -A -F "___" -t -c "select fnct_get_team_id_from_employee_names('$(echo ${op_fullname}|iconv -f iso-8859-1 -t utf-8)')" 1> /dev/null

	#Put that into a file
	printf "${op_abbrev}\t${op_fullname}\t${op_team_id}\n" >> /dev/shm/${ts}_operators_ref_list.txt
done

#erm	Edouard Reed-Métayer	124
#vseigner	Vincent Seigner	118
#jeffl	Jean-François Légaré	110
#csimard	Christine Simard	106
#jfl	Jean-François Légaré	110
#jfleagre	Jean-François Légaré	110
#eduss	Éric Dussault	16
#jflegare	Jean-François Légaré	110
#foster	Foster Hart	95
#ini	Ioan Nicolae	140
#foster-francis	Foster Hart, Francis de Araujo	139

#cat /dev/shm/${ts}_operators_ref_list.txt
#exit



#Options:
#-------------------------------------------------
#Variable to systematically consider all first rings as piths [20190711] 
first_ring_is_pith=0	#0=no, 1=yes

#Transition density methods below:
#1. Mid-range value method
#2. Median value method
ewlw_transition_method=1

#Transition to choose when multiple transitions are found
#1. Keep the last encountered (closest to bark end) - DEFAULT
#2. Keep the first (closest to pith end)
multiple_transitions_option=1

#End-regions (near pith and bark) low density reads removal option (see example below)
#	1. Reject the last read below the GRADUAL density threshold, and all previous reads
#	2. Reject the last read below the FIXED density threshold, and all previous reads
#	3. Reject only reads below the GRADUAL density threshold
#	4. Reject only reads below the FIXED density threshold
low_density_reads_removal_choice=2

#Constants for calculations
#-------------------------------------------------
#Distance between each read, in mm
step=0.02

#Minimum number of reads per ring allowed in the .dat file
min_reads_per_ring_dat=5

#Minimal number of reads (in .dat file) to calculate transition for each ring in .sum file
declare -i min_reads_for_transition=10

#Minimal required proportion of early wood reads over total ring reads. Anything less than that will trigger an error message and not calculate the transition.
min_ew_proportion=0.05

#If a ring width is this time bigger than the median ring width, send a warning (Added 8/9/2017)
max_ring_width_factor=3
#NOTE: THIS IS ONLY FOR MAXIMUM, NO MINIMUM SET. This factor could be used to divide the median.
#See: regroup_ss_data20180604.txt

#Percent of invalid vs total rings before flagging sample as invalid [20190625]
max_pct_invalid_rings_for_invalid_sample=30	#4 out of 10 rings is sufficient tocall the sample as invalid.


#min_allowed_density is used for the following:
#	1. to remove reads at the the extremities of the sample, along with the reads_to_check_for_density_pithside and reads_to_check_for_density_barkside variables below
#	2. to remove out-of-range densities before calculating min/max/avg/mid-range and median densities (these out-of-range densities WILL STILL be kept in the final file).
#
#Note: very low density woods such as balsa (average density ~ 150 km/m3) would NOT work with this value. 
#Some other low density woods should be treated with caution:
#	Bamboo (~ 350 kg/m3), Western red cedar (~ 380 kg/m3), cottonwood (410),  White pine (350 -500), poplar (350 -500)
#	Another way could be to set that value according to species
min_allowed_density=100

#max_allowed_density is used like min_allowed_density, for the point #2 above.
max_allowed_density=2000

#Maximum percentage of extreme density reads allowed before flagging the ring as invalid. [NEW 20190618] 
#This is somewhat arbitrary, but consider that 6 abnormal density reads  (avg. 84 kg/m3) with 22 normal density (avg. 485 kg/m3) reads give 21.4% of extreme density reads.
extreme_densities_max_pct_allowed=50






#Options for removal of low-density reads at the bark and pith ends
#-------------------------------------------------------------------------------------
	#End-regions low density reads removal option (see example below)
	#	1. Reject the last read below the GRADUAL density threshold, and all previous reads
	#	2. Reject the last read below the FIXED density threshold, and all previous reads
	#	3. Reject only reads below the GRADUAL density threshold
	#	4. Reject only reads below the FIXED density threshold
	#	See: low_density_reads_removal_choice above.
	
	#Number of reads to check for minimum density on either extremity of the sample (25/9/2017)
	reads_to_check_for_density_pithside=40
	reads_to_check_for_density_barkside=40
	
	#The lowest density threshold that will be reached at the last read specified by
	#reads_to_check_for_density_pithside or reads_to_check_for_density_barkside
	#when calculating the gradual density threshold for low-density reads removal
	lowest_density_threshold=10
	
	highest_density_threshold=${min_allowed_density}	#typically 100

	#Step by which the density threshold will decrease (bark side) or increase (pith side) for each successive read
	varying_threshold_step=$(echo "scale=1; (${highest_density_threshold}-${lowest_density_threshold})/(${reads_to_check_for_density_barkside}-1)"|bc)

	
	#Explanations:
	#	Even if only reads delimitated from the .sum file (ring end position and ring start position) are taken, 
	#	...some reads with -1,N (ring number and transition) often still remain in the range in the first (bark side) and last (pith side) rings.
	#	These -1,N reads occur when density is <= 100 kg/m3 (verified for 1912 .dat files in E952 project, see: "P:\___0TreeSource\___0Requetes_utilisateurs\20170925_(TODO)_vérifier_distribution_densité_dans_x_ray_dens_msmts_per_read\protocole.txt").
	#	... and should not be in the final files.
	#	Hence, they are removed here.
	#	This serves to remove reads with normal density that sometimes appear before (bark-side) or after (pith side) low-density reads...

	#There are 2 types of density threshold:
		#a) Gradual - the threshold for removing reads will gradually become less severe as we move away from the extremity
		#b) Fixed - the threshold always remain the same
		#Example: bark side, reads_to_check_for_density_barkside=20, min_allowed_density=100, lowest_density_threshold=10
		#								grad.	fixed
		#								\/	\/
		#A-2362-1-5      2011    2.200   635.25  	1       100     100		<=== highest_density_threshold (=min_allowed_density=100)
		#A-2362-1-5      2011    2.240   577.59  	2       95.3    100
		#A-2362-1-5      2011    2.280   537.22  	3       90.6    100
		#A-2362-1-5      2011    2.320   504.68  	4       85.9    100
		#A-2362-1-5      2011    2.360   513.04  	5       81.2    100
		#A-2362-1-5      2011    2.400   57.59  	6       76.5    100		***rejected read with fixed AND gradual threshold
		#A-2362-1-5      2011    2.440   664.44  	7       71.8    100		
		#A-2362-1-5      2011    2.480   81.18  	8       67.1    100		***rejected read with fixed threshold
		#A-2362-1-5      2011    2.520   696.39  	9       62.4    100
		#A-2362-1-5      2011    2.560   694.73  	10      57.7    100
		#A-2362-1-5      2011    2.600   654.56  	11      53      100
		#A-2362-1-5      2011    2.640   660.53  	12      48.3    100
		#A-2362-1-5      2011    2.680   701.26  	13      43.6    100
		#A-2362-1-5      2011    2.720   723.80  	14      38.9    100
		#A-2362-1-5      2011    2.760   732.91  	15      34.2    100
		#A-2362-1-5      2011    2.800   697.50  	16      29.5    100
		#A-2362-1-5      2011    2.840   693.63  	17      24.8    100
		#A-2362-1-5      2011    2.880   74.05  	18      20.1    100		***rejected read (and all previous reads, option 2) with fixed threshold
		#A-2362-1-5      2011    2.920   670.66  	19      15.4    100
		#A-2362-1-5      2011    2.960   691.20  	20      10.7    100		<=== last read checked (reads_to_check_for_density_barkside=20), also where lowest_density_threshold (=10) occurs
		#A-2362-1-5      2011    3.000   678.98  	21      6       100		<=== outside range, not checked
		#A-2362-1-5      2011    3.040   59.66  	22      1.3     100		<=== 			" 
		#A-2362-1-5      2011    3.080   633.86  	23      -3.4    100		<=== 			"
		#A-2362-1-5      2011    3.120   666.51  	24      -8.1    100		<=== 			"
		#A-2362-1-5      2011    3.160   623.27  	25      -12.8   100		<=== 			"

	#Note: the same logic, albeit reversed, is applied to the ring closest to pith.

#.dat files parameters
#----------------------------------------------------------------

#Parameters to grab in each file (NEW: 23/11/2018)


#For test, reduced number of parameters: parameters_to_keep=("Sample ID" "Operator" "Description" "Is pith present" "Commentaires" "No. pith rings missing" "Sample moisture content")

parameters_to_keep=("Time/Date of Scan" "Sample ID" "Study Name" "Operator" "Description" "Is pith present" "Commentaires" "No. pith rings missing" "Sample moisture content")



#[NEW 20210719]: fixed column number and position
dat_column_pos_determination_method=2	#1 = fixed (below)	2 = automatic (see lines 1637+)

#Fixed column numbers for specific fields (Added: 22/11/2018)
#These will be ignored if dat_column_pos_determination_method=2 (above)
	#Column number for position
		col_pos_b2p=2
	#Column number for density
		col_dens=3
	#Column number for ring number p2b
		col_ringno_p2b=4
	#Column number for wood type
		col_wood=5



#Number of expected columns in .dat files (Added: 7/7/2016)
#Note: 4 for files from S. Mansfield, 6 for files from LFC.
	check_for_expected_nb_of_columns=0	#0 = no, 1 = yes. Note that this check (line ~ 1500) can be long!
	dat_file_data_cols=6



#Field separator
dat_fs=","


#Script run parameters
#-------------------------------------------------

#Number of reads per ring
declare -i number_of_reads

#[20190625] Counter for number of invalid rings flagged per sample
declare -i current_sample_invalid_rings



#sample counter
declare -i sample_number=0

#Infiles folder
infiles_folder=$1
if [ -z $infiles_folder ]
then
	printf "${red_color}Missing parameter: name of folder containing the .dat and .sum files!\n"
	printf "ABORTING${normal_color}\n"
	exit
else
	if [ ! -e $infiles_folder ]
	then
		printf "${red_color}Folder named '$infiles_folder' does not exist!\n"
		printf "ABORTING${normal_color}\n"
		exit
	fi
fi


#Is the equivalency list in parameters there ? (26/11/2018)
eq_list=$2
if [ -z $eq_list ]
then
	printf "${red_color}Missing parameter: name of file containing the sample names vs id's and data_source_id's!\n"
	printf "ABORTING${normal_color}\n"
	exit

else
	if [ ! -e $eq_list ]
	then
		printf "${red_color}File named '$eq_list' does not exist!\n"
		printf "ABORTING${normal_color}\n"
		exit
	fi

fi

#Check equivalency list columns count (26/11/2018)
dos2unix $eq_list 2> /dev/null
awk -F "\t" '{print NF}' $eq_list|sort -u > /dev/shm/${ts}_eq_table_col_count.txt
#Check if column number is homogeneous
if [ $(cat /dev/shm/${ts}_eq_table_col_count.txt|wc -l) -ne 1 ]
then
	printf "${red_color}Equivalency table '${eq_list}' has an uneven number of columns!\n"
	printf "ABORTING${normal_color}\n"
	exit

else
	#Check it has 5 columns
	eq_table_col_count=$(head -1 /dev/shm/${ts}_eq_table_col_count.txt)
	#Check if eq. table has 5 columns
	if [ $eq_table_col_count -ne 5 ]
	then
		printf "${red_color}Equivalency table '${eq_list}' must have 5 columns!\n"
		printf "\t1. Sample name in .dat/.sum files.\n"
		printf "\t2. Sample unique identifier in TreeSource.\n"
		printf "\t3. data_source_id in TreeSource.\n"
		printf "\t4. Sample growth year at harvest.\n"
		printf "\t5. Was sample harvested during growing season (t/f)?\n"
		printf "ABORTING${normal_color}\n"
		exit
	fi
fi



#Put data_source_id's from $eq_list in a file
cut -f3 -d $'\t' $eq_list|sort -u > /dev/shm/${ts}_data_source_ids.txt

#Make sure there is only one data_source_id [20190711]
if [ $(cat /dev/shm/${ts}_data_source_ids.txt|wc -l) -gt 1 ]
then 
	printf "${red_color}There must be only one data_source_id for each equivalency list!\n"
	printf "File ${eq_list} has the following values for data_source_id:\n"
	perl -pe 's/^/\t/g' /dev/shm/${ts}_data_source_ids.txt
	printf "ABORTING${normal_color}\n"
	exit
fi

data_source_id=$(cat /dev/shm/${ts}_data_source_ids.txt)

#Make sure data_source_id is numeric [20190711]
if [ $(echo $data_source_id|grep -E '^[[:digit:]]+$'|wc -l) -eq 0 ]
then 
	printf "${red_color}data_source_id must be an integer!\n"
	printf "The following value is incorrect: $(cat /dev/shm/${ts}_data_source_ids.txt)\n"
	printf "ABORTING${normal_color}\n"
	exit
fi


#Temp folders creation in local folder (/dev/shm not involved)
#-------------------------------------------------
#Create a temporary folder
temp_f=density_outfiles_${ts}
if [ ! -e $temp_f ]; then mkdir $temp_f;fi

#Within temporary folder, create a subfolder for log and summary files (new 15/6/2017)
if [ ! -e $temp_f/logs_and_summaries/ ]; then mkdir $temp_f/logs_and_summaries/;fi
if [ ! -e $temp_f/logs_and_summaries/intermediate/ ]; then mkdir $temp_f/logs_and_summaries/intermediate/;fi
if [ ! -e $temp_f/for_import/ ]; then mkdir $temp_f/for_import/;fi
if [ ! -e $temp_f/corrected_files/ ]; then mkdir $temp_f/corrected_files/;fi #27/11/2018

date +%Y-%m-%d\ %Hh%Mm%Ss > /dev/shm/${ts}_all_analyses_start_timestamp.txt







#================================================================================================================================================
#FUNCTIONS
#================================================================================================================================================

#Calculates the time in hours, minutes and seconds between the creation of 2 files
#If 2 parameters received then:
	#$1=file 1 (older)
	#$2= file 2 (more recent)
#If only one parameter reveived, then:
	#$1=duration in seconds

function fnct_calc_time_between_2_files {
	if [ -z $2 ] #If only one parameter, then age_hd calculated from a duration in seconds
	then 
		age_hd=$(echo "scale=10;$1/3600"|bc)
	else		#Else, age_hd is calculated from the substraction of ages (in seconds, since Jan 1, 1970) of 2 files
		age_hd=$(echo "scale=10;($(stat -c %Z $2)-$(stat -c %Z $1))/3600"|bc)				#time in hours, with decimals, e.g.		.3808333333
	fi
	age_h=$(echo $age_hd|awk '{printf "%02d\n", int($1)}')								#time in hours, integer, e.g.			0
	age_lt60md=$(echo "scale=10;($age_hd-$age_h)*60"|bc)								#remaining minutes, with decimals, e.g.	22.8499999980
	age_lt60m=$(echo $age_lt60md|awk '{printf "%02d\n", int($1)}')							#remaining minutes, integer, e.g.		22
	age_lt60sd=$(echo "scale=10;($age_lt60md-$age_lt60m)*60"|bc)						#remaining seconds, with decimals, e.g.	50.9999998800
	age_lt60s=$(echo $age_lt60sd|awk '{printf "%02d\n", int($1)}')							#remaining seconds, integer, e.g.		50
	age_string="${age_h}h:${age_lt60m}m:${age_lt60s}s"								#string representing the duration, e.g.	00h:22m:50s

	echo $age_string
}


#If file with current sample ring error messages (/dev/shm/current_sample_ring_error_messages.txt) exists
#...concatenate all error/warning codes on a single line and add them to samples_errors_and_warnings.txt
#Parameters (none):
function fnct_write_warning_and_errors_to_stats_files {
#--------------------------------------------------------------------------------				
if [ -s /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt ]
	then
		#Generate the summary for the whole sample, using the /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt file.
		error_codes_concat_per_sample=""
		for error_code in $(cut -f3 /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt|sort -u)
		do
			#If error code is "E", bring attention
			if [ ${error_code:0:1} == "E" ];then warning_signal="***";else warning_signal="";fi

			#If not yet any error messages, create 
			if [ -z "${error_codes_concat_per_sample}" ]
			then
				error_codes_concat_per_sample=$(printf "${warning_signal}${error_code}${warning_signal} ($(awk -F"\t" -v ec=${error_code} '{if ($3 == ec) print $2}' /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt |sort -n|perl -pe 's/\n/,/g'|perl -pe 's/,$/\n/g'))")
			else #add to
				error_codes_concat_per_sample="${error_codes_concat_per_sample}, $(printf "${warning_signal}${error_code}${warning_signal} ($(awk -F"\t" -v ec=${error_code} '{if ($3 == ec) print $2}' /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt |sort -n|perl -pe 's/\n/,/g'|perl -pe 's/,$/\n/g'))")"
			fi
				
		done

		#echo $error_codes_concat_per_sample
		
		printf "...Ring errors/warnings: ${error_codes_concat_per_sample}.\n" >> ${temp_f}/logs_and_summaries/samples_errors_and_warnings.txt
		#Example:
		#samples_errors_and_warnings.txt
		#	F114		F 114.dat	...Ring errors/warnings: W8f (14), W8r (15), W9 (1,2,3,4,6,7,8,9,10,15).
		#	F134		F 134.dat	...Ring errors/warnings: ***E11*** (4,5).
		
		
		#Add these sample ring errors to ${temp_f}/logs_and_summaries/intermediate/rings_errors_and_warnings.txt
		sort -k2,2n -k3,3 /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt >> ${temp_f}/logs_and_summaries/intermediate/rings_errors_and_warnings.txt
		#Example:
		#rings_errors_and_warnings.txt
		#	F114	1	W9	2 transition points were found within the ring. Only the last transition found (nearer the ring end) was kept (multiple_transitions_option=1).
		#	F114	14	W8f	Ring 14 end pos (3.60) differs from ring 15 start pos (3.56)
		#	F114	15	W8r	Ring 15 start pos (3.56) differs from ring 14 end pos (3.60)
		#	F114	15	W9	2 transition points were found within the ring. Only the last transition found (nearer the ring end) was kept (multiple_transitions_option=1).
	
	else
		printf "...Ok.\n" >> ${temp_f}/logs_and_summaries/samples_errors_and_warnings.txt
	fi

}


#Function du calculate median value from a SINGLE-COLUMN file.
#	The file DOESN'T NEED TO BE SORTED, it will be sorted below.
#Parameter:
#	1. file path
function fnct_get_median_value {
#--------------------------------------------------------------------------------
filepath=$1

values_count=$(cat ${filepath}|wc -l) #Number of values
	
#Line at which the first value will be used to calculate median value (even number of values), or will become the median value itself (odd number of values).
#Note: if number of lines is even, will start exactly at number of lines/2 (e.g. 20 ---> 10), if odd, will start at rounded up value of lines/2 (e.g. 5/2 =2.5 ---> 3)
starting_line=$(echo "scale=1;${values_count}/2"|bc|awk '{printf("%d\n",$1 + 0.5)}')
let ending_line=starting_line+1 #2nd value read line in case of even number of reads
starting_line_value=$(sort -n ${filepath}|sed -n ${starting_line}p) #First value read
ending_line_value=$(sort -n ${filepath}|sed -n ${ending_line}p) #Second value read (needed only in case of even number of reads)

#Calculate median value		
if [ $((values_count%2)) -eq 0 ]
then #$((values_count%2)) = 0 ===> even
	#echo "pair"
	median_value=$(echo "scale=3;(${starting_line_value}+${ending_line_value})/2"|bc)
	
else #$((values_count%2)) = 1 ===> odd
	#echo "impair"
	median_value=${starting_line_value}
fi

}



#START OF LOGGING
{


#================================================================================================================================================
#MAIN PROGRAM
#================================================================================================================================================


#File header tags
dat_file_data_tag="\[SAMPLE DATA\]"
dat_file_parameters_tag="\[SAMPLE PARAMETERS\]"


#No longer used (30/6/2016): sum_file_header_tag="^Study"

#Create a file to log results per sample.
#------------------------------------------------------------------------------------------------------------
printf "name\t.dat file\tcomments\n------\t---------\t----------------\n" > ${temp_f}/logs_and_summaries/samples_errors_and_warnings.txt


#Script launch line
#------------------------------------------------------------------------------------------------------------
printf "${blue_color}Script to calculate early- to late-wood transitions from densitometry (.dat and .sum) files.\n"
printf "Created Feb. 8, 2016, S. Clément.\n"
printf "Current version: $0 (${version})${normal_color}\n\n"

#List .dat/.sum files in specified directory.
#------------------------------------------------------------------------------------------------------------
#NOTE: in the future, use find, to have all files in sub-folders as well.
printf "Listing all .dat and .sum files..."
ls -1 ./${infiles_folder}|grep '\.dat$' > /dev/shm/${ts}_dat_files.txt
ls -1 ./${infiles_folder}|grep '\.sum$' > /dev/shm/${ts}_sum_files.txt
printf "done.\n"


#Check that sample names are present in equivalency table (NEW: 26/11/2018)
#------------------------------------------------------------------------------------------------------------
printf "Checking that all sample names from .dat files are in '${eq_list}' file..."

#List any sample from .dat files not found in the eq list
join -t $'\t' -v1 <(perl -pe 's/\.dat//g' /dev/shm/${ts}_dat_files.txt|sort) <(sort -k1,1 ${eq_list}) > /dev/shm/${ts}_samples_not_in_eq_list.txt

#If that file is not empty, then 
if [ -s /dev/shm/${ts}_samples_not_in_eq_list.txt ]
then
	printf "\n${red_color}There are some samples from .dat files that are NOT in the equivalency table:\n"
	perl -pe 's/^/\t/g' /dev/shm/${ts}_samples_not_in_eq_list.txt
	printf "ABORTING${normal_color}\n"
	exit
fi
printf "done.\n"

printf "All $(cat /dev/shm/${ts}_dat_files.txt|wc -l) sample were found in '${eq_list}'\n"


#List of dat files without a corresponding sum file
#------------------------------------------------------------------------------------------------------------
printf "Checking that each .dat file has a corresponding .sum file and vice-versa..."
join -t $'\t' <(perl -pe 's/\.dat//g' /dev/shm/${ts}_dat_files.txt|sort) <(perl -pe 's/\.sum//g' /dev/shm/${ts}_sum_files.txt|sort) -v1 > /dev/shm/${ts}_dat_files_wo_sum_files.txt
#List of sum files without a correspondind dat file
join -t $'\t' <(perl -pe 's/\.dat//g' /dev/shm/${ts}_dat_files.txt|sort) <(perl -pe 's/\.sum//g' /dev/shm/${ts}_sum_files.txt|sort) -v2 > /dev/shm/${ts}_sum_files_wo_dat_files.txt

#If there are .dat files without .sum files
#------------------------------------------------------------------------------------------------------------
if [ -s /dev/shm/${ts}_dat_files_wo_sum_files.txt ]
then
	printf "${red_color}\nWARNING: there are .dat files without the corresponding .sum files:${normal_color}\n\n"
	cat /dev/shm/${ts}_dat_files_wo_sum_files.txt|perl -pe 's/^(.+)/\t\1.dat/g'
	printf "\t${red_color}***ABORTED***${normal_color}\n"
	exit
fi

#If there are .sum files without .dat files
#------------------------------------------------------------------------------------------------------------
if [ -s /dev/shm/${ts}_sum_files_wo_dat_files.txt ]
then
	printf "${red_color}\nWARNING: there are .sum files without the corresponding .dat files:${normal_color}\n\n"
	cat /dev/shm/${ts}_sum_files_wo_dat_files.txt|perl -pe 's/^(.+)/\t\1.sum/g'
	printf "\t${red_color}***ABORTED***${normal_color}\n"
	exit
fi
printf "done\n"


#List .dat files WITHOUT the [SAMPLE DATA] header (Added: 7/7/2016)
#------------------------------------------------------------------------------------------------------------
#Corrected 20/9/2017 to add $ at the end of grep ".dat", because it would grab any path name having dat within. This new way, only the end of the full path is considered, that is, the extension of the file.
printf "Checking that all .dat files have the [SAMPLE DATA] header..."

#[21/9/2017]More logical way of approchaing the search: 1) find .dat files 2) list those without the header tag
find ./${infiles_folder} -type f -iregex ".*.dat" -exec grep -EL "${dat_file_data_tag}" {} \;|awk -F "/" '{print $NF}'|sort > /dev/shm/${ts}_dat_files_wo_data_headers.txt
number_of_dat_files_wo_data_header=$(cat /dev/shm/${ts}_dat_files_wo_data_headers.txt|wc -l)


#echo $number_of_dat_files_wo_data_header
#exit


#If there are files w/o data headers, warn and exit
if [ ${number_of_dat_files_wo_data_header} -gt 0 ]
then
	printf "${red_color}\nWARNING: there are ${number_of_dat_files_wo_data_header} .dat files without the ${dat_file_data_tag} header:${normal_color}\n\n"
	cat /dev/shm/${ts}_dat_files_wo_data_headers.txt|perl -pe 's/^/\t/g'
	printf "\t${red_color}***ABORTED***${normal_color}\n"
	exit
fi
printf "done\n"



#[New: 21/9/2017] Check for files with replicated headers in .dat files
#------------------------------------------------------------------------------------------------------------
printf "Checking that .dat files have no more than one [SAMPLE DATA] header..."
find ./${infiles_folder} -type f -iregex ".*.dat" -exec grep -EH "${dat_file_data_tag}" {} \;|perl -pe 's/dat:.+/dat/g'|awk -F "/" '{print $NF}'|uniq -dc|perl -pe 's/^ +(\d+) (\S+)/\2\t\1/g'|sort -k1,1 > /dev/shm/${ts}_dat_files_w_rep_headers.txt
number_of_dat_files_w_rep_header=$(cat /dev/shm/${ts}_dat_files_w_rep_headers.txt|wc -l)
if [ ${number_of_dat_files_w_rep_header} -gt 0 ]
then
	printf "${red_color}\nWARNING: there are ${number_of_dat_files_w_rep_header} .dat files with several ${dat_file_data_tag} headers:${normal_color}\n\n"
	cat /dev/shm/${ts}_dat_files_w_rep_headers.txt|perl -pe 's/^/\t/g'
	printf "\t${red_color}***ABORTED***${normal_color}\n"
	exit
fi
printf "done\n"

#exit


#List .dat files WITHOUT the [SAMPLE PARAMETERS] header (Added: 22/11/2018)
#------------------------------------------------------------------------------------------------------------

printf "Checking that all .dat files have the [PARAMETERS DATA] header..."
find ./${infiles_folder} -type f -iregex ".*.dat" -exec grep -EL "${dat_file_parameters_tag}" {} \;|awk -F "/" '{print $NF}'|sort > /dev/shm/${ts}_dat_files_wo_param_headers.txt
number_of_dat_files_wo_param_header=$(cat /dev/shm/${ts}_dat_files_wo_param_headers.txt|wc -l)


#If there are files w/o parameters headers, warn and exit
if [ ${number_of_dat_files_wo_param_header} -gt 0 ]
then
	printf "${red_color}\nWARNING: there are ${number_of_dat_files_wo_param_header} .dat files without the ${dat_file_parameters_tag} header:${normal_color}\n\n"
	cat /dev/shm/${ts}_dat_files_wo_param_headers.txt|perl -pe 's/^/\t/g'
	printf "\t${red_color}***ABORTED***${normal_color}\n"
	exit
fi
printf "done\n"


#dos2unix all .dat and .sum files (NEW: 23/11/2018)
#------------------------------------------------------------------------------------------------------------
#Note: it is required before analysing the contents of the files, like getting the .dat parameters below.
printf "Converting the files EOL to Unix format..."
dos2unix ${infiles_folder}/*.dat 2> /dev/null
dos2unix ${infiles_folder}/*.sum 2> /dev/null
printf "done\n"


#Get parameters from all .dat files (New: 23/11/2018)
#------------------------------------------------------------------------------------------------------------
printf "Extracting parameters from all .dat files..."
for parameter in $(seq 0 $(echo "scale=0;${#parameters_to_keep[@]}-1"|bc))
do 
	printf "."
	#For some parameters containing slashes (e.g. "Time/Date of Scan"), void the slash for the perl regexp replace below
	param_voided_slashes=$(echo ${parameters_to_keep[$parameter]}|perl -pe 's/\//\\\//g')

	#Extract the current parameter's column values (new 27/11/2018) and add the "file" and parameter name as headers
	#a. extract lines matching that parameter's name, echa line being made of the filename, the parameter and its value (grep -r "^${parameters_to_keep[$parameter]}," ${infiles_folder}/*.dat)
	#	test/14.dat:Description,                E560A3 1 169 2 14
	#	test/2.dat:Description,                E560A3 1 32 4 2
	#	test/57.dat:Description,                E560A3 2 170 4 57
	#b. Remove the parameter name (perl -pe "s/(^.+):${param_voided_slashes}, +/\1\t/g")
	#	test/14.dat     E560A3 1 169 2 14
	#	test/2.dat      E560A3 1 32 4 2
	#	test/57.dat     E560A3 2 170 4 57
	#c. Remove the prefixing path (perl -pe 's/^.+\/(.+)\t/\1\t/g')
	#	14.dat  E560A3 1 169 2 14
	#	2.dat   E560A3 1 32 4 2
	#	57.dat  E560A3 2 170 4 57
	#d. Add the header
	#	file    Description
	#	14.dat  E560A3 1 169 2 14
	#	2.dat   E560A3 1 32 4 2
	#	57.dat  E560A3 2 170 4 57
	
	#Note: any parameter not found in the files will result in the "file    parameter_name" line in the file.
	grep -rH "^${parameters_to_keep[$parameter]}," ${infiles_folder}/*.dat|perl -pe "s/(^.+):${param_voided_slashes}, +/\1\t/g"|perl -pe 's/^.+\/(.+)\t/\1\t/g'|cat <(printf "file\t${parameters_to_keep[$parameter]}\n") - > /dev/shm/${ts}_dat_parameters_2_cols.txt

	#Check if there are mistakenly inserted tabs after parameter values, which will result in > 2 columns after parameter extraction [2019-07-12]
	awk -F "\t" '{if (NF > 2) print}' /dev/shm/${ts}_dat_parameters_2_cols.txt|cat -A > /dev/shm/${ts}_dat_parameters_extra_tabs.txt
	if [ -s /dev/shm/${ts}_dat_parameters_extra_tabs.txt ]
	then
		printf "${red_color}\nWARNING: there are .dat files with extra tabulations after the '${parameters_to_keep[$parameter]}' parameter value:\n"
		perl -pe 's/^/\t/g' /dev/shm/${ts}_dat_parameters_extra_tabs.txt
		printf "These .dat files must be corrected before running the script again.\n"
		printf "\t***ABORTED***${normal_color}\n"
		exit
	fi
	
	#If column is the date, convert to proper format and add this as a separate column (NEW: 28/11/2018)
	if [ "${parameters_to_keep[$parameter]}" == "Time/Date of Scan" ]
	then
		cut -f2 -d $'\t' /dev/shm/${ts}_dat_parameters_2_cols.txt|tail -n+2|perl -pe 's/ +/\t/g'|cut -f1 -d $'\t'|awk '{print "date -d\""$0"\" +%Y-%m-%d"}'|bash > /dev/shm/${ts}_parameters_all_dates.txt
		cat <(printf "Date\n") /dev/shm/${ts}_parameters_all_dates.txt| paste /dev/shm/${ts}_dat_parameters_2_cols.txt - > /dev/shm/${ts}_dat_parameters_3_cols.txt
		mv /dev/shm/${ts}_dat_parameters_3_cols.txt /dev/shm/${ts}_dat_parameters_2_cols.txt
	fi

	#If column is operators (NEW: 28/11/2018)
	if [ "${parameters_to_keep[$parameter]}" == "Operator" ]
	then
		#Extract all distinct names from .dat files
		cut -f2 -d $'\t' /dev/shm/${ts}_dat_parameters_2_cols.txt|tail -n+2|tr '[:upper:]' '[:lower:]'|sort -u > /dev/shm/${ts}_distinct_operators.txt
		#csimard
		#jflegare
		#vseigner
		
		#If there are empty names in .dat files
		if [ $(perl -pe 's/ //g' /dev/shm/${ts}_distinct_operators.txt|grep '^$'|wc -l) -gt 0 ]
		then
			awk -F "\t" '{if ($2 == "" || $2 ~ /^ +$/) print $1}' /dev/shm/${ts}_dat_parameters_2_cols.txt > /dev/shm/${ts}_files_wo_operators.txt
			
			printf "${red_color}\nWARNING: there are empty operator names in .dat files!\n"
			perl -pe 's/^/\t/g' /dev/shm/${ts}_files_wo_operators.txt
			printf "\t***ABORTED***${normal_color}\n"
			exit	
		#NOTE: in the future, could replace all empty values with a reference name.
		
		fi
		
		
		#Check if operators extracted from .dat files are in refeference list (created at the beginning under the VARIABLES section)
		#Search for exclusive names from .dat files vs ref list
		#Line before 2023-03-17: join -t $'\t' -i -v1 /dev/shm/${ts}_distinct_operators.txt /dev/shm/${ts}_operators_ref_list.txt > /dev/shm/${ts}_operators_NOT_in_ref_list.txt
		join -t $'\t' -i -v1 /dev/shm/${ts}_distinct_operators.txt <(sort -k1,1 /dev/shm/${ts}_operators_ref_list.txt) > /dev/shm/${ts}_operators_NOT_in_ref_list.txt
		
		#If there are exclusive, warn to add to the array and quit.
		if [ -s /dev/shm/${ts}_operators_NOT_in_ref_list.txt ]
		then 
			printf "${red_color}\nWARNING: there are operator names in .dat files that are absent from the reference names:\n"
			cat /dev/shm/${ts}_operators_NOT_in_ref_list.txt|perl -pe 's/^/\t/g'
			printf "\tPlease add these names to the associative array \"operators_abbrev_fullname\" and restart the script.\n"
			printf "\t***ABORTED***${normal_color}\n"
			exit
		fi
		
		
		#All were found in ref list of names
		#Add the full name to the list of columns
		#Line before 2023-03-17: join -t $'\t' -i <(awk -F "\t" '{print $2"\t"$0}' /dev/shm/${ts}_dat_parameters_2_cols.txt|sort -k1,1) /dev/shm/${ts}_operators_ref_list.txt|cut -f1 -d $'\t' --complement|sort -k1,1|cat <(printf "file\tOperator\tOp_fullname\n") - > /dev/shm/${ts}_dat_parameters_3_cols.txt
		join -t $'\t' -i <(awk -F "\t" '{print $2"\t"$0}' /dev/shm/${ts}_dat_parameters_2_cols.txt|sort -k1,1) <(sort -k1,1 /dev/shm/${ts}_operators_ref_list.txt)|cut -f1 -d $'\t' --complement|sort -k1,1|cat <(printf "file\tOperator\tOp_fullname\tOp_team_id\n") - > /dev/shm/${ts}_dat_parameters_3_cols.txt
		mv /dev/shm/${ts}_dat_parameters_3_cols.txt /dev/shm/${ts}_dat_parameters_2_cols.txt
		
		#exit
		#echo
		#echo "Parameter# $parameter" 
		#echo "---------------------"
		#head  /dev/shm/${ts}_dat_parameters_2_cols.txt
		#cp /dev/shm/${ts}_dat_parameters_2_cols.txt ${temp_f}/operators.txt
		#exit
	fi


	#If it is the first parameter to search...
	if [ $parameter -eq 0 ]
	then # ...create the file
		 cp /dev/shm/${ts}_dat_parameters_2_cols.txt /dev/shm/${ts}_dat_parameters.txt
	else	#...append to existing file.

		#Using a left join, then filling any lines with missing columns
		#a. Left join
		join -t $'\t' -a 1 <(sort -k1,1 /dev/shm/${ts}_dat_parameters.txt) <(sort -k1,1 /dev/shm/${ts}_dat_parameters_2_cols.txt) > /dev/shm/${ts}_dat_parameters_temp.txt
		
		#b. keep header in a separate file
		grep '^file[[:space:]]' /dev/shm/${ts}_dat_parameters_temp.txt > /dev/shm/${ts}_dat_parameters_temp_header.txt
		
		#c. remove header and put results in another file
		#Line before 2023-03-15: grep -v '^file[[:space:]]' /dev/shm/${ts}_dat_parameters_temp.txt > /dev/shm/${ts}_dat_parameters_temp_wo_header.txt
		#2023-03-15: add -a option to prevent the occasional "Binary file" error from grep when it encounters accents.
		grep -va '^file[[:space:]]' /dev/shm/${ts}_dat_parameters_temp.txt > /dev/shm/${ts}_dat_parameters_temp_wo_header.txt
				
		#b. count max number of columns
		max_colcount=$(awk -F "\t" '{print NF}' /dev/shm/${ts}_dat_parameters_temp.txt|sort -n|tail -1)
		
		#c. fill lines (uniformize) having less columns than the max with the appropriate number of tabs
		awk -v maxcc=${max_colcount} 'BEGIN { FS = OFS = "\t" } { str=""; for (i=1; i<=(maxcc-NF); i++) str=str"\t" }; {print $0 str}' /dev/shm/${ts}_dat_parameters_temp_wo_header.txt > /dev/shm/${ts}_dat_parameters_temp_uc.txt
		cat /dev/shm/${ts}_dat_parameters_temp_header.txt /dev/shm/${ts}_dat_parameters_temp_uc.txt > /dev/shm/${ts}_dat_parameters.txt
		
		#echo
		#echo "Parameter# $parameter" 
		#echo "---------------------"
		#head  /dev/shm/${ts}_dat_parameters.txt
		
	fi



done
mv /dev/shm/${ts}_dat_parameters.txt ${temp_f}/logs_and_summaries/intermediate/dat_parameters.txt
printf "done\n"

#file	Time/Date of Scan	Date	Sample ID	Study Name	Operator	Op_fullname	Op_team_id	Description	Is pith present	Commentaires	No. pith rings missing	Sample moisture content
#E60-A-1-002-7-186.dat	26-Jul-2019   14:12:13	2019-07-26	186	E60-A-1-002-7-186	CSIMARD	Christine Simard	106	2012-11 passent pas	Yes		0	8.00
#E60-A-1-005-4-001.dat	19-Jul-2019   13:51:32	2019-07-19	001	E60-A-1-005-4-001	CSIMARD	Christine Simard	106	2017 passe pas, commence en 2016	Yes		0	8.00
#E60-A-1-010-2-314.dat	04-Apr-2019   13:28:43	2019-04-04	314	E60-A-1-010-2-314	JFLegare	Jean-François Légaré	110		Yes		0	8.00
#E60-A-1-010-5-317.dat	04-Apr-2019   15:35:22	2019-04-04	317	E60-A-1-010-5-317	JFLegare	Jean-François Légaré	110		Yes		0	8.00
#E60-A-1-010-6-604.dat	29-May-2019   13:59:33	2019-05-29	604	E60-A-1-010-6-604	CSIMARD	Christine Simard	106	2017-2015 passent pas, commence en 2014	Yes		0	8.00
#E60-A-2-003-7-120.dat	24-Jul-2019   18:16:54	2019-07-24	120	E60-A-2-003-7-120	CSIMARD	Christine Simard	106	2011-2006 passent pas, commence en 2005	Yes		0	8.00
#E60-A-2-006-4-215.dat	14-Sep-2018   16:46:51	2018-09-14	215	E60-A-2-006-4-215	CSIMARD	Christine Simard	106		Yes		0	8.00


#Extract distinct values from  parameters (New: 27/11/2018)
#------------------------------------------------------------------------------------------------------------
printf "Extracting meaningful values from .dat files parameters..."

#List all columns from file (NEW: 28/11/2018)
head -1 ${temp_f}/logs_and_summaries/intermediate/dat_parameters.txt|perl -pe 's/\t/\n/g'|cat -n > /dev/shm/${ts}_params_columns.txt
#    1  file
#     2  Time/Date of Scan
#     3  Date
#     4  Sample ID
#     5  Study Name
#     6  Operator
#     7  Op_fullname
#     8  Op_team_id
#     9  Description
#    10  Is pith present
#    11  Commentaires
#    12  No. pith rings missing
#    13  Sample moisture content

    
#Dates (NEW: 28/11/2018)
sort -u /dev/shm/${ts}_parameters_all_dates.txt > ${temp_f}/logs_and_summaries/intermediate/distinct_scan_dates.txt

#Opérateurs distincts dans les .dat files, mis tous à la chaîne. Sera utilisé pour le rapport final.
operators=$(perl -pe 's/\n/, /g' /dev/shm/${ts}_distinct_operators.txt|perl -pe 's/, $/\n/g')


#Échantillons avec commentaires, statut de moëlle , et nombre de cernes enlevés côté moëlle

#Get the field positions (NEW: 28/11/2018)
#Note: filename is always #1
date_col=$(awk -F "\t" '{if(tolower($2) ~ "^date$") print $1}' /dev/shm/${ts}_params_columns.txt|perl -pe 's/ //g')
operator_col=$(awk -F "\t" '{if(tolower($2) ~ "op_fullname") print $1}' /dev/shm/${ts}_params_columns.txt|perl -pe 's/ //g')
#[NEW 2023-03-17]:
operator_team_id_col=$(awk -F "\t" '{if(tolower($2) ~ "op_team_id") print $1}' /dev/shm/${ts}_params_columns.txt|perl -pe 's/ //g')
description_col=$(awk -F "\t" '{if(tolower($2) ~ "^description") print $1}' /dev/shm/${ts}_params_columns.txt|perl -pe 's/ //g')
is_pith_present_col=$(awk -F "\t" '{if(tolower($2) ~ "^is pith present") print $1}' /dev/shm/${ts}_params_columns.txt|perl -pe 's/ //g')
comments_col=$(awk -F "\t" '{if(tolower($2) ~ "^commentaire") print $1}' /dev/shm/${ts}_params_columns.txt|perl -pe 's/ //g')
pith_rings_missing_col=$(awk -F "\t" '{if(tolower($2) ~ "^no. pith rings missing") print $1}' /dev/shm/${ts}_params_columns.txt|perl -pe 's/ //g')
mc_col=$(awk -F "\t" '{if(tolower($2) ~ "^sample moisture") print $1}' /dev/shm/${ts}_params_columns.txt|perl -pe 's/ //g')

#Create a file containing the sample name, the date, operator team id, is_pith_present, missing_pith_rings, comments
#Line before 25/6/2019: awk -F "\t" -v v_date=${date_col} -v v_op=${operator_col} -v v_desc=${description_col} -v v_pith=${is_pith_present_col} -v v_missrings=${pith_rings_missing_col} '{if ($v_desc != "") print $1"\t"$v_date"\t"$v_op"\t"$v_pith"\t"$v_missrings"\t"$v_desc; else print $1"\t"$v_date"\t"$v_op"\t"$v_pith"\t"$v_missrings"\t\\N"}' ${temp_f}/logs_and_summaries/intermediate/dat_parameters.txt|perl -pe 's/\.dat//g' > /dev/shm/${ts}_dat_params_temp.txt
#[Corrected 25/6/2019]: now includes the "Commentaires" columns, and no longer includes the condition to check for each line if a column is missing, because missing columns are now filled with \t above.
#Line before 2023-03-17: awk -F "\t" -v v_date=${date_col} -v v_op=${operator_col} -v v_desc=${description_col} -v v_pith=${is_pith_present_col} -v v_comments=${comments_col} -v v_missrings=${pith_rings_missing_col} '{print $1"\t"$v_date"\t"$v_op"\t"$v_pith"\t"$v_missrings"\t"$v_desc"\t"$v_comments}' ${temp_f}/logs_and_summaries/intermediate/dat_parameters.txt|perl -pe 's/\.dat//g' > /dev/shm/${ts}_dat_params_temp.txt
awk -F "\t" -v v_date=${date_col} -v v_op=${operator_col} -v v_op_ti=${operator_team_id_col} -v v_desc=${description_col} -v v_pith=${is_pith_present_col} -v v_comments=${comments_col} -v v_missrings=${pith_rings_missing_col} '{print $1"\t"$v_date"\t"$v_op"\t"$v_op_ti"\t"$v_pith"\t"$v_missrings"\t"$v_desc"\t"$v_comments}' ${temp_f}/logs_and_summaries/intermediate/dat_parameters.txt|perl -pe 's/\.dat//g' > /dev/shm/${ts}_dat_params_temp.txt

#for test
#cp /dev/shm/${ts}_dat_params_temp.txt ${temp_f}/${ts}_dat_params_temp.txt
#head /dev/shm/${ts}_dat_params_temp.txt
#exit

#Keep the header
head -1 /dev/shm/${ts}_dat_params_temp.txt > /dev/shm/${ts}_dat_params_temp_header.txt

#Add germplasm_id and data_source_id columns from equivalency list ($eq_list)
join -t $'\t' <(sort -k1,1 /dev/shm/${ts}_dat_params_temp.txt) <(sort -k1,1 $eq_list)|cat <(paste /dev/shm/${ts}_dat_params_temp_header.txt <(printf "germplasm_id\tdata_source_id\tgrowth_year\tharvested_in_growing_season\n")) - > ${temp_f}/logs_and_summaries/intermediate/samples_info_from_dat_parameters.txt

#samples_info_from_dat_parameters.txt
#file	Date	Op_fullname	Op_team_id	Is pith present	No. pith rings missing	Description	Commentaires	germplasm_id	data_source_id	growth_year	harvested_in_growing_season
#E60-A-1-002-7-186	2019-07-26	Christine Simard	106	Yes	0	2012-11 passent pas		954371	627	2017	t
#E60-A-1-005-4-001	2019-07-19	Christine Simard	106	Yes	0	2017 passe pas, commence en 2016		954372	627	2017	t

#exit


#Taux d'humidité - en théorie un seul, parfois plusieurs!
	#a) dans un fichier, arrondi à l'unité  [2019-07-12]
	tail -n+2 ${temp_f}/logs_and_summaries/intermediate/dat_parameters.txt|cut -f${mc_col} -d $'\t'|sort -un|awk '{printf "%.*f\n", 0, $1}' > ${temp_f}/logs_and_summaries/intermediate/distinct_mc.txt
	#8
	#12

	#b) dans une variable, séparés par des virgules [2019-07-12]
	#sample_moisture_contents=$(tail -n+2 ${temp_f}/logs_and_summaries/intermediate/dat_parameters.txt|cut -f${mc_col} -d $'\t'|sort -u|perl -pe 's/\n/, /g'|perl -pe 's/, $/\n/g')
	sample_moisture_contents=$(perl -pe 's/\n/, /g' ${temp_f}/logs_and_summaries/intermediate/distinct_mc.txt|perl -pe 's/, $/\n/g')
	#8, 12

printf "done\n"


#exit

#Check the number of columns in each .dat file (New version: 23/11/2018, 2022-04-06)
#------------------------------------------------------------------------------------------------------------
printf "Checking .dat files number of columns of data..."

#For all concatenated .dat files, list the possible number of columns for the data section, and the number of rows for each found number of columns. In theory, all files should have the same number of columns, hence 1 row in the file.
cat ${infiles_folder}/*.dat|sed "/^${dat_file_parameters_tag}/,/^${dat_file_data_tag}/{d;}"|grep -v '^$'|awk -F ${dat_fs} '{print NF}'|sort|uniq -c|perl -pe 's/^ +(\d+) (\d+)/\2\t\1/g'|sort -k2,2n > /dev/shm/${ts}_temp_dat_column_counts.txt
#Example 1:
#6	3005

#Example 2
#4       1375
#2       3275


#Check if number of columns is consistent [NEW 2022-04-06]
#[2022-04-07]: now a simple warning, because in some projects (e.g. FastTRAC2 Matapedia/Robidoux), most .dat files have 4 columns, but some (e.g. 522.dat, 550.dat) have only two.
#	2 columns of data (position and density) are now accepted.
if [ $(cat /dev/shm/${ts}_temp_dat_column_counts.txt|wc -l) -gt 1 ]
then
	printf "${yellow_color}\nWARNING: the number of columns in .dat files is inconsistent:\n"
	printf "\tcolumns\tNb of lines\n"
	head -10 /dev/shm/${ts}_temp_dat_column_counts.txt|perl -pe 's/^/\t/g'
	#printf "\n\tSee the /dev/shm/${ts}_temp_dat_column_counts.txt file for details.\n" # No, deleted along with other temporary files.
	printf "${normal_color}\n"
	#printf "\t${red_color}***ABORTED***${normal_color}\n"
	#exit
fi

#For testing ONLY [2022-04-07]
#See the different formats in each column throughout ALL .dat files combined:
#	dos2unix ${infiles_folder}/*.dat
#	cat ${infiles_folder}/*.dat|sed "/^${dat_file_parameters_tag}/,/^${dat_file_data_tag}/{d;}"|perl -pe 's/"//g'|perl -pe 's/[ \t]+//g'|perl -pe 's/,/\t/g'|grep -v '^$' > /dev/shm/all_dat_files_data_cleaned.txt
#	Column 1 (usually position):
#	cut -f1 /dev/shm/all_dat_files_data_cleaned.txt| perl -pe 's/\d/0/g'|sort -u 
#		0.000
#		00.000
#	Column 2 (usually density)
#	cut -f2 /dev/shm/all_dat_files_data_cleaned.txt| perl -pe 's/\d/0/g'|sort -u 
#		0.00
#		00.00
#		000.00
#		0000.00
#	Column 3 (usually ring number)
#	cut -f3 /dev/shm/all_dat_files_data_cleaned.txt| perl -pe 's/\d/0/g'|sort -u 
#		0
#		-0
#		00
#	Column 4 (usually wood type)
#	cut -f3 /dev/shm/all_dat_files_data_cleaned.txt| perl -pe 's/\d/0/g'|sort -u 
#		E
#		L
#		N


#[20220406]: 
#If a check of the number of columns is required to ensure they meet ${dat_file_data_cols}
#The cat below is LOOONG, that's why we set this as an option
if [ ${check_for_expected_nb_of_columns} -ne 0 ]
then
	#Line before 2022-04-06: if [ $(cat /dev/shm/${ts}_temp_dat_column_counts.txt|wc -l) -ne 1 ] : this was incorrect because triggered only when the number of columns were inconsistent, not necessarily when they differed from the expected number from ${dat_file_data_cols}
		
	#List the files and number of lines where the number of columns in data is <> than the one specified in dat_file_data_cols
	cat ${infiles_folder}/*.dat|sed "/^${dat_file_parameters_tag}/,/^${dat_file_data_tag}/{d;}"|grep -v '^$'|awk -F ${dat_fs} -v refcolcount=${dat_file_data_cols} '{if (NF != refcolcount) print}'|grep -r ${infiles_folder}/*.dat -f -|awk -F ":" '{print $1}'|awk -F "/" '{print $NF}'|sort|uniq -c|perl -pe 's/^ +(\d+) (.+)/\2\t\1/g' > /dev/shm/${ts}_dat_files_w_col_problems.txt

	#If such lines exist, warn and exit
	if [ -s /dev/shm/${ts}_dat_files_w_col_problems.txt ]
	then
		#Warn and exit
		printf "${red_color}\nWARNING: there are .dat files with a number of columns in data different than the ${dat_file_data_cols} expected. Here are the first ten:\n"
		head -10 /dev/shm/${ts}_dat_files_w_col_problems.txt|cut -f1 -d $'\t'|perl -pe 's/^/\t/g'
		printf "\n\tSee the /dev/shm/${ts}_dat_files_w_col_problems.txt file for details.\n"
		printf "\tYou might need to change the variable dat_file_data_cols currently set at ${dat_file_data_cols}.\n"
		printf "\t${red_color}***ABORTED***${normal_color}\n"
		exit
	fi
fi
printf "done\n"	

#exit





#Number of .dat/.sum files to be analyzed
#------------------------------------------------------------------------------------------------------------
number_of_dat_sum_files=$(cat /dev/shm/${ts}_dat_files.txt|wc -l)
printf "${number_of_dat_sum_files} .dat and .sum file(s) to be analyzed.\n"


#Create corrected file headers: (added 13/6/2017). Previously, headers were added when every corrected reads and rings file was created.
#Since they're common to all output files, no need to create them everytime
	#reads file
	printf "sample_name\tring_year_sum\tring_no_sum\tpos_dat\tdensity_dat\tring_no_dat\ttransition_dat\tline_no\ttransition\tpos_p2b\n" > /dev/shm/${ts}_header_corr_reads.txt
	#rings file
	printf "sample_name\tring_year\tring_no\tring_start_pos\tring_end_pos\tnumber_of_reads\tring_width\tring_dens_avg\tring_dens_min\tring_dens_max\tring_dens_median\tew_start_pos\tew_end_pos\treads_ew\tew_width\tew_dens_avg\tew_dens_min\tew_dens_max\tew_pct\tlw_start_pos\tlw_end_pos\treads_lw\tlw_width\tlw_dens_avg\tlw_dens_min\tlw_dens_max\tlw_pct\tnote\tring_start_pos_inv\tring_end_pos_inv\tew_start_pos_inv\tew_end_pos_inv\tlw_start_pos_inv\tlw_end_pos_inv\n" > /dev/shm/${ts}_header_corr_ring_stats.txt



printf "Calculating stats:\n=====================\n"


#[2017-06-29] Create the file to store ring error codes and messages for all samples
#------------------------------------------------------------------------------------------------------------
printf "" > ${temp_f}/logs_and_summaries/intermediate/rings_errors_and_warnings.txt

#[2017-09-25] Create the file to list rejected low density reads
#------------------------------------------------------------------------------------------------------------
printf "" > ${temp_f}/logs_and_summaries/intermediate/all_reads_rejected_for_low_density.txt


#[2019-06-18]  Create the file to store invalid rings due to extreme densities for all samples
printf "" > /dev/shm/${ts}_invalid_rings_due_to_extreme_densities.txt

#[2023-03-09]  Create the file to store other invalid rings
printf "" > /dev/shm/${ts}_other_invalid_rings.txt


#[2019-06-25]  Create the SQL UPDATE file for invalid samples
printf "" > ${temp_f}/for_import/SQL_UPDATE_invalid_samples.txt

#[2019-06-27] File to store samples where last year in data is lower than expected
printf "" > ${temp_f}/for_import/last_ring_year_in_densitometry_data.txt

#[2019-06-26] File to store samples which last year in data is newer than expected (=ERROR!)
printf "" > ${temp_f}/logs_and_summaries/intermediate/last_ring_year_in_data_newer_than_harvest_year.txt

#[2019-07-11] File to store samples with incomplete last ring
printf "" > ${temp_f}/logs_and_summaries/intermediate/samples_with_incomplete_last_ring.txt

#[2019-07-12] File to store first rings as pith (invalid rings)
printf "" > /dev/shm/${ts}_pith_rings.txt


#--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#Cycle through all .dat files (all samples)
#--------------------------------------------------------------------------------------------------------------------------------------------------------------------
for datfile in $(cat /dev/shm/${ts}_dat_files.txt)
do
	sample_number+=1
	#[20190625] Reset the number of invalid rings to 0
	current_sample_invalid_rings=0
	
	
	#Create a file listing all ring error messages for the current sample (added: 29/6/2017)
	#The file is recreated for each new sample
	printf "" > /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
	
	
	#Extract prefix and calculate the .sum file name
	file_prefix=$(echo $datfile|perl -pe 's/\.\w+$//g')
	#Sample name = file prefix without spaces
	sample_name=$(echo $file_prefix|tr -d ' ')
	sumfile="${file_prefix}.sum"
	
	
	
	#dos2unix ./${infiles_folder}/$datfile 2> /dev/null #Already done above.
	#dos2unix ./${infiles_folder}/$sumfile 2> /dev/null #Already done above.
	
	printf "${sample_number}/${number_of_dat_sum_files}: ${datfile}\n----------------------------\n"
	
	printf "${sample_name}\t${datfile}\t" >> ${temp_f}/logs_and_summaries/samples_errors_and_warnings.txt 

	#Clean the .dat file
	#--------------------------------------------------------------------
	#1. get data only from after the [SAMPLE DATA] line
	#2. Remove any double quotes
	#3. remove spaces
	#4. Replace commas with tabs
	#	NOTE: all 4 original columns are kept, but only the first 2 (position, density) will be used.
	#5. Remove empty lines (added 13/6/2017)
	#6. [NEW 10/9/2019]: auto-detect type of data
	
	#7. Keep only the following fields, in that order: 1. position; 2. density; 3. ring_no; 4. wood type. [Added 23/11/2018]: because the fields displayed in .dat files may change from lab to lab.
	#Line before 23/11/2018: sed -n -e "/${dat_file_data_tag}/",'$p' ./${infiles_folder}/${datfile}|tail -n+2|perl -pe 's/"//g'|perl -pe 's/[ \t]+//g'|perl -pe 's/,/\t/g'|grep -v '^$' > /dev/shm/${ts}_reads_tmp.txt
	#Line before 10/9/2019: sed -n -e "/${dat_file_data_tag}/",'$p' ./${infiles_folder}/${datfile}|tail -n+2|perl -pe 's/"//g'|perl -pe 's/[ \t]+//g'|perl -pe 's/,/\t/g'|grep -v '^$'|awk -F "\t" -v pos=${col_pos_b2p} -v dens=${col_dens} -v ringno=${col_ringno_p2b} -v wood=${col_wood} '{print $pos"\t"$dens"\t"$ringno"\t"$wood}' > /dev/shm/${ts}_reads_tmp.txt
	
	sed -n -e "/${dat_file_data_tag}/",'$p' ./${infiles_folder}/${datfile}|tail -n+2|perl -pe 's/"//g'|perl -pe 's/[ \t]+//g'|perl -pe 's/,/\t/g'|grep -v '^$' > /dev/shm/${ts}_partly_cleaned_dat.txt
	
	#echo "TEST"
	#echo "-------------------"
	#head /dev/shm/${ts}_partly_cleaned_dat.txt
	#exit
		
		#0.000	0.00	-1	N
		#0.040	5.91	-1	N
		#0.080	0.00	-1	N
		#0.120	0.00	-1	N
		#0.160	1.26	-1	N
		#0.200	0.00	-1	N
		#0.240	0.00	-1	N
		#0.280	1.89	-1	N
	
	#Get the number of columns
	part_cleaned_cols=$(awk -F "\t" '{print NF}' /dev/shm/${ts}_partly_cleaned_dat.txt|sort -u)
	
	
	#[NEW 20210719]: use this method only if automatic mode was selected at line ~876+
	if [ $dat_column_pos_determination_method -eq 2 ]
	then
		#[NEW 2022-04-06]: reset these variables before looking for them. 999 = not found.
		col_pos_b2p=999
		col_dens=999
		col_ringno_p2b=999
		col_wood=999
		
		#[NEW 10/9/2019]: auto-detect type of data
		#Go through each column to check the type of data
		for column in $(seq 1 ${part_cleaned_cols})
		do 
			#For test
			#echo "--------------------"
			#echo $column
			#echo "--------------------"
			
			#[NEW 2023-02-21]: extract current column
			#Note: before 2023-02-21, extracting the column and keeping only the distinct zeroed format was done in a single step below.
			cut -f${column} /dev/shm/${ts}_partly_cleaned_dat.txt > /dev/shm/${ts}_partly_cleaned_dat_curr_col.txt
			
			#[NEW 2023-02-21] Get median value from pre-existing function
			fnct_get_median_value /dev/shm/${ts}_partly_cleaned_dat_curr_col.txt
			#Get the integer for that median value, for the if below (only accepts integers)
			median_value_int=$(echo ${median_value%.*})
			
			#Extract all possible formats after replacing all digits with 0's
			#Line before 2023-02-21: cut -f${column} /dev/shm/${ts}_partly_cleaned_dat.txt|perl -pe 's/\d/0/g'|sort -u > /dev/shm/${ts}_partly_cleaned_dat_curr_col.txt
			perl -pe 's/\d/0/g' /dev/shm/${ts}_partly_cleaned_dat_curr_col.txt|sort -u > /dev/shm/${ts}_partly_cleaned_dat_curr_col_zeroed_formats.txt
			
			
			
			#For test
			#echo "Formats in column ${column}:"
			#perl -pe 's/^/\t/g' /dev/shm/${ts}_partly_cleaned_dat_curr_col_zeroed_formats.txt
			#echo "Median value from function: $median_value"
			#echo "median value int from function: $median_value_int"
		
			#Ex:
			#Read number (often column #1): 
			#	0
			#	00
			#	000
			#	0000
			
			#Read position (mm): 
			#	0.000
			#	00.000
			
			#Density:
			#	0.00
			#	00.00
			#	000.00
			#	0000.00
			
			#Ring number:
			#	0
			#	00
			
			#Wood type:
			#	E
			#	L
			
			#
			
			
			
			#Check the type of data for current column
			
			#Position. Possible formats: 0.000, 00.000
			#If the two formats are present, consider the current column as being the position
			if [ $(grep -E '^0{1,2}\.0{3}$' /dev/shm/${ts}_partly_cleaned_dat_curr_col_zeroed_formats.txt|wc -l) -eq 2 ]
			then 
				#echo "pos"
				col_pos_b2p=${column}
				continue
			#else 
				#echo "not pos"
			fi


			#Density. Possible formats: 0.00, 00.00, 000.00, 0000.00
			#If at least 2 of the above formats are found, consider the current column as being the density
			#2023-02-17: NO! Sometimes, only the 000.00 format is found! That's why we added the condition that the median value integer be above 200.
			if [ $(grep -E '^0{1,4}\.0{2}$' /dev/shm/${ts}_partly_cleaned_dat_curr_col_zeroed_formats.txt|wc -l) -gt 0 ] && [ $median_value_int -gt 200 ]
			then 
				#echo "dens"
				col_dens=${column}
				continue
			#else 
				#echo "not dens"
			fi


			#Ring no. Possible formats: 0, -0, 00
			#If at least 1 of the above formats is found, consider the current column as being the ring number
			if [ $(grep -E '^-?0{1,2}$' /dev/shm/${ts}_partly_cleaned_dat_curr_col_zeroed_formats.txt|wc -l) -gt 0 ]
			then 
				#echo "ringno"
				col_ringno_p2b=${column}
				continue
			#else 
				#echo "not ringno"
			fi
			
			
			#Wood type. Possible formats: E, L, N
			#If at least 1 of the above formats is found, consider the current column as being the wood type
			if [ $(grep -E '^[ELN]$' /dev/shm/${ts}_partly_cleaned_dat_curr_col_zeroed_formats.txt|wc -l) -gt 0 ]
			then 
				#echo "wood type"
				col_wood=${column}
			#else 
				#echo "not wood type"
			fi
			
		done
	
	fi
	
	
	
	#[NEW 2022-04-06]: si certaines colonnes sont absentes, envoyer un avertissement et passer à l'échantillon suivant (position, densité) ou continuer (numéro de cerne, type de bois)
	
	#col_pos_b2p and col_dens SHOULD ALWAYS be present, otherwise abort the sample, go to the next.
	
	#For test
	#echo col_pos_b2p ${col_pos_b2p}
	#echo col_dens ${col_dens}
	#echo col_ringno_p2b ${col_ringno_p2b}
	#echo col_wood ${col_wood}
	
	#exit
	
	
	
	#Position (ESSENTIELLE) - if missing, warn and skip sample
	if [ ${col_pos_b2p} -eq 999 ]
	then
		printf "${red_color}\tE15. The .dat file is missing the POSITION column, which is REQUIRED!\n\tSAMPLE SKIPPED!${normal_color}\n\n"
			
		ring_error_message="The .dat file is missing the POSITION column."
		ring_error_code="E15"
		printf "${sample_name}\tALL\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
			
		#With the command "continue" below, the rest of the "for" loop is skipped to go directly to the next sample
		#Thus, we must write the /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt file to the rings_errors_and_warnings.txt and samples_errors_and_warnings.txt files
		fnct_write_warning_and_errors_to_stats_files
		continue
	fi
	
	#Densité (ESSENTIELLE) - if missing, warn and skip sample
	if [ ${col_dens} -eq 999 ]
	then
		
		exit #*****************************
		printf "${red_color}\tE16. The .dat file is missing the DENSITY column, which is REQUIRED!\n\tSAMPLE SKIPPED!${normal_color}\n\n"
			
		ring_error_message="The .dat file is missing the DENSITY column."
		ring_error_code="E16"
		printf "${sample_name}\tALL\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
			
		#With the command "continue" below, the rest of the "for" loop is skipped to go directly to the next sample
		#Thus, we must write the /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt file to the rings_errors_and_warnings.txt and samples_errors_and_warnings.txt files
		fnct_write_warning_and_errors_to_stats_files
		continue
	fi
	
	#Numéro de cerne (facultatif) - if missing, warn only
	if [ ${col_ringno_p2b} -eq 999 ]
	then
		#Add warning to the log
		ring_error_message="The .dat file is missing the RING NO column."
		ring_error_code="W21"
		printf "${yellow_color}${ring_error_code}. ${ring_error_message}\n"
		printf "${sample_name}\tALL\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
	fi
	
	#Type de bois (facultatif) - if missing, warn only
	if [ ${col_wood} -eq 999 ]
	then
		#Add warning to the log
		ring_error_message="The .dat file is missing the WOOD TYPE column."
		ring_error_code="W22"
		printf "${yellow_color}${ring_error_code}. ${ring_error_message}\n"
		printf "${sample_name}\tALL\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
	fi
	
	#[NEW 2022-04-06]: Fix the errors caused by missing columns among the 4 above
	#Explanations: 
	#	Previously, when there were missing columns in the *_partly_cleaned_dat_curr_col_zeroed_formats.txt (Note: 2023-02-21: then: *_partly_cleaned_dat_curr_col.txt) file, there was an empty value in:
	#	col_pos_b2p, col_dens, col_ringno_p2b or col_wood.
	#	Example: 
	#		col_pos_b2p=1
	#		col_dens=2
	#		col_ringno_p2b=""
	#		col_wood=""
	# 	This	was causing an improper output in the awk command below ($"" was interpreted as $0, and all columns were copied for each missing variable value).
	#	0.000   0.00    0.000   0.00    0.000   0.00
	#	0.040   1.42    0.040   1.42    0.040   1.42
	#	0.080   0.00    0.080   0.00    0.080   0.00
	#	0.120   0.00    0.120   0.00    0.120   0.00
	#	0.160   0.00    0.160   0.00    0.160   0.00
	#	0.200   0.00    0.200   0.00    0.200   0.00
	#	0.240   0.00    0.240   0.00    0.240   0.00
	#	0.280   0.00    0.280   0.00    0.280   0.00
	#	0.320   5.19    0.320   5.19    0.320   5.19
	#	0.360   5.52    0.360   5.52    0.360   5.52
	#	Columns 3,4 and 5,6 are simply copies of columns 1,2
	#
	#	To avoid that, these variables were set to 999
	#	This put "" values in these columns
	#	There are still 4 columns in the output below
	#	The "" are then changed for "\N"
		
	#Create the /dev/shm/${ts}_reads_tmp.txt file by keeping only the fields specified by the type of data found above
	awk -F "\t" -v pos=${col_pos_b2p} -v dens=${col_dens} -v ringno=${col_ringno_p2b} -v wood=${col_wood} '{print $pos"\t"$dens"\t"$ringno"\t"$wood}' /dev/shm/${ts}_partly_cleaned_dat.txt > /dev/shm/${ts}_reads_tmp.txt
	
	#[NEW 2022-04-06] Replace empty fields with \N in case ring no or wood type are empty
	awk -F "\t" '{if ($3 =="") print $1"\t"$2"\t\\N\t"$4; else print $0}' /dev/shm/${ts}_reads_tmp.txt|awk -F "\t" '{if ($4 =="") print $1"\t"$2"\t"$3"\t\\N"; else print $0}' > /dev/shm/${ts}_reads_tmp2.txt
	mv /dev/shm/${ts}_reads_tmp2.txt /dev/shm/${ts}_reads_tmp.txt
	
	#head /dev/shm/${ts}_reads_tmp.txt
	#exit
	
	#reads_tmp.txt
		#0.000   0.00    -1      N
		#0.040   0.00    -1      N
		#0.080   0.00    -1      N
		#0.120   6.49    -1      N
		#0.160   2.35    -1      N
		#0.200   0.00    -1      N
		#0.240   0.00    -1      N
		#0.280   1.31    -1      N
		#0.320   0.00    -1      N
		#0.360   12.90   -1      N

	#--------------------------------------------------------------------
	#Whole sample checks
	#--------------------------------------------------------------------

	#Check E1 (.dat): is file empty/without proper header ? [2017-07-03]
	#--------------------------------------------------------------------
	#If the cleaned .dat file is empty, warn and skip the sample.
	if [ ! -s /dev/shm/${ts}_reads_tmp.txt ]
	then 
		printf "${red_color}\tE1. The .dat file is either empty, or does not contain the required header on the line just before data: $(echo $dat_file_data_tag|perl -pe 's/(\\|\^)//g')\n\tSAMPLE SKIPPED!${normal_color}\n\n"
		
		ring_error_message="The .dat file is empty or without proper header ($(echo $dat_file_data_tag|perl -pe 's/(\\|\^)//g'))."
		ring_error_code="E1"
		printf "${sample_name}\tALL\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		
		#With the command "continue" below, the rest of the "for" loop is skipped to go directly to the next sample
		#Thus, we must write the /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt file to the rings_errors_and_warnings.txt and samples_errors_and_warnings.txt files
		fnct_write_warning_and_errors_to_stats_files

		
		continue
	fi


	#Check E2 (.dat): are positions duplicated ? [2017-07-03]
	#--------------------------------------------------------------------
	cut -f1 /dev/shm/${ts}_reads_tmp.txt|sort|uniq -dc > /dev/shm/${ts}_reads_tmp_replicated_pos.txt
	replicated_pos=$(cat /dev/shm/${ts}_reads_tmp_replicated_pos.txt|wc -l)
	
	if [ ${replicated_pos} -gt 0 ]
	then
		#printf "Sample ${file_prefix}:\n"
		
		printf "\t${red_color}E2. The .dat file has ${replicated_pos} replicated positions!\n\tSAMPLE SKIPPED.${normal_color}\n\n"
					
		ring_error_message="The .dat file has ${replicated_pos} replicated positions!"
		ring_error_code="E2"
		printf "${sample_name}\tALL\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		
		#With the command "continue" below, the rest of the "for" loop is skipped to go directly to the next sample
		#Thus, we must write the /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt file to the rings_errors_and_warnings.txt and samples_errors_and_warnings.txt files
		fnct_write_warning_and_errors_to_stats_files
		continue
	fi


	#Check E3 (.dat): are positions ordered ? [2017-07-03]
	#--------------------------------------------------------------------
	#NOTE: we must redirect STDERR to STDOUT in order to capture it in the string
	disordered_pos=$(cut -f1 /dev/shm/${ts}_reads_tmp.txt|sort -k1,1 -nc 2>&1)
	#Note: double quotes required because the potential error message (e.g. "sort: -:2: disorder: 8") contains spaces.
	if [ ! -z "${disordered_pos}" ]
	then
		printf "${red_color}\tE3. The .dat file has disordered positions!\n\tSAMPLE SKIPPED!${normal_color}\n\n"
		
		ring_error_message="The .dat file has disordered positions!"
		ring_error_code="E3"
		printf "${sample_name}\tALL\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		
		#With the command "continue" below, the rest of the "for" loop is skipped to go directly to the next sample
		#Thus, we must write the /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt file to the rings_errors_and_warnings.txt and samples_errors_and_warnings.txt files
		fnct_write_warning_and_errors_to_stats_files
		continue
	fi

	#Get stats per ring for .dat [2017-07-03]
	#--------------------------------------------------------------------
		
	#[NEW 2022-04-07]: do the ring check only if there was a ring number column in the .dat file
	#Perform the following only if a ring number column is present in the .dat file. See around line 1817.
	if [ ${col_ringno_p2b} -ne 999 ]
	then	
		cut -f3 /dev/shm/${ts}_reads_tmp.txt|sort|uniq -c|perl -pe 's/^ +(\d+) (-*\d+)/\2\t\1/g'|sort -k1,1n > /dev/shm/${ts}_reads_tmp_reads_per_ringno.txt
		#-1	62
		#1	207
		#2	141
		#3	159
		#4	160
		#5	208
		#6	196
		#7	150
		#8	130
		#9	112

		#Get first and last ring no
		min_ring_no_in_dat=$(awk -F "\t" '{if($1 >= 0) print $1}' /dev/shm/${ts}_reads_tmp_reads_per_ringno.txt|head -1)
		max_ring_no_in_dat=$(awk -F "\t" '{if($1 >= 0) print $1}' /dev/shm/${ts}_reads_tmp_reads_per_ringno.txt|tail -1)
		
		#Check for any missing ring by creating an inclusive list between min and max
		join <(seq $min_ring_no_in_dat $max_ring_no_in_dat|sort) <(awk -F "\t" '{if($1 >= 0) print $1}' /dev/shm/${ts}_reads_tmp_reads_per_ringno.txt|sort) -v1 > /dev/shm/${ts}_reads_tmp_missing_rings.txt
		#/dev/shm/${ts}_reads_tmp_missing_rings.txt
		#2
		#7
	
		#[2023-03-13] Check W24 (.dat): missing rings ? 
		#	Note: previously (2017-07-03)error E4, but since ring no from .dat files is not taken into consideration, we changed that to a warning.
		#--------------------------------------------------------------------
		if [ -s /dev/shm/${ts}_reads_tmp_missing_rings.txt ]
		then
			#Add warning to the log
			ring_error_message="The .dat file is missing some rings."
			ring_error_code="W24"
			printf "${yellow_color}${ring_error_code}. ${ring_error_message}\n"
			printf "${sample_name}\tALL\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		
			#Before 2023-03-13
				#printf "\t${red_color}E4. The .dat file is missing some rings!\n"
				#perl -pe 's/^/\t\t/g' /dev/shm/${ts}_reads_tmp_missing_rings.txt
				#printf "\tSAMPLE SKIPPED!\n${normal_color}"
				#awk -F "\t" -v sn=${sample_name} '{print sn"\t"$1"\tE4\tMissing ring in the .dat file"}' /dev/shm/${ts}_reads_tmp_missing_rings.txt >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
				
				#With the command "continue" below, the rest of the "for" loop is skipped to go directly to the next sample
				#Thus, we must write the /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt file to the rings_errors_and_warnings.txt and samples_errors_and_warnings.txt files
				#fnct_write_warning_and_errors_to_stats_files
				#continue
		fi

		#Check W1 (.dat): rings with less reads than allowed in min_reads_per_ring_dat [2017-07-03]
		awk -F "\t" -v mr=${min_reads_per_ring_dat} '{if($1 >= 0 && $2 < mr) print $0}' /dev/shm/${ts}_reads_tmp_reads_per_ringno.txt > /dev/shm/${ts}_reads_tmp_not_enough_reads.txt
		#/dev/shm/${ts}_reads_tmp_not_enough_reads.txt
		#2	3
		#9	2

		if [ -s /dev/shm/${ts}_reads_tmp_not_enough_reads.txt ]
		then
			#Add ring(s) to /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
			awk -F "\t" -v sn=${sample_name} -v mrprd=${min_reads_per_ring_dat} '{print sn"\t"$1"\tW1\tRing only has "$2" read(s). The minimum number of allowed reads per ring (min_reads_per_ring_dat) in .dat files is "mrprd"."}' /dev/shm/${ts}_reads_tmp_not_enough_reads.txt >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		fi
	
	fi #<=== previous sections executed only if .dat has a ring number column
	
	

	#Check E5/E11/W2 (.dat): Check for abnormal (<> 0.04) gaps between reads [2017-07-04]
	#--------------------------------------------------------------------------------------------------------------------------------------------------------------------

	#List abnormal steps (different than step variable, normally=0.04) between reads:
	paste <(cut -f1,3 /dev/shm/${ts}_reads_tmp.txt) <(cat <(cut -f1,3 /dev/shm/${ts}_reads_tmp.txt|tail -n+2) <(printf "xxx\txxx\n"))|awk -F "\t" -v incr=${step} '{if ($3 != "xxx") print $0"\t"$3-$1"\t"($3-$1)/incr}'|awk -F "\t" -v incr=${step} '{if ($5 != incr) print $0}' > /dev/shm/${ts}_reads_tmp_abnormal_steps.txt
	#Line before 1/10/2019 (was omitting when gaps were smaller than the step): paste <(cut -f1,3 /dev/shm/${ts}_reads_tmp.txt) <(cat <(cut -f1,3 /dev/shm/${ts}_reads_tmp.txt|tail -n+2) <(printf "xxx\txxx\n"))|awk -F "\t" -v incr=${step} '{if ($3 != "xxx") print $0"\t"$3-$1"\t"($3-$1)/incr}'|awk -F "\t" -v incr=${step} '{if ($6 >=10) print $0"\tMAJ"; else if ($6 <10 && $6 >1) print $0"\tmin"}' > /dev/shm/${ts}_reads_tmp_abnormal_steps.txt
	
	#/dev/shm/${ts}_reads_tmp_abnormal_steps.txt
	#6.160	9	11.240	8	5.08	127
	#17.360	7	25.120	6	7.76	194
	#29.400	5	29.480	5	0.08	2
	#50.400	2	50.800	2	0.4	10
	#Where
	#Col1: position
	#col2: ring
	#Col3: next read pos
	#Col4: next read ring
	#Col5: difference in pos (mm) between position and next position.
	#Col6: Col5/step: number of times the gap is compared to the step.
	

	#Pct of abnormal steps [NEW: 2019-10-01]
	pct_abnormal_steps=$(printf "$(cat /dev/shm/${ts}_reads_tmp_abnormal_steps.txt|wc -l)\t$(cat /dev/shm/${ts}_reads_tmp.txt|wc -l)\n"|awk -F "\t" '{ printf "%.*f\n",2, $1/$2*100}')
	
	#Distribution of gaps different than those expected from step (e.g. 0.04) [NEW: 2019-10-01]
	cut -f5 -d $'\t' /dev/shm/${ts}_reads_tmp_abnormal_steps.txt|sort|uniq -c|perl -pe 's/^ +(\d+) ([\d.]+)/\2\t\1/g'|awk -F "\t" -v all_reads_count=$(cat /dev/shm/${ts}_reads_tmp.txt|wc -l) '{print$1"\t"$2"\t"$2/all_reads_count}'|sort -k1,1nr > /dev/shm/${ts}_abnormal_steps_distro.txt
	
	#E11: Reads systematically spaced differently than expected from the step parameter (e.g. 0.04) [NEW: 2019-10-01]
	#Chech if pct_abnormal_steps > 50%
	if [ $(echo $pct_abnormal_steps|awk '{if ($1 > 50) print}'|wc -l) -gt 0 ]
	then
		#awk -F "\t" -v incr=${step} -v sn=${sample_name} '{print sn"\t"$2"\tE5\tSpaces between reads systematically differ from those expected for >50% of reads ("incr"). Here is the distribution:"}' /dev/shm/${ts}_reads_tmp_abnormal_steps.txt >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		printf "${sample_name}\tALL\tSpaces between reads systematically differ from those expected for >50%% of reads (${step}).\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
				
		printf "\t${red_color}E11: The .dat file has gaps between reads that systematically differ from those expected (${step})! Here is the distribution:\n"
		printf "\tgap\tcount\tpct all reads\n"
		perl -pe 's/^/\t/g' /dev/shm/${ts}_abnormal_steps_distro.txt
		
		printf "\tSAMPLE SKIPPED!${normal_color}\n"
		
		#With the command "continue" below, the rest of the "for" loop is skipped to go directly to the next sample
		#Thus, we must write the /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt file to the rings_errors_and_warnings.txt and samples_errors_and_warnings.txt files
		fnct_write_warning_and_errors_to_stats_files
		continue
	fi
	
	#E5: Large gaps (>= 10x step)
	#Line before 1/10/2019: if [ $(grep 'MAJ' /dev/shm/${ts}_reads_tmp_abnormal_steps.txt|wc -l) -gt 0 ]
	if [ $(awk -F "\t" '{if ($5 > 10) print}' /dev/shm/${ts}_reads_tmp_abnormal_steps.txt|wc -l) -gt 0 ]
	
	then
		#Inscrit dans ${ts}_current_sample_ring_errors_and_warnings.txt le "gap", de la lecture actuelle vers la prochaine, et vice-versa.
		#Génère donc 2 messages d'erreur à la fois.
		awk -F "\t" -v sn=${sample_name} '{if ($6 >= 10) print sn"\t"$2"\tE5\tLarge gap ("$5" mm) from position "$1" to next position "$3"."}' /dev/shm/${ts}_reads_tmp_abnormal_steps.txt >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		awk -F "\t" -v sn=${sample_name} '{if ($6 >= 10) print sn"\t"$4"\tE5\tLarge gap ("$5" mm) from position "$3" to previous position "$1"."}' /dev/shm/${ts}_reads_tmp_abnormal_steps.txt >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		
		printf "\t${red_color}E5: The .dat file has major gaps between reads!\n\tSAMPLE SKIPPED!${normal_color}\n"
		
		#With the command "continue" below, the rest of the "for" loop is skipped to go directly to the next sample
		#Thus, we must write the /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt file to the rings_errors_and_warnings.txt and samples_errors_and_warnings.txt files
		fnct_write_warning_and_errors_to_stats_files
		continue
	
	fi


	#W2: Other gaps (<10x step) if none of the errors above (E5, E11) were found
	#--------------------------------------------------------------------------------------------------------------------------------------------------------------------

	if [ $(grep 'min' /dev/shm/${ts}_reads_tmp_abnormal_steps.txt|wc -l) -gt 0 ]
	then
		#Add ring(s) to /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		#Line before 1/10/2019: awk -F "\t" -v sn=${sample_name} '{if ($6 < 10) print sn"\t"$2"\tW2\tMinor gap ("$5" mm) from position "$1" to next position "$3"."}' /dev/shm/${ts}_reads_tmp_abnormal_steps.txt >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		#Line before 1/10/2019: awk -F "\t" -v sn=${sample_name} '{if ($6 < 10) print sn"\t"$4"\tW2\tMinor gap ("$5" mm) from position "$3" to previous position "$1"."}' /dev/shm/${ts}_reads_tmp_abnormal_steps.txt >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		awk -F "\t" -v incr=${step} -v sn=${sample_name} '{if ($6 < 10) print sn"\t"$2"\tW2\tGap ("$5" mm) from position "$1" to next position "$3" is different from expected ("incr" mm) gap."}' /dev/shm/${ts}_reads_tmp_abnormal_steps.txt >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		awk -F "\t" -v incr=${step} -v sn=${sample_name} '{if ($6 < 10) print sn"\t"$4"\tW2\tGap ("$5" mm) from position "$3" to previous position "$1" is different from expected ("incr" mm) gap."}' /dev/shm/${ts}_reads_tmp_abnormal_steps.txt >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
	fi

	
	
	#Add pith-to-bark line numbering, required for storage into x_ray_dens_msmts_per_read [2017-06-14]
	sort -k1,1 -t $'\t' -nr /dev/shm/${ts}_reads_tmp.txt|cat -n|awk -F "\t" '{print $0"\t"$1}'|cut -f1 --complement -d $'\t'|sort -k1,1 -n > /dev/shm/${ts}_reads_tmp_numbered_p2b.txt
		#0.000   0.00    -1      N         1100
		#0.040   0.00    -1      N         1099
		#0.080   0.00    -1      N         1098
		#0.120   0.00    -1      N         1097
		#0.160   0.00    -1      N         1096
		#0.200   0.00    -1      N         1095
		#0.240   0.00    -1      N         1094
		#0.280   0.00    -1      N         1093
		#0.320   9.16    -1      N         1092
		#0.360   0.00    -1      N         1091



	#--------------------------------------------------------------------------------------------------------------------------------------------------------------------
	#Clean the .sum info file
	#--------------------------------------------------------------------------------------------------------------------------------------------------------------------
	#1. Remove headers by keeping only rows with real numbers (having 9.9 or 9,9)
	#2. Remove double quotes
	#3. Replace commas with periods (some files have commas instead of periods as decimal points)
	#4. Remove leading spaces or tabs
	#5. a) Replace interior spaces/tabs with single tabs
	#    b) Remove trailing spaces/tabs (added 2023-03-13)
	#6. Test the homogeneity of column numbers (NEW: 23/11/2018) - This allows to avoid partially deleted lines that may cause errors later
	
	#7. Keep only the following 5 original columns (Sample ID, Ring No., Year, End mm, Start mm)
	#	- this is now done by grabbing the 10 last columns (#3-12) from the right side of the table, to avoid the Sample ID field...
	#	...the reason being that there are sometimes spaces in that field (stupid practice, combined with space-separated fields, brilliant), which thus splits the Sample ID into 2 columns.
	#	From these 10 columns, only the first 4 are kept (Ring No., Year, End mm, Start mm) and sample name, computed from filename, is put as a 5th column on the left of the 4 others.
	#	Note [20220405]: this works with .sum files generated by the Excel VBA script regroup_data_from_sm_density_files20220404.bas
	#	- path must be put between double quotes because some filenames [alas] contain spaces.
	#8. Remove empty lines (added 13/6/2017)
	#9. [2017-07-04] Add the ring width by substracting column 4 (ring end position) from column 5 (ring start position)
	
	
	#Steps 1-5
	#[Line before 2023-03-13]: grep -E '[0-9](\.|,)[0-9]' "./${infiles_folder}/${sumfile}"|perl -pe 's/"//g'|perl -pe 's/,/./g'|perl -pe 's/^[ \t]+//g'|perl -pe 's/[ \t]+/\t/g' > /dev/shm/${ts}_rings_tmp_part.txt
	grep -E '[0-9](\.|,)[0-9]' "./${infiles_folder}/${sumfile}"|perl -pe 's/"//g'|perl -pe 's/,/./g'|perl -pe 's/^[ \t]+//g'|perl -pe 's/[ \t]+(\w)/\t\1/g'|perl -pe 's/[ \t]+$//g' > /dev/shm/${ts}_rings_tmp_part.txt
	
	#cat -A /dev/shm/${ts}_rings_tmp_part.txt
	#exit
	
	
	#Step 6
	#If there are lines with different numbers of columns
	if [ $(awk -F "\t" '{print NF}' /dev/shm/${ts}_rings_tmp_part.txt|sort -u|wc -l) -gt 1 ]
	then
		printf "\t${red_color}E14. The .sum file has an irregular number of columns!\n\tSAMPLE SKIPPED!${normal_color}\n\n"
		ring_error_message="The .sum file has an irregular number of columns."
		ring_error_code="E14"
		printf "${sample_name}\tALL\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		#With the command "continue" below, the rest of the "for" loop is skipped to go directly to the next sample
		#Thus, we must write the /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt file to the rings_errors_and_warnings.txt and samples_errors_and_warnings.txt files
		fnct_write_warning_and_errors_to_stats_files
		continue
	fi
	
	
	
	#Steps 7-9
	awk -F "\t" '{print $(NF-9)"\t"$(NF-8)"\t"$(NF-7)"\t"$(NF-6)"\t"$(NF-5)"\t"$(NF-4)"\t"$(NF-3)"\t"$(NF-2)"\t"$(NF-1)"\t"$NF}' /dev/shm/${ts}_rings_tmp_part.txt|awk -F "\t" -v sn="${sample_name}" '{print sn"\t"$1"\t"$2"\t"$3"\t"$4"\t"$4-$3}'|grep -v '^$' > /dev/shm/${ts}_rings_tmp.txt
		#Note: NF-9 = $3 (Ring No.)
		
	#rings_tmp.txt
		#A1	9	2014	2.16	6.20	4.04
		#A1	8	2013	6.20	11.40	5.2
		#A1	7	2012	11.40	17.40	6
		#A1	6	2011	17.40	25.24	7.84
		#A1	5	2010	25.24	33.56	8.32
		#A1	4	2009	33.56	39.96	6.4
		#A1	3	2008	39.96	46.32	6.36
		#A1	2	2007	46.32	51.96	5.64
		#A1	1	2006	51.96	56.12	4.16
		#NOTE: here, the corrected (no spaces) file prefix is used for the sample name.
		#Col 1: sample name (corrected)
		#Col 2: ring number (pith to bark), from .sum file
		#Col 3: ring year, from .sum file
		#Col 4: ring end position (bark to pith), from .sum file
		#Col 5: ring start position (bark to pith), from .sum file
		#Col 6: ring width, calculated here.
	
	
	#Check E6 (WHOLE .sum): cleaned .sum file is empty or without proper header? [2017-07-04]
	#--------------------------------------------------------------------------------------------------------------------------------------------------------------------

	if [ ! -s /dev/shm/${ts}_rings_tmp.txt ]
	then 
		
		printf "\t${red_color}E6. The .sum file is either empty, or does not contain the required header on the line just before data: $(echo $sum_file_header_tag|perl -pe 's/(\\|\^)//g')\n\tSAMPLE SKIPPED!${normal_color}\n\n"
					
		ring_error_message="The .sum file is empty or without proper header ($(echo $sum_file_header_tag|perl -pe 's/(\\|\^)//g'))."
		ring_error_code="E6"
		printf "${sample_name}\tALL\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		#With the command "continue" below, the rest of the "for" loop is skipped to go directly to the next sample
		#Thus, we must write the /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt file to the rings_errors_and_warnings.txt and samples_errors_and_warnings.txt files
		fnct_write_warning_and_errors_to_stats_files
		continue
	fi


	#Check E13 (WHOLE .sum): replicated rings [2017-07-04]
	#--------------------------------------------------------------------------------------------------------------------------------------------------------------------

	if [ $(cut -f2 /dev/shm/${ts}_rings_tmp.txt|sort|uniq -d|wc -l) -gt 0 ]
	then
		
		printf "\t${red_color}E13. The .sum file has replicated ring numbers!\n\tSAMPLE SKIPPED!\n"
		
		cut -f1,2 /dev/shm/${ts}_rings_tmp.txt|sort|uniq -d|awk -F "\t" '{print $1"\t"$2"\tE13\tReplicated ring number.\n"}' >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		#With the command "continue" below, the rest of the "for" loop is skipped to go directly to the next sample
		#Thus, we must write the /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt file to the rings_errors_and_warnings.txt and samples_errors_and_warnings.txt files
		fnct_write_warning_and_errors_to_stats_files
		continue
	fi


	#Check E7 (WHOLE .sum): check that rings number (p2b) are ordered [2017-07-04]
	#--------------------------------------------------------------------------------------------------------------------------------------------------------------------
	
	disordered_rings=$(cut -f2 /dev/shm/${ts}_rings_tmp.txt|sort -rcn 2>&1)
	#Note: double quotes required because the potential error message (e.g. "sort: -:2: disorder: 8") contains spaces.
	if [ ! -z "${disordered_rings}" ]
	then 
		printf "\t${red_color}E7. The .sum file has disordered ring numbers!\n\tSAMPLE SKIPPED!${normal_color}\n"
		ring_error_message="The .sum file has disordered ring numbers!"
		ring_error_code="E7"
		printf "${sample_name}\tALL\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		
		#With the command "continue" below, the rest of the "for" loop is skipped to go directly to the next sample
		#Thus, we must write the /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt file to the rings_errors_and_warnings.txt and samples_errors_and_warnings.txt files
		fnct_write_warning_and_errors_to_stats_files
		continue
	fi

	
	#Check E8 (WHOLE .sum): missing rings ? [2017-07-04]
	#--------------------------------------------------------------------------------------------------------------------------------------------------------------------
	
	#Get first and last ring no
	min_ring_no_in_sum=$(cut -f2 /dev/shm/${ts}_rings_tmp.txt|sort -n|head -1)
	max_ring_no_in_sum=$(cut -f2 /dev/shm/${ts}_rings_tmp.txt|sort -n|tail -1)
	
	#Check for any missing ring by creating an inclusive list between min and max
	join <(seq $min_ring_no_in_sum $max_ring_no_in_sum|sort) <(awk -F "\t" '{if($1 >= 0) print $2}' /dev/shm/${ts}_rings_tmp.txt|sort) -v1 > /dev/shm/${ts}_rings_tmp_missing_rings.txt
	#/dev/shm/${ts}_rings_tmp_missing_rings.txt
	#4
	
	#If rings are missing from the .sum file
	if [ -s /dev/shm/${ts}_rings_tmp_missing_rings.txt ]
	then
		printf "\t${red_color}E8. The .sum file is missing some rings!\n"
		perl -pe 's/^/\t\t/g' /dev/shm/${ts}_rings_tmp_missing_rings.txt
		printf "\tSAMPLE SKIPPED!${normal_color}"
		awk -F "\t" -v sn=${sample_name} '{print sn"\t"$1"\tE8\tMissing ring in the .sum file"}' /dev/shm/${ts}_rings_tmp_missing_rings.txt >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		
		#With the command "continue" below, the rest of the "for" loop is skipped to go directly to the next sample
		#Thus, we must write the /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt file to the rings_errors_and_warnings.txt and samples_errors_and_warnings.txt files
		fnct_write_warning_and_errors_to_stats_files
		continue
	
	fi

	#[NEW 2022-04-07]: do the ring check only if there was a ring number column in the .dat file
	#Perform the following only if a ring number column is present in the .dat file. See around line 1817.
	#--------------------------------------------------------------------------------------------------------------------------------------------------------------------
	if [ ${col_ringno_p2b} -ne 999 ]
	then
	
		#Checks W10/W18 (WHOLE .sum/.dat): all rings in .sum file are in .dat file and vice-versa ? [2017-07-04]
		#--------------------------------------------------------------------------------------------------------------------------------------------------------------------
		#Rings in .dat NOT present in .sum (W10)
		join <(awk -F "\t" '{if ($1 > 0) print $1}' /dev/shm/${ts}_reads_tmp_reads_per_ringno.txt|sort) <(cut -f2 /dev/shm/${ts}_rings_tmp.txt|sort) -v1 > /dev/shm/${ts}_rings_tmp_missing_rings_in_sum_vs_dat.txt

		#Rings in .sum NOT present in .dat (W18)
		join <(awk -F "\t" '{if ($1 > 0) print $1}' /dev/shm/${ts}_reads_tmp_reads_per_ringno.txt|sort) <(cut -f2 /dev/shm/${ts}_rings_tmp.txt|sort) -v2 > /dev/shm/${ts}_rings_tmp_missing_rings_in_dat_vs_sum.txt
		
		#If rings are missing in the .sum file compared to the .dat file ---> W10 (may have been deliberately omitted)
		#NOTE: this error message WILL NOT SHOW onscreen (line ~ 2237) because this or these rings are absent from .SUM and will not be reviewed in the FOR loop.
		if [ -s /dev/shm/${ts}_rings_tmp_missing_rings_in_sum_vs_dat.txt ]
		then
			awk -F "\t" -v sn=${sample_name} '{print sn"\t"$1"\tW10\tRing in the .dat file ABSENT from the .sum file."}' /dev/shm/${ts}_rings_tmp_missing_rings_in_sum_vs_dat.txt >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		fi
#exit			
		#If rings are missing in the .dat file compared to the .sum file ---> W18 (.dat ring numbers are not considered anyways)
		#Note [17/6/2019]
		#	- Previously, this was considered to be an error (E9)
		#	- But since ring number in .dat files is ignored (see line ~ 1934), being replaced by that of the .sum file using POSITIONS, there is no critical need for it in .dat files.
		#	- Even in .sum files, the ring number is a guideline at best, often arbitrarily set. Ring year is always a better indicator, especially when crossdating was done.
		if [ -s /dev/shm/${ts}_rings_tmp_missing_rings_in_dat_vs_sum.txt ]
		then
			#Add ring(s) to /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
			awk -F "\t" -v sn=${sample_name} '{print sn"\t"$1"\tW18\tRing in the .sum file ABSENT from the .dat file."}' /dev/shm/${ts}_rings_tmp_missing_rings_in_dat_vs_sum.txt >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		fi

	fi	#<=== previous sections executed only if .dat has a ring number column
	
	#Check E10 (WHOLE .sum): start pos < end pos ? [2017-07-04]
	#--------------------------------------------------------------------------------------------------------------------------------------------------------------------
	
	#Get rings with start position (bark to pith) < end position (bark to pith)
	awk -F "\t" '{if($5 < $4) print}' /dev/shm/${ts}_rings_tmp.txt > /dev/shm/${ts}_rings_tmp_start_pos_lt_end_pos.txt
	
	#If there are rings with start pos < end pos
	if [ -s /dev/shm/${ts}_rings_tmp_start_pos_lt_end_pos.txt ]
	then
		printf "${red_color}\tE10. There are rings with starting position LOWER THAN end position in the .sum file!\n"
		perl -pe 's/^/\t\t/g' /dev/shm/${ts}_rings_tmp_start_pos_lt_end_pos.txt
		printf "\tSAMPLE SKIPPED!\n${normal_color}"
		awk -F "\t" '{print $1"\t"$2"\tE10\tRing has a starting position ("$5") LOWER than the ending position ("$4")."}' /dev/shm/${ts}_rings_tmp_start_pos_lt_end_pos.txt >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		
		#With the command "continue" below, the rest of the "for" loop is skipped to go directly to the next sample
		#Thus, we must write the /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt file to the rings_errors_and_warnings.txt and samples_errors_and_warnings.txt files
		fnct_write_warning_and_errors_to_stats_files
		continue
	fi
	
	#Check W11 (WHOLE .sum): ring width > max_ring_width_factor times median ring width ? [2017-07-04, 2017-09-18]
	#--------------------------------------------------------------------------------------------------------------------------------------------------------------------
	#Previously an error (E11), now a warning only.
	#Get median width, to get rid of extremes, and calculate deviation from median.
	cut -f6 /dev/shm/${ts}_rings_tmp.txt|sort -n > /dev/shm/${ts}_rings_tmp_ordered_widths.txt
	#-38.04
	#1.32
	#3.32
	#3.92
	#4.16
	#4.44
	#4.52
	#5.36
	#5.6
	#5.88
	#5.96
	#11.24
	#43
	
	#Get the WIDTH median value
	fnct_get_median_value /dev/shm/${ts}_rings_tmp_ordered_widths.txt
	
	#echo median_value: $median_value
	
	

	#Get the lines where width is > max_ring_width_factor x the median width
	#[8/9/2017] Now based on a variable
	awk -F "\t" -v mv=${median_value} -v mrwf=${max_ring_width_factor} '{if($6 > mv*mrwf) print $0"\t"mv}' /dev/shm/${ts}_rings_tmp.txt > /dev/shm/${ts}_rings_tmp_many_x_median_width.txt
	
	#If there are such values, add a W11 warning
	if [ -s /dev/shm/${ts}_rings_tmp_many_x_median_width.txt ]
	then
		#Below is redundant, as the W11 error message will be displayed (via /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt) within each ring.
			#printf "\t${yellow_color}W11. There are rings > ${max_ring_width_factor}x the median ring width in the .sum file!\n"
			#printf "\t\tSmpl\tRing\tYear\tEnd\tStart\tWidth\tMedian width\n"	#[20190715]
			#perl -pe 's/^/\t\t/g' /dev/shm/${ts}_rings_tmp_many_x_median_width.txt
			#printf "${normal_color}"
		
		#Add ring(s) to /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		awk -F "\t" -v mrwf=${max_ring_width_factor} '{print $1"\t"$2"\tW11\tRing width ("$6" mm) is >"mrwf"x the median ring width ("$7")!"}' /dev/shm/${ts}_rings_tmp_many_x_median_width.txt >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		
	fi

	
	#Check W8 (WHOLE .sum): Check for inconsistencies between current ring end position and next ring start position [28/6/2017]
	#--------------------------------------------------------------------------------------------------------------------------------------------------------------------
		
	#				ring end	ring start
	#				\/		\/
	#	A6	8	2014	2.32		6.20
	#	A6	7	2013	6.20		10.88
	#	A6	6	2012	10.88		16.88
	#	A6	5	2011	16.88		22.64
	#	A6	4	2010	22.64		28.88
	#	A6	3	2009	28.88		35.08
	#	A6	2	2008	35.08		**41.00**
	#	A6	1	2007	**41.04**	46.24
	#	Here, there is an inconsistency between ring 1's end position (41.04) and ring 2's start position, as they should be equal.

	#Add a column with the next ring's start position, simply by offsetting down by 1 the start_pos. The last ring will have the next ring start pos filled with xxx
	cat <(printf "ringno\tend_pos\tstart_pos\tnext_ringno\tnext_r_start_pos\n") <(paste <(cut -f2,4,5 /dev/shm/${ts}_rings_tmp.txt) <(cat <(printf "xxx\txxx\n") <(cut -f2,5 /dev/shm/${ts}_rings_tmp.txt|head -n-1))) > /dev/shm/${ts}_rings_tmp_with_next_ring_start_pos.txt
	#/dev/shm/${ts}_rings_tmp_with_rev_ring_start_pos.txt
	#	ringno  end_pos start_pos       next_ringno     next_r_start_pos
	#	8       2.32    6.20    xxx     xxx
	#	7       6.20    10.88   8       6.20
	#	6       10.88   16.88   7       10.88
	#	5       16.88   22.64   6       16.88
	#	4       22.64   28.88   5       22.64
	#	3       28.88   35.08   4       28.88
	#	2       35.08   41.00   3       35.08
	#	1       41.04   46.24   2       41.00

	#Removing header and last ring (xxx), compare current ring's end position with next ring's start position.
	#List any discrepancies.
	tail -n+2 /dev/shm/${ts}_rings_tmp_with_next_ring_start_pos.txt |grep -v 'xxx'|awk -F "\t" '{if($2 != $5) print $1"\t"$2"\t"$4"\t"$5}' > /dev/shm/${ts}_rings_tmp_inconsistensies_between_ring_end_pos_and_next_ring_start_pos.txt
	#1       41.04   2       41.00


	#Warning messages if any.
	#NOTE: this is done for ALL RINGS at once, not each ring at a time
	if [ -s /dev/shm/${ts}_rings_tmp_inconsistensies_between_ring_end_pos_and_next_ring_start_pos.txt ]
	then 

	
		#Add ring(s) to /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		#NOTE: it will add a warning for each ring involved (e.g. ring 4 end position differs from ring 5 dtart position: both rings will be listed as separate lines.
		#	Hence, not using the ring_error_message here because there will be >=2 lines with different messages.
		cat <(awk -F "\t" -v sn=${sample_name} '{print sn"\t"$1"\tW8f\tRing "$1" end pos ("$2") differs from ring "$3" start pos ("$4")"}' /dev/shm/${ts}_rings_tmp_inconsistensies_between_ring_end_pos_and_next_ring_start_pos.txt) <(awk -F "\t" -v sn=${sample_name} '{print sn"\t"$3"\tW8r\tRing "$3" start pos ("$4") differs from ring "$1" end pos ("$2")"}' /dev/shm/${ts}_rings_tmp_inconsistensies_between_ring_end_pos_and_next_ring_start_pos.txt)|sort -k2,2n >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt

	fi
	
	
	#exit
	
	#Going through each row (ring) of the corrected rings file
	#----------------------------------------------------------------------------------------------------------
	
	#Create corrected files: 1) 001_corr_reads.txt (all reads), 2) 001_corr_ring_stats.txt (ring stats).
	printf "" > "${temp_f}/corrected_files/${sample_name}_corr_reads.txt"
	printf "" > "${temp_f}/corrected_files/${sample_name}_corr_ring_stats.txt"


	#[20190625] Count the number of rings
	number_of_rings=$(cat /dev/shm/${ts}_rings_tmp.txt|wc -l)

	#Go through each ring of the /dev/shm/${ts}_rings_tmp.txt file
	for rings_line in $(cat /dev/shm/${ts}_rings_tmp.txt)
	do
		#Error message specific to each ring
		ring_error_message=""
		
		#Get ring variables from the .sum file
			#ring last read position. Since samples are read in the bark-to-pith direction, this value is lower than the one for ring_start_pos.
			ring_end_pos=$(echo ${rings_line}|cut -f4 -d $'\t')
						
			#ring first read position: this must be corrected from the .sum file, which equates ring start position with previous ring end position
			#...which is not right considering a read cannot be simultaneously in two distinct rings.
			#...hence ring start position will be equal to ring first read position (=previous ring end position in this .sum file) - read step (0.04)
			#Since samples are read in the bark-to-pith direction, this value is higher than the one for ring_end_pos.
			ring_start_pos=$(echo "scale=3;$(echo ${rings_line}|cut -f5 -d $'\t')-$step"|bc)
			
			
			#Examples: A-2142-5-1.sum (E952 SMarTForests dataset)
			#	|--------.sum file-------------------|	|-----------------script-----------------|
			#	ring_no	end		start		ring_end_pos		ring_start_pos	
			#	8		1,52		6,04**	1,52				6,00			
			#	7		6,08**	10,84	6,08				10,80
			#	6		10,84	15,6		10,84			15,56
			#	5		15,6		20,84	15,6				20,80
			#	4		20,84	25,96	20,84			25,92
			#	3		25,96	31,24		25,96			31,20
			#	2		31,24		36,2		31,24				36,16
			#	1		36,2		38,64	36,2				38,60
			#**Note the inconsistency in the .sum file between current ring's (8) start and previous ring's (7) end, whereas it is always equal for all other adjacent rings
			
			
			#ring year
			ring_year=$(echo ${rings_line}|cut -f3 -d $'\t')
			
			#Ring number from the .sum file. Not a reliable ring numbering from pith to bark (see physico_mechanical_properties_datasets2015.docx), but needed as a reference in the script.
			ring_no=$(echo ${rings_line}|cut -f2 -d $'\t')
			
			#Sample name 
			#sample_name=$(echo ${rings_line}|cut -f1 -d $'\t')
			#not necessary, already defined as $sample_name on line 565

			printf "RING: ${blue_color}${ring_no} (${ring_year})${normal_color}\n"
	
		#Extract all .dat lines with POSITIONS (not ring number) within the ring_end_pos and ring_start_pos (both included) limits
		#...and add sample number, ring year and ring no as first columns
		#----------------------------------------------------------------------------------------------------------
		#NOTE: 2023-03-09
		#	When interdating of sampled trees was done, rings with 0 width are sometimes added to the .sum file by the operator.
		#	This represents cases where these rings are known to exist for these years, as shown by stand interdatation, but could not be found by densitometry for the current tree.
		#	Adding them allows to have ring years synchronized with the rest of the ring-dated trees.
		#	Below is an example from the 20326177 sample, collected in 2017 at Acadia Research Forest (E60A).
		#	In those cases, no reads will be found from the command below, and those rings will be absent from the resulting files *_corr_reads.txt and *_corr_ring_stats.txt.
		#									      Late
		#							      Wood    Ring    Late    Early   Late    Ring
		#				  Ring        	End     Start   Width   Width   Wood    Wood    Wood   Average
		#	Study ID     Sample ID    No.  Year    mm      mm      mm      mm    Percent Density Density Density
		#	    20326177          177  38  2015    1.42    1.56    0.04    0.14   28.57  405.49  538.97  443.63
		#	    20326177          177  37  2014    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00
		#	    20326177          177  36  2013    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00
		#	    20326177          177  35  2012    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00
		#	    20326177          177  34  2011    1.56    1.68    0.04    0.12   33.33  474.07  525.36  491.16
		#	    20326177          177  33  2010    1.68    1.90    0.04    0.22   18.18  389.40  523.03  413.70

		
		#if $1 >= last: if position (bark-to-pith) is greater or equal to ring end position (e.g. 1.2 cm)
		#	and
		#if $1 <= first: if position (bark-to-pith) is less or equal to ring start position (e.g. 4.0 cm)
		#	then this read is within the current ring's range: add the sample name, ring year and number, coming from .sum file, as 3 first columns.
		#Line before 14/6/2017
		#awk -F "\t" -v last=${ring_end_pos} -v first=${ring_start_pos} -v name=${sample_name} -v year=${ring_year} -v no=${ring_no} '{if($1 >= last && $1 <= first) print name"\t"year"\t"no"\t"$0}' /dev/shm/${ts}_reads_tmp.txt > /dev/shm/${ts}_current_ring_reads_tmp.txt
		#New line (14/6/2017)
		awk -F "\t" -v last=${ring_end_pos} -v first=${ring_start_pos} -v name=${sample_name} -v year=${ring_year} -v no=${ring_no} '{if($1 >= last && $1 <= first) print name"\t"year"\t"no"\t"$0}' /dev/shm/${ts}_reads_tmp_numbered_p2b.txt > /dev/shm/${ts}_current_ring_reads_tmp.txt
			#Note: first column comes from the .dat filename, 2 next colums from the .sum file, the 4 next from the .dat file, and the last is line numbering from pith to bark.
			
			#/dev/shm/${ts}_current_ring_reads_tmp.txt
			#A1	2014	9	2.160	677.84	9	L	  1471
			#A1	2014	9	2.200	619.56	9	L	  1470
			#A1	2014	9	2.240	592.35	9	L	  1469
			#A1	2014	9	2.280	575.44	9	L	  1468
			#A1	2014	9	2.320	535.90	9	E	  1467
			#A1	2014	9	2.360	525.21	9	E	  1466
			#A1	2014	9	2.400	507.31	9	E	  1465
			#A1	2014	9	2.440	489.93	9	E	  1464
			#A1	2014	9	2.480	467.35	9	E	  1463
			#A1	2014	9	2.520	449.74	9	E	  1462
		#Col 1: sample name, from .DAT filename
		#Col 2: ring year, from .SUM file.
		#Col 3: ring number (pith to bark), from .SUM file.
		#Col 4: position (bark-to-pith), from .DAT file.
		#Col 5: density, from .DAT file.
		#Col 6: ring number (pith to bark), from .DAT file.			===> WILL BE IGNORED, ring year from .SUM file will be used.
		#Col 7: wood type (E=earlywood, L=latewood), from .DAT file.	===> WILL BE IGNORED, transition calculated in the current script will be used.
		#Col 8: pth-to-bark line numbering, for the whole sample.
		
		
		#[20190617] Print start/end pos and number of reads, before any outlier density reads removal
		printf "\tOriginal (.sum) ring start pos/ring end pos/number of reads: ${ring_start_pos}/${ring_end_pos}/$(cat /dev/shm/${ts}_current_ring_reads_tmp.txt|wc -l)\n" 


		
		#[NEW: 25/9/2017] For the first and last rings, remove density reads <100
		#echo ring_no $ring_no
		#echo max_ring_no_in_sum $max_ring_no_in_sum
		#echo min_ring_no_in_sum $min_ring_no_in_sum
		
		
		#This variable reset ensures that for each ring, unless low-density reads are removed...
		#...there will be no need to check if the /dev/shm/${ts}_current_ring_reads_tmp.txt file has enough reads
		rejected_reads_counts=0
		
		#Check if current ring (from .SUM file) is the first or last (from pith)
		#----------------------------------------------------------------------------------------------------------
		#1. A removal of low density reads on both ends will be performed
		#2. For first ring, it will be added to a list of invalid rings is the first ring is considered systematically as the pith (first_ring_is_pith=1) [2019-07-12]
		if [ $ring_no -eq $min_ring_no_in_sum ] || [ $ring_no -eq $max_ring_no_in_sum ]
		then
			#echo min or max ring $ringno
			
			#First ring (pith side)
			#----------------------------------------------------------------------------------------------------------
			if [ $ring_no -eq $min_ring_no_in_sum ]
			then
				
				#Auto. flag the ring as invalid is the first ring is considered systematically as the pith (first_ring_is_pith=1) [2019-07-12]
				if [ ${first_ring_is_pith} -eq 1 ]
				then
					printf "${sample_name}\t${ring_no}\tRing auto. flagged as the pith (invalid ring) on ${pgf_date} by $0, because piths are assumed to be systematically left in the results (parameter first_ring_is_pith=1).\n" >> /dev/shm/${ts}_pith_rings.txt
				fi
				
				#echo "first ring pith side: ${ring_no}"
				#Note: PITH side is the one encountered LAST in the .dat files! Hence, the <100 density reads, if present, will be at the end of the current ring file.
				
				#Number of reads in the file, prior to the minimum density test
				number_of_reads_before_dens_test=$(cat /dev/shm/${ts}_current_ring_reads_tmp.txt|wc -l)
				
				


				#[Added: 4/10/2017]
				#Add columns for density threshold a) gradual b) fixed
				awk -F "\t" -v r2cb=${reads_to_check_for_density_pithside} -v md=${min_allowed_density} -v tds=${varying_threshold_step} -v nrbdt=${number_of_reads_before_dens_test} '{print $0"\t"NR"\t"md-(nrbdt-NR)*tds"\t"md}' /dev/shm/${ts}_current_ring_reads_tmp.txt > /dev/shm/${ts}_current_ring_reads_w_dens_threshold_tmp.txt
				#A1	2014	9	2.160		677.84	9	L	  1471		1	100	100
				#A1	2014	9	2.200	619.56	9	L	  1470	2	97.7	100
				#A1	2014	9	2.240	592.35	9	L	  1469	3	95.4	100
				#A1	2014	9	2.280	575.44	9	L	  1468	4	93.1	100
				#A1	2014	9	2.320	535.90	9	E	  1467	5	90.8	100
				#A1	2014	9	2.360	525.21	9	E	  1466	6	88.5	100
				#A1	2014	9	2.400	507.31	9	E	  1465	7	86.2	100
				#A1	2014	9	2.440	489.93	9	E	  1464	8	83.9	100
				#A1	2014	9	2.480	467.35	9	E	  1463	9	81.6	100
				#A1	2014	9	2.520	449.74	9	E	  1462	10	79.3	100


				#Read no at which the minimum density test will start, usually the 20th before the end.
				let starting_read_for_density_check=${number_of_reads_before_dens_test}-${reads_to_check_for_density_pithside}+1
				#[added 2/10/2017]: to avoid having a starting read <1 in case there's fewer reads than the number to check
				if [ ${starting_read_for_density_check} -lt 1 ]; then let starting_read_for_density_check=1;fi
				
				#echo "number of reads in last ring (pithside): ${number_of_reads_before_dens_test}"
				#echo "start looking at low density from read: ${starting_read_for_density_check}"
				
				
				#Line before 4/10/2017: if [ $low_density_reads_removal_choice -eq 1 ]
				
				if [ $low_density_reads_removal_choice -lt 3 ]
				then #Option 1 or 2 chosen: last low-density read and all previous reads are removed
					#[2/10/2017] Find the first line of the first ring (pith side) reads where density <100, in order to remove all following reads as well, even if they are of density >=100
					#First line rejected because of low density
					
					first_rejected_read_line_no=""
					
					if [ $low_density_reads_removal_choice -eq 1 ]
					then #Option 1
						first_rejected_read_line_no=$(awk -F "\t" -v sr4dc=${starting_read_for_density_check} '{if (NR >= sr4dc && $5 < $10) print NR}' /dev/shm/${ts}_current_ring_reads_w_dens_threshold_tmp.txt|head -1)
					else #Option 2
						first_rejected_read_line_no=$(awk -F "\t" -v sr4dc=${starting_read_for_density_check} '{if (NR >= sr4dc && $5 < $11) print NR}' /dev/shm/${ts}_current_ring_reads_w_dens_threshold_tmp.txt|head -1)
					fi
						
					#Line before 4/10/2017
					#first_rejected_read_line_no=$(awk -F "\t" -v sr4dc=${starting_read_for_density_check} -v md=${min_allowed_density} '{if (NR >= sr4dc && $5 < md) print NR}' /dev/shm/${ts}_current_ring_reads_tmp.txt|head -1)
					
					#If there was at least one line found
					if [ ! -z ${first_rejected_read_line_no} ]
					then
						#Rejected reads		
						awk -F "\t" -v frrln=${first_rejected_read_line_no} '{if (NR >= frrln) print}' /dev/shm/${ts}_current_ring_reads_tmp.txt > /dev/shm/${ts}_current_ring_reads_rejected_for_low_density_tmp.txt
					fi
				
				else	#Option 3 or 4 chosen: only low-density reads are removed
					
					if [ $low_density_reads_removal_choice -eq 3 ]
					then #Option 3
						awk -F "\t" -v sr4dc=${starting_read_for_density_check} '{if (NR >= sr4dc && $5 < $10) print}' /dev/shm/${ts}_current_ring_reads_w_dens_threshold_tmp.txt|cut -f9-11 --complement  -d $'\t' > /dev/shm/${ts}_current_ring_reads_rejected_for_low_density_tmp.txt
					else #Option 4
						awk -F "\t" -v sr4dc=${starting_read_for_density_check} '{if (NR >= sr4dc && $5 < $11) print}' /dev/shm/${ts}_current_ring_reads_w_dens_threshold_tmp.txt|cut -f9-11 --complement  -d $'\t' > /dev/shm/${ts}_current_ring_reads_rejected_for_low_density_tmp.txt
					fi
				fi
				
				if [ -e /dev/shm/${ts}_current_ring_reads_rejected_for_low_density_tmp.txt ]
				then
					rejected_reads_counts=$(cat /dev/shm/${ts}_current_ring_reads_rejected_for_low_density_tmp.txt|wc -l)
				else
					rejected_reads_counts=0
				fi
				
				#If there are rejected reads
				if [ ${rejected_reads_counts} -gt 0 ] #;then echo warning;fi
				then
					#echo "Warning ${rejected_reads_counts} low density reads found on pith side."
					ring_error_message="${rejected_reads_counts} low density (< ${min_allowed_density} km/m3) reads in ${reads_to_check_for_density_pithside} first reads of ring ${ring_no} (pith side) were removed from results."
					ring_error_code="W12"
					#Add ring to /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
					printf "${sample_name}\t${ring_no}\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
					
					#Put those rejected reads in the all_reads_rejected_for_low_density.txt file.
					cat /dev/shm/${ts}_current_ring_reads_rejected_for_low_density_tmp.txt >> ${temp_f}/logs_and_summaries/intermediate/all_reads_rejected_for_low_density.txt
					
				#Kept reads
					#Only fetched if there were some rejected reads above
					#if [ $low_density_reads_removal_choice -eq 1 ]
					
					if [ $low_density_reads_removal_choice -lt 3 ]
					
					then #options 1 or 2
						awk -F "\t" -v frrln=${first_rejected_read_line_no} '{if (NR < frrln) print}' /dev/shm/${ts}_current_ring_reads_tmp.txt > /dev/shm/${ts}_current_ring_reads_passed_for_density_tmp.txt
					else #options 3 or 4
						if [ $low_density_reads_removal_choice -eq 3 ]
						then
							awk -F "\t" -v sr4dc=${starting_read_for_density_check} '{if (NR < sr4dc || $5 >= $10) print}' /dev/shm/${ts}_current_ring_reads_w_dens_threshold_tmp.txt|cut -f9-11 --complement  -d $'\t' > /dev/shm/${ts}_current_ring_reads_passed_for_density_tmp.txt
						else
							awk -F "\t" -v sr4dc=${starting_read_for_density_check} '{if (NR < sr4dc || $5 >= $11) print}' /dev/shm/${ts}_current_ring_reads_w_dens_threshold_tmp.txt|cut -f9-11 --complement  -d $'\t' > /dev/shm/${ts}_current_ring_reads_passed_for_density_tmp.txt
						fi
						
						#Line before 4/10/217
						#awk -F "\t" -v sr4dc=${starting_read_for_density_check} -v md=${min_allowed_density} '{if (NR < sr4dc || $5 >= md) print}' /dev/shm/${ts}_current_ring_reads_tmp.txt > /dev/shm/${ts}_current_ring_reads_passed_for_density_tmp.txt
					
					fi
					
					#Get the count of reads left after removal
					let remaining_reads_after_removal_of_low_density_reads=$(cat /dev/shm/${ts}_current_ring_reads_passed_for_density_tmp.txt|wc -l)

					#Copy them back to *_current_ring_reads_tmp.txt
					mv /dev/shm/${ts}_current_ring_reads_passed_for_density_tmp.txt /dev/shm/${ts}_current_ring_reads_tmp.txt
				
				fi #Done: if there are rejected reads in first ring
			fi	#Done: first ring (pith side)
#exit			
			#Last ring (bark side)
			#----------------------------------------------------------------------------------------------------------
			if [ $ring_no -eq $max_ring_no_in_sum ]
			then
				#echo "last ring bark side: ${ring_no}"
				#Note: BARK side is the one encountered FIRST in the .dat files! Hence, the <100 density reads, if present, will be at the beginning of the current ring file.
								
				#Add columns for density threshold a) gradual b) fixed
				awk -F "\t" -v r2cb=${reads_to_check_for_density_barkside} -v md=${min_allowed_density} -v tds=${varying_threshold_step} '{print $0"\t"NR"\t"md-(NR-1)*tds"\t"md}' /dev/shm/${ts}_current_ring_reads_tmp.txt > /dev/shm/${ts}_current_ring_reads_w_dens_threshold_tmp.txt
									
				
				#Rejected reads
				
				#1. Reject the last read below the GRADUAL density threshold, and all previous reads
				#2. Reject the last read below the FIXED density threshold, and all previous reads
				#3. Reject only reads below the GRADUAL density threshold
				#4. Reject only reads below the FIXED density threshold

				if [ $low_density_reads_removal_choice -lt 3 ]
				
				then #Option 1 or 2 chosen: last low-density read and all previous reads are removed
					
					last_rejected_read_line_no=""
					
					if [ $low_density_reads_removal_choice -eq 1 ]
					then	#Option 1
						last_rejected_read_line_no=$(awk -F "\t" -v r2cb=${reads_to_check_for_density_barkside} '{if (NR <= r2cb && $5 < $10) print NR}' /dev/shm/${ts}_current_ring_reads_w_dens_threshold_tmp.txt|tail -1)
					else	#Option 2
						last_rejected_read_line_no=$(awk -F "\t" -v r2cb=${reads_to_check_for_density_barkside} '{if (NR <= r2cb && $5 < $11) print NR}' /dev/shm/${ts}_current_ring_reads_w_dens_threshold_tmp.txt|tail -1)
					fi
				
					#Line before 4/10/2017
					#last_rejected_read_line_no=$(awk -F "\t" -v r2cb=${reads_to_check_for_density_barkside} -v md=${min_allowed_density} '{if (NR <= r2cb && $5 < md) print NR}' /dev/shm/${ts}_current_ring_reads_tmp.txt|tail -1)
				
					#If there was at least one line found (options 1 or 2)
					if [ ! -z ${last_rejected_read_line_no} ]
					then
						#Rejected reads		
						awk -F "\t" -v lrrln=${last_rejected_read_line_no} '{if (NR <= lrrln) print}' /dev/shm/${ts}_current_ring_reads_tmp.txt > /dev/shm/${ts}_current_ring_reads_rejected_for_low_density_tmp.txt
					fi
				
				
				else #Option 3 or 4 chosen: only low-density reads are removed
					
					if [ $low_density_reads_removal_choice -eq 3 ]
					then	#Option 3
						awk -F "\t" -v r2cb=${reads_to_check_for_density_barkside} '{if (NR <= r2cb && $5 < $10) print}' /dev/shm/${ts}_current_ring_reads_w_dens_threshold_tmp.txt|cut -f9-11 --complement  -d $'\t' > /dev/shm/${ts}_current_ring_reads_rejected_for_low_density_tmp.txt
					else	#Option 4
						awk -F "\t" -v r2cb=${reads_to_check_for_density_barkside} '{if (NR <= r2cb && $5 < $11) print}' /dev/shm/${ts}_current_ring_reads_w_dens_threshold_tmp.txt|cut -f9-11 --complement  -d $'\t' > /dev/shm/${ts}_current_ring_reads_rejected_for_low_density_tmp.txt
					fi
				fi
				
				#Count the number of rejected reads
				if [ -e /dev/shm/${ts}_current_ring_reads_rejected_for_low_density_tmp.txt ]
				then
					rejected_reads_counts=$(cat /dev/shm/${ts}_current_ring_reads_rejected_for_low_density_tmp.txt|wc -l)
				else
					rejected_reads_counts=0
				fi

				
				
				#If there are rejected reads
				if [ ${rejected_reads_counts} -gt 0 ] #;then echo warning;fi
				then
					#echo "Warning: ${rejected_reads_counts} low density reads found on bark side."
					ring_error_message="${rejected_reads_counts} low density (< ${min_allowed_density} km/m3) reads in ${reads_to_check_for_density_barkside} last reads of ring ${ring_no} (bark side) were removed from results."
					ring_error_code="W13"
					#Add ring to /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
					printf "${sample_name}\t${ring_no}\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
					
					#Put those rejected reads in the all_reads_rejected_for_low_density.txt file.
					cat /dev/shm/${ts}_current_ring_reads_rejected_for_low_density_tmp.txt >> ${temp_f}/logs_and_summaries/intermediate/all_reads_rejected_for_low_density.txt
					
					#Kept reads
					if [ $low_density_reads_removal_choice -lt 3 ]
					then #options 1 or 2
						awk -F "\t" -v lrrln=${last_rejected_read_line_no} '{if (NR > lrrln) print}' /dev/shm/${ts}_current_ring_reads_tmp.txt > /dev/shm/${ts}_current_ring_reads_passed_for_density_tmp.txt
					else	#options 3 or 4
						if [ $low_density_reads_removal_choice -eq 3 ]
						then
							awk -F "\t" -v r2cb=${reads_to_check_for_density_barkside}  '{if (NR > r2cb || $5 >= $10) print}' /dev/shm/${ts}_current_ring_reads_w_dens_threshold_tmp.txt|cut -f9-11 --complement  -d $'\t' > /dev/shm/${ts}_current_ring_reads_passed_for_density_tmp.txt
						else
							awk -F "\t" -v r2cb=${reads_to_check_for_density_barkside}  '{if (NR > r2cb || $5 >= $11) print}' /dev/shm/${ts}_current_ring_reads_w_dens_threshold_tmp.txt|cut -f9-11 --complement  -d $'\t' > /dev/shm/${ts}_current_ring_reads_passed_for_density_tmp.txt
						fi
						
						#Line before 4/10/2017
						#awk -F "\t" -v r2cb=${reads_to_check_for_density_barkside} -v md=${min_allowed_density} '{if (NR > r2cb || $5 >= md) print}' /dev/shm/${ts}_current_ring_reads_tmp.txt > /dev/shm/${ts}_current_ring_reads_passed_for_density_tmp.txt
					fi
				
					#Get the count of reads left after removal
					let remaining_reads_after_removal_of_low_density_reads=$(cat /dev/shm/${ts}_current_ring_reads_passed_for_density_tmp.txt|wc -l)
					
					#Copy them back to *_current_ring_reads_tmp.txt
					cp /dev/shm/${ts}_current_ring_reads_passed_for_density_tmp.txt /dev/shm/${ts}_current_ring_reads_tmp.txt
				
				fi #Done: if there are rejected reads in last ring
			fi	#Done: last ring (bark side)
		
			#[new 29/9/2017]: After removal of reads, check if more reads than the mimimum required still remain (min_reads_per_ring_dat=5)
			#Note 1: This was already checked on the original .dat file (W1), but the status may have changed after the removal of reads of low density above
			
			#This condition ensures that the following block is done only when there were some low-density reads removal above
			#----------------------------------------------------------------------------------------------------------
			if [ ${rejected_reads_counts} -gt 0 ]
			then
				
				#If there were some reads removed, but there are still reads remaining.
				if [ ${remaining_reads_after_removal_of_low_density_reads} -gt 0 ]
				then
					#Alter ring_start_pos and ring_end_pos, which were originally derived from the *_rings_tmp.txt file
					#ring_start_pos= Last position at bottom of the remaining reads file
					ring_start_pos=$(tail -1 /dev/shm/${ts}_current_ring_reads_tmp.txt|cut -f4)
					#ring_end_pos= First position at top of the remaining reads file
					ring_end_pos=$(head -1 /dev/shm/${ts}_current_ring_reads_tmp.txt|cut -f4)
							

					#[20190617] Print start/end positions and number of reads, after some invalid density reads were removed
					printf "\Final ring start pos/ring end pos/number of reads: ${ring_start_pos}/${ring_end_pos}/${remaining_reads_after_removal_of_low_density_reads}\n" 

					
					#If there are less reads remaining than the minimal amount required
					if [ ${remaining_reads_after_removal_of_low_density_reads} -lt ${min_reads_per_ring_dat} ]
					then
						#Log lines below add too much information (they could be added if needed):
						#	printf "\tW14.\tToo few reads for ring ${ring_no} after removal of low-density reads!\n"
						#	printf "Rejected reads:\n"
						#	perl -pe 's/^/\t\t/g' /dev/shm/${ts}_current_ring_reads_rejected_for_low_density_tmp.txt
						#	printf "Kept reads:\n"
						#	perl -pe 's/^/\t\t/g' /dev/shm/${ts}_current_ring_reads_passed_for_density_tmp.txt
						
						#Add ring to /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
						printf "${sample_name}\t${ring_no}\tW14\tRing only has ${remaining_reads_after_removal_of_low_density_reads} read(s) after removal of low-density reads. The minimum number of allowed reads per ring (min_reads_per_ring_dat) in .dat files is ${min_reads_per_ring_dat}.\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
					fi
				
				else #if there's no more reads left!
					
					#These comments were removed to avoid too much info onscreen
					#printf "\tNo reads left for ring ${ring_no} after removal of low-density reads.\n"
					#printf "Rejected reads:\n"
					#perl -pe 's/^/\t\t/g' /dev/shm/${ts}_current_ring_reads_rejected_for_low_density_tmp.txt
					#printf "This will become an E12 error for the current sample.\n"
					
					#Add ring to /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt					
					printf "${sample_name}\t${ring_no}\tW15\tRing has no reads left after removal of low-density reads. This will lead to an E12 error.\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
				
				fi
				
			fi
		
		fi	#DONE: First (pith) and last (bark) rings checked for low density reads

		
#exit		
		
		

		#Count the final number of reads (lines), after the above low density reads (if any) were removed from FIRST and LAST ring.
		#These INCLUDE any other extreme density values as determined by ${min_allowed_density} and ${max_allowed_density}, that are removed below
		number_of_reads=$(cat /dev/shm/${ts}_current_ring_reads_tmp.txt|wc -l)
		
		min_dens="\N"
		max_dens="\N"
		avg_dens="\N"
		mid_range_dens="\N"
		median_dens="\N"
		transition_dens="\N"
			
		
		#Go on to CALCULATE STATS AND TRANSITION ONLY IF THERE ARE ACTUAL READS for that ring in the .dat file (after removal of low-density reads from first/last rings).
		#Note: this can be any ring (first, last, or any in between)
		#----------------------------------------------------------------------------------------------------------
		if [ ${number_of_reads} -gt 0 ]
		then
					
			#[NEW 4/7/2018]
			#Like for the regroup_ss_data.txt script, create a list of densities without extreme values (< min_allowed_density OR > max_allowed_density)
			#Removal of those outside-range densities is ONLY for min/max/avg/mid-range/median density calculations
			#...the extreme reads WILL BE kept in the final file.
					
			#List any extreme density reads
			awk -F "\t" -v dmin=${min_allowed_density} -v dmax=${max_allowed_density} '{if ($5 < dmin || $5 > dmax ) print $5}' /dev/shm/${ts}_current_ring_reads_tmp.txt|sort -k1,1n > /dev/shm/${ts}_current_ring_densities_outside_boundaries.txt
			#19.66
			#39.50
			#56.34
			
			#[20190617] Number of reads outside boundaries
			curr_ring_extreme_reads=$(cat /dev/shm/${ts}_current_ring_densities_outside_boundaries.txt|wc -l)

			#If some extremet density values were found, warn
			#----------------------------------------------------------------------------------------------------------
			if [ ${curr_ring_extreme_reads} -gt 0 ]
			then
				ring_error_message="There are some extreme density (< ${min_allowed_density} OR > ${max_allowed_density} kg/m3) reads in the .DAT file. These reads will be removed before calculating stats (min/mx/avg/median), but will be kept in the final file."
				ring_error_code="W16"
				#Add ring to /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
				printf "${sample_name}\t${ring_no}\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
			
				
				#Within boundaries (normal density reads)
				awk -F "\t" -v dmin=${min_allowed_density} -v dmax=${max_allowed_density} '{if ($5 >= dmin && $5 <= dmax ) print $5}' /dev/shm/${ts}_current_ring_reads_tmp.txt|sort -n > /dev/shm/${ts}_current_ring_clean_densities_ordered.txt
				#216.69
				#218.95
				#220.80
				#222.03
				#223.17
				#(...)
			
			
				#Subset of $number_of_reads above, after removal of OUTSIDE-RANGE densities
				curr_ring_clean_reads=$(cat /dev/shm/${ts}_current_ring_clean_densities_ordered.txt|wc -l)
				
				#[20190617] Only there will we calculate stats for extreme densities
				extreme_dens_avg=$(awk -F "\t" 'BEGIN { sum=0; count=0 } { if ($1 > 0) {sum+=$1;count+=1}; } END { print sum/count;}' /dev/shm/${ts}_current_ring_densities_outside_boundaries.txt)
				normal_dens_avg=$(if [ $curr_ring_clean_reads -eq 0 ]; then echo "N/A";else echo $(awk -F "\t" 'BEGIN { sum=0; count=0 } { if ($1 > 0) {sum+=$1;count+=1}; } END { print sum/count;}' /dev/shm/${ts}_current_ring_clean_densities_ordered.txt);fi)
				
				#$(awk -F "\t" 'BEGIN { sum=0; count=0 } { if ($1 > 0) {sum+=$1;count+=1}; } END { print sum/count;}' /dev/shm/${ts}_current_ring_clean_densities_ordered.txt)
				
				all_dens_avg=$(awk -F "\t" 'BEGIN { sum=0; count=0 } { if ($5 > 0) {sum+=$5;count+=1}; } END { print sum/count;}' /dev/shm/${ts}_current_ring_reads_tmp.txt)
				
				extreme_dens_pct=$(printf "%4g\n" $(echo "scale=3; $curr_ring_extreme_reads/$number_of_reads*100" | bc))
				normal_dens_pct=$(if [ $curr_ring_clean_reads -gt 0 ] ; then printf "%4g\n" $(echo "scale=3; $curr_ring_clean_reads/$number_of_reads*100" | bc);else printf "0";fi)
				
				printf "\tStats on extreme values:\n"
				printf "\t\tClass  \tDensity\tRows\tPercent\n"
				printf "\t\tExtreme\t${extreme_dens_avg}\t${curr_ring_extreme_reads}\t${extreme_dens_pct}\n"
				printf "\t\tNormal \t${normal_dens_avg}\t${curr_ring_clean_reads}\t${normal_dens_pct}\n"
				printf "\t\tTOTAL  \t${all_dens_avg}\t${number_of_reads}\t$(printf "%4g\n" $(echo "scale=3; $number_of_reads/$number_of_reads*100" | bc))\n"
			
				#Si le % de lectures de densité extrème dépasse celui permis (affichera 1 ligne et l'expression sera vraie), mettre le cerne dans la liste d'invalides
				if [ $(printf "$extreme_dens_pct\t$extreme_densities_max_pct_allowed\n"|awk -F "\t" '{if($1 > $2) print}'|wc -l) -gt 0 ]
				then
					
					#Warning/error code and message
					ring_error_message="Invalid ring. Percent extreme density reads (${extreme_dens_pct}%%) is above the accepted limit (${extreme_densities_max_pct_allowed}%%). Average density for extreme reads: ${extreme_dens_avg} kg/m3"
					ring_error_code="W19"
			
					#Print onscreen
					#printf "\t\t${yellow_color}${ring_error_message}.${normal_color}\n"
				
				
					#Add ring to /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
					printf "${sample_name}\t${ring_no}\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt

				
					#Add a line to /dev/shm/${ts}_invalid_rings_due_to_extreme_densities.txt
					printf "${sample_name}\t${ring_no}\t${ring_error_message}. Auto-flagged by $0 on ${pgf_date}.\n" >> /dev/shm/${ts}_invalid_rings_due_to_extreme_densities.txt
					#14	20	Invalid ring. Percent extreme density reads ( 100%) is above the accepted limit (50%). Average density for extreme reads: 9.81722 kg/m3. Auto-flagged by recalc_Quintek_densitometry_files_20190712.txt on 2019-07-12.
					#14	19	Invalid ring. Percent extreme density reads ( 100%) is above the accepted limit (50%). Average density for extreme reads: 10.9771 kg/m3. Auto-flagged by recalc_Quintek_densitometry_files_20190712.txt on 2019-07-12.
					#14	18	Invalid ring. Percent extreme density reads ( 100%) is above the accepted limit (50%). Average density for extreme reads: 11.6472 kg/m3. Auto-flagged by recalc_Quintek_densitometry_files_20190712.txt on 2019-07-12.

				
					#[20190625]
					current_sample_invalid_rings+=1
				
				fi

				
				#exit
			
			else	#There are NO extreme density values
			
				#Simply copy the density column from ${ts}_current_ring_reads_tmp.txt to ${ts}_current_ring_clean_densities_ordered.txt
				awk -F "\t" '{print $5}' /dev/shm/${ts}_current_ring_reads_tmp.txt|sort -n > /dev/shm/${ts}_current_ring_clean_densities_ordered.txt
			
				#Number of clean reads = total number of reads
				curr_ring_clean_reads=${number_of_reads}
			
			fi

			
			
			
			#If there are still at least 2 density reads after removing the extremes, calculate the stats
			#[NEW 4/7/2018]
			#Otherwise, transition WILL NOT BE CALCULATED
			#----------------------------------------------------------------------------------------------------------
			if [ ${curr_ring_clean_reads} -gt 1 ]
			then
				#Calculate stats from densities where extremes were removed (/dev/shm/${ts}_current_ring_clean_densities_ordered.txt)
				min_dens=$(head -1 /dev/shm/${ts}_current_ring_clean_densities_ordered.txt)
				max_dens=$(tail -1 /dev/shm/${ts}_current_ring_clean_densities_ordered.txt)
				avg_dens=$(awk -F "\t" 'BEGIN { sum=0; count=0 } { if ($1 > 0) {sum+=$1;count+=1}; } END { print sum/count;}' /dev/shm/${ts}_current_ring_clean_densities_ordered.txt)
				mid_range_dens=$(echo "scale=1;(${min_dens}+${max_dens})/2"|bc)
				#Use function to get median density
				fnct_get_median_value /dev/shm/${ts}_current_ring_clean_densities_ordered.txt
				median_dens=${median_value}
				
				#Transition density obtained from one of the methods below (NEW: 4/7/2018):
				#1. Mid-range value method
				#2. Median value method
			
				case $ewlw_transition_method in
				1)	#Mid-range
					transition_dens=${mid_range_dens}
					transition_method="Mid-range"
					;;
				2)	#Median
					transition_dens=${median_dens}
					transition_method="Median"
					;;
				
				*)	#Any other value = Mid-range (DEFAULT)
					transition_dens=${mid_range_dens}
					transition_method="Mid-range"
					;;
				esac
				
				
				#Ring width. Note: this time, it is calculated as previous ring's end position (ring_start_pos + step of 0.04) less current ring's end position
				#Note: if low-density reads were removed, ring_start_pos and ring_end_pos were modified above to account for reduced number of reads
				#See line ~ 1585 above.
				ring_width=$(echo "scale=3;$ring_start_pos+$step-$ring_end_pos"|bc)
				
				printf "\tmin/max/avg/mid-range/median/transition densities: ${min_dens}/${max_dens}/${avg_dens}/${mid_range_dens}/${median_dens}/${transition_dens}\n" 
			fi
#echo "fin"
#exit

				
			#Check if there are enough reads to calculate transition (once low density reads (if any) were removed from FIRST and LAST ring. Extreme density reads kept)
			#----------------------------------------------------------------------------------------------------------
			#[NEW: 5/7/2018] added the requirement to have a valid transition density, calculated only when sufficient cleaned density reads are available.
			if [ ${number_of_reads} -ge ${min_reads_for_transition} ] && [ ${transition_dens} != "\N" ]
			then #there are enough reads
			
			
				#Sort the file in reverse order of position, to get the density profile correctly (low in early wood, high in latewood).
				#Note: done by copying the 4th column (position) in first column and sorting by that first column, to avoid problematic ordering sometimes encountered by sort when using a column in the middle of a file.
				#then the sorting column is removed.
				#Ok with new line numbering (14/6/2017)
				paste <(cut -f4 -d $'\t' /dev/shm/${ts}_current_ring_reads_tmp.txt) /dev/shm/${ts}_current_ring_reads_tmp.txt|sort -nrk1,1|cut -f1 -d $'\t' --complement > /dev/shm/${ts}_current_ring_reads_inverted_tmp.txt
					#A4	2014	11	3.960	241.73	11	E	  1001
					#A4	2014	11	3.920	236.84	11	E	  1002
					#A4	2014	11	3.880	238.40	11	E	  1003
					#A4	2014	11	3.840	242.88	11	E	  1004
					#A4	2014	11	3.800	248.10	11	E	  1005
					#A4	2014	11	3.760	239.75	11	E	  1006
					#A4	2014	11	3.720	259.43	11	E	  1007
					#Note: last column is line numbering from pith to bark.
				
				#Adding two columns at the end: 1) column with next line's density; 2) column with second next line's density.
				#Ok with new line numbering (14/6/2017)
				paste /dev/shm/${ts}_current_ring_reads_inverted_tmp.txt <(cut -f5 -d $'\t' /dev/shm/${ts}_current_ring_reads_inverted_tmp.txt|tail -n+2|cat - <(printf "0\n")) <(cut -f5 -d $'\t' /dev/shm/${ts}_current_ring_reads_inverted_tmp.txt|tail -n+3|cat - <(printf "0\n0\n")) > /dev/shm/${ts}_current_ring_reads_inverted_with_next_2_densities_tmp.txt
					#A4      2014    11      3.960   241.73  11      E         1001  236.84  238.40
					#A4      2014    11      3.920   236.84  11      E         1002  238.40  242.88
					#A4      2014    11      3.880   238.40  11      E         1003  242.88  248.10
					#A4      2014    11      3.840   242.88  11      E         1004  248.10  239.75
					#A4      2014    11      3.800   248.10  11      E         1005  239.75  259.43
					#A4      2014    11      3.760   239.75  11      E         1006  259.43  261.74
					#A4      2014    11      3.720   259.43  11      E         1007  261.74  267.33
					#A4      2014    11      3.680   261.74  11      E         1008  267.33  260.06
					#A4      2014    11      3.640   267.33  11      E         1009  260.06  286.54
					#A4      2014    11      3.600   260.06  11      E         1010  286.54  263.53



				


				#Determine transition. Note that there might be several lines meeting theses criteria!
				#----------------------------------------------------------------------------------------------------------
				#[NEW 5/7/2016]: save all possible lines where criteria met, then choose according to a parameter.
				
				#Find where latewood starts. Latewood begins at the first line where: 
				# 1) density reading < transition density, AND
				# 2) next line density reading >= transition density, AND
				# 3) second next line density reading >= transition density
				#In case no row is found, the result will be an empty string
				#New line 14/6/2017 (with line numberings)
				awk -F "\t" -v md=${transition_dens} '{if ($5 < md && $9 >= md && $10 >= md) print $4"\t"NR}' /dev/shm/${ts}_current_ring_reads_inverted_with_next_2_densities_tmp.txt > /dev/shm/${ts}_all_latewood_possible_positions_and_line_nos.txt
				transition_rows_found=$(cat /dev/shm/${ts}_all_latewood_possible_positions_and_line_nos.txt|wc -l)
				
#exit							
				#5/7/2016
				#If transition WAS found
				#----------------------------------------------------------------------------------------------------------
				if [ $transition_rows_found -gt 0 ]
				then
		
					#If there is only one possible transition
					if [ $transition_rows_found -eq 1 ]
					then	
						#Get the first (and only) row. Note that since there's only one row, head -1 would not be required.
						first_latewood_position=$(cut -f1 /dev/shm/${ts}_all_latewood_possible_positions_and_line_nos.txt|head -1)
						first_latewood_line_no=$(cut -f2 /dev/shm/${ts}_all_latewood_possible_positions_and_line_nos.txt|head -1)
						
					#There are several transitions possible
					else
						if [ $multiple_transitions_option -eq 1 ]
						then
							#multiple_transitions_option=1 (DEFAULT) ---> last transition found
							first_latewood_position=$(cut -f1 /dev/shm/${ts}_all_latewood_possible_positions_and_line_nos.txt|tail -1)
							first_latewood_line_no=$(cut -f2 /dev/shm/${ts}_all_latewood_possible_positions_and_line_nos.txt|tail -1)
							
							#Check W9 (.sum/.dat): If several transitions were found, notice that and the choice made.
							#printf "\t\tOnly the last row found (nearer the ring end) was kept (multiple_transitions_option=1).\n"
							ring_error_message="${transition_rows_found} transition points were found within the ring. Only the last transition found (nearer the ring end) was kept (multiple_transitions_option=1)."
						
						else
							#multiple_transitions_option=2 ---> first transition found
							first_latewood_position=$(cut -f1 /dev/shm/${ts}_all_latewood_possible_positions_and_line_nos.txt|head -1)
							first_latewood_line_no=$(cut -f2 /dev/shm/${ts}_all_latewood_possible_positions_and_line_nos.txt|head -1)
							
							#Check W9 (.sum/.dat): If several transitions were found, notice that and the choice made.
							#printf "\t\tOnly the first row found (nearer the ring start) was kept (multiple_transitions_option=2).\n"
							ring_error_message="${transition_rows_found} transition points were found within the ring. Only the first transition found (nearer the ring start) was kept (multiple_transitions_option=2)."

						fi
						ring_error_code="W9"
						#Add ring to /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
						printf "${sample_name}\t${ring_no}\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt

					
					
					fi
				
					#Make sure found transition it is not in the first 5% of reads
					#Get ew proportion (line number of last ew read (equal to the first lw read - 1) / total number of reads)
					#If lw line no is 1 (first read of the ring), ew_reads_from_1st_lw_position will = 0
					ew_reads_from_1st_lw_position=$(echo "scale=0;(${first_latewood_line_no})-1"|bc)
					
					#Note:  actual_ew_proportion will = 0 if ew_reads_from_1st_lw_position = 0
					actual_ew_proportion=$(echo "scale=3;(${first_latewood_line_no}-1)/${number_of_reads}"|bc)
					
					#If ew proportion less than min_ew_proportion, set low_ew_proportion=1. Else, low_ew_proportion=2 (normal). 
					low_ew_proportion=$(printf "${actual_ew_proportion}\t${min_ew_proportion}\n"|awk -F "\t" '{if ($1 < $2) print "1";else printf "2"}')
					if [ $low_ew_proportion -eq 1 ]
					then
						first_latewood_position="" #The transition field will be filled with \N values
												
						if [ $ew_reads_from_1st_lw_position -eq 0 ] # no ew reads at all!
						then
							ring_error_message="No early wood reads at the start of the ring. Transition will not be calculated."
							ring_error_code="W5"
							#Add ring to /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
							printf "${sample_name}\t${ring_no}\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
						else # too few ew reads!
							ring_error_message="Number of early wood reads (${ew_reads_from_1st_lw_position}) is too low. Transition will not be calculated if proportion of ew reads is < ${min_ew_proportion}. Actual ew proportion: ${actual_ew_proportion}."
							ring_error_code="W6"
							#Add ring to /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
							printf "${sample_name}\t${ring_no}\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
						
						fi
					fi
					
					
				else #transition NOT found ($transition_rows_found = 0) using the median density
					#----------------------------------------------------------------------------------------------------------
					#[NEW: 5/7/2018] ... or because transition density could not be calculated.
					
					first_latewood_position=""
					first_latewood_line_no=""				
				
					#...no transition was found (${transition_rows_found} = 0)
					ring_error_message="Early to late wood transition could not be calculated because no clear shift in density could be found."
					ring_error_code="W4"
					#Add ring to /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
					printf "${sample_name}\t${ring_no}\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt

				
				fi
				
				
				
				#Add the transition column: 1=early wood, 2=late wood, \N=not found.
				#Remove the next row and second next row density columns
				#Reorder by position
				#Line before 4/7/2016: awk -F "\t" -v flwp=${first_latewood_position} '{if (flwp == "") print $0"\t\\N"; else if ($4 <= flwp) print $0"\t2"; else print $0"\t1"}' /dev/shm/current_ring_reads_inverted_with_next_2_densities_tmp.txt|cut -f6,7 -d $'\t' --complement|paste <(cut -f4 -d $'\t' /dev/shm/current_ring_reads_inverted_with_next_2_densities_tmp.txt) -|sort -nk1,1|cut -f1 -d $'\t' --complement > /dev/shm/current_ring_reads_with_transition_tmp.txt
				#Line before 14/6/2017: awk -F "\t" -v flwp=${first_latewood_position} '{if (flwp == "") print $0"\t\\N"; else if ($4 <= flwp) print $0"\t2"; else print $0"\t1"}' /dev/shm/current_ring_reads_inverted_with_next_2_densities_tmp.txt|cut -f8,9 -d $'\t' --complement|paste <(cut -f4 -d $'\t' /dev/shm/current_ring_reads_inverted_with_next_2_densities_tmp.txt) -|sort -nk1,1|cut -f1 -d $'\t' --complement > /dev/shm/current_ring_reads_with_transition_tmp.txt
				
				#New line 14/6/2017 (with new line numbers)
				awk -F "\t" -v flwp=${first_latewood_position} '{if (flwp == "") print $0"\t\\N"; else if ($4 <= flwp) print $0"\t2"; else print $0"\t1"}' /dev/shm/${ts}_current_ring_reads_inverted_with_next_2_densities_tmp.txt|cut -f9,10 -d $'\t' --complement|paste <(cut -f4 -d $'\t' /dev/shm/${ts}_current_ring_reads_inverted_with_next_2_densities_tmp.txt) -|sort -nk1,1|cut -f1 -d $'\t' --complement > /dev/shm/${ts}_current_ring_reads_with_transition_tmp.txt
				
				#/dev/shm/${ts}_current_ring_reads_with_transition_tmp.txt
				#	A4      2014    11      1.200   336.42  11      E         1070  2
				#	A4      2014    11      1.240   482.57  11      E         1069  2
				#	A4      2014    11      1.280   534.30  11      E         1068  2
				#	A4      2014    11      1.320   604.33  11      L         1067  2
				#	A4      2014    11      1.360   644.25  11      L         1066  2
				#	A4      2014    11      1.400   655.25  11      L         1065  2
				#	A4      2014    11      1.440   636.99  11      L         1064  2
				#	A4      2014    11      1.480   608.09  11      L         1063  2
				#	A4      2014    11      1.520   592.61  11      L         1062  2
				#	A4      2014    11      1.560   560.30  11      E         1061  2

				
				#Column #1: sample number (from .sum file)
				#Column #2: year (from .sum file)
				#Column #3: ring number (from .sum file)
				#Column #4: position (from .dat file)
				#Column #5: density (from .dat file)
				#Column #6: ring number (from .dat file)
				#Column #7: wood type (from .dat file)
				#Column #8: line numbering, pith to bark.
				#Column #9: NEWLY calculated transition
	
			
			else	#Not enough reads to calculate transition, simply add "\N" as transition at the end of the file.
				#----------------------------------------------------------------------------------------------------------
				#[NEW: 5/7/2018] Or simply no transition density.
				
				#Ok with new line numbering (14/6/2017)
				awk -F "\t" '{print $0"\t\\N"}' /dev/shm/${ts}_current_ring_reads_tmp.txt >/dev/shm/${ts}_current_ring_reads_with_transition_tmp.txt
				
				#A4      2014    11      1.200   336.42  11      E         1070  \N
				#A4      2014    11      1.240   482.57  11      E         1069  \N
				#A4      2014    11      1.280   534.30  11      E         1068  \N
				#A4      2014    11      1.320   604.33  11      L         1067  \N
				#A4      2014    11      1.360   644.25  11      L         1066  \N
				#A4      2014    11      1.400   655.25  11      L         1065  \N
				#A4      2014    11      1.440   636.99  11      L         1064  \N
				#A4      2014    11      1.480   608.09  11      L         1063  \N
				#A4      2014    11      1.520   592.61  11      L         1062  \N
				#A4      2014    11      1.560   560.30  11      E         1061  \N
				
				#[Added 18/9/2017] This will signal the script not to calculate the EW/LW stats below
				first_latewood_position=""
			
				
				
				#W3: less reads than required for transition ?
				#[29/9/2017] W3 check moved here
					
				if [ ${number_of_reads} -lt ${min_reads_for_transition} ]
				then
					ring_error_message="Early to late wood transition could not be calculated because there are only ${number_of_reads} reads in the ring. Minimum number of reads required is ${min_reads_for_transition}."
					ring_error_code="W3"
					#Add ring to /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
					printf "${sample_name}\t${ring_no}\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
				fi
				
				#W17: no transition_dens could be calculated because not enough clean density values available!
				if [ ${transition_dens} == "\N" ]
				then
					ring_error_message="Not enough (<2) valid density reads after extreme values (< ${min_allowed_density} OR > ${max_allowed_density} kg/m3) were removed from the the .DAT file. Transition will NOT be calculated."
					ring_error_code="W17"
					#Add ring to /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
					printf "${sample_name}\t${ring_no}\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
				fi
				

				
			#exit
			
			
			fi



			#Put that in the corrected reads file
			#----------------------------------------------------------------------------------------------------------
			#Ok with new line numbers, 14/6/2017
			cat /dev/shm/${ts}_current_ring_reads_with_transition_tmp.txt >> "${temp_f}/corrected_files/${sample_name}_corr_reads.txt"
		
				#A4      2014    11      1.200   336.42  11      E         1070  2
				#A4      2014    11      1.240   482.57  11      E         1069  2
				#A4      2014    11      1.280   534.30  11      E         1068  2
				#A4      2014    11      1.320   604.33  11      L         1067  2
				#A4      2014    11      1.360   644.25  11      L         1066  2
				#A4      2014    11      1.400   655.25  11      L         1065  2
				#A4      2014    11      1.440   636.99  11      L         1064  2
				#A4      2014    11      1.480   608.09  11      L         1063  2
				#A4      2014    11      1.520   592.61  11      L         1062  2
				#A4      2014    11      1.560   560.30  11      E         1061  2

		
		


			
			#exit 
					
			#If a transition was found and the minimal reads number is achieved, calculate ew/lw stats
			#----------------------------------------------------------------------------------------------------------
			#Line before 6/7/2016: if [ ! -z ${first_latewood_position} ] && [ ${number_of_reads} -ge ${min_reads_for_transition} ]
			#Line before 18/9/2017: if [ ${transition_rows_found} -gt 0 ] && [ ${number_of_reads} -ge ${min_reads_for_transition} ]
			#	Note: changed 18/9/2017 because in some cases
			#		[ ${number_of_reads} -ge ${min_reads_for_transition} ]  = TRUE
			#		[ ${transition_rows_found} -gt 0 ] = TRUE
			#	but there may not be enough ew reads (low_ew_proportion)=1 to calculate stats below.
			#	Hence, much better to use first_latewood_position (assigned after transition_rows_found) as the validation variable.
			#	first_latewood_position will be equal to "" in the following cases:
			#		transitions_row_found=0: no lw could be found using the median density transition method.
			#		low_ew_proportion=1: there is not enough ew reads to calculate transition/lw position.
			#echo "first_latewood_position: _${first_latewood_position}_"
			if [ ! -z ${first_latewood_position} ] #If THERE IS a latewood position.
			then
				#printf "Calc ${ring_no} ew/lw stats..." For debugging
				#Get stats for EW/LW
				#Corrected for new line numbering (14/6/2017)
				min_ew_dens=$(awk -F "\t" '(minew=="" || $5 < minew) && $9 == 1 {minew=$5} END {print minew}' FS="\t" /dev/shm/${ts}_current_ring_reads_with_transition_tmp.txt)
				min_lw_dens=$(awk -F "\t" '(minlw=="" || $5 < minlw) && $9 == 2 {minlw=$5} END {print minlw}' FS="\t" /dev/shm/${ts}_current_ring_reads_with_transition_tmp.txt)
				max_ew_dens=$(awk -F "\t" '(maxew=="" || $5 > maxew) && $9 == 1 {maxew=$5} END {print maxew}' FS="\t" /dev/shm/${ts}_current_ring_reads_with_transition_tmp.txt)
				max_lw_dens=$(awk -F "\t" '(maxlw=="" || $5 > maxlw) && $9 == 2 {maxlw=$5} END {print maxlw}' FS="\t" /dev/shm/${ts}_current_ring_reads_with_transition_tmp.txt)
				#Average for lines where density > 0
				avg_ew_dens=$(awk -F "\t" 'BEGIN { sum=0; count=0 } { if ($9 == 1 && $5 > 0) {sum+=$5;count+=1}; } END { print sum/count;}' /dev/shm/${ts}_current_ring_reads_with_transition_tmp.txt)
				avg_lw_dens=$(awk -F "\t" 'BEGIN { sum=0; count=0 } { if ($9 == 2 && $5 > 0) {sum+=$5;count+=1}; } END { print sum/count;}' /dev/shm/${ts}_current_ring_reads_with_transition_tmp.txt)
				
				reads_ew=$(awk -F "\t" '{if($9 == 1) print}' /dev/shm/${ts}_current_ring_reads_with_transition_tmp.txt |wc -l)
				reads_lw=$(awk -F "\t" '{if($9 == 2) print}' /dev/shm/${ts}_current_ring_reads_with_transition_tmp.txt |wc -l)
				
				ring_end_pos_ew=$(awk -F "\t" '(minpos=="" || $4 < minpos) && $9 == 1 {minpos=$4} END {print minpos}' FS="\t" /dev/shm/${ts}_current_ring_reads_with_transition_tmp.txt)
				ring_end_pos_lw=$(awk -F "\t" '(minpos=="" || $4 < minpos) && $9 == 2 {minpos=$4} END {print minpos}' FS="\t" /dev/shm/${ts}_current_ring_reads_with_transition_tmp.txt)
				
				ring_start_pos_ew=$(awk -F "\t" '(maxpos=="" || $4 > maxpos) && $9 == 1 {maxpos=$4} END {print maxpos}' FS="\t" /dev/shm/${ts}_current_ring_reads_with_transition_tmp.txt)
				ring_start_pos_lw=$(awk -F "\t" '(maxpos=="" || $4 > maxpos) && $9 == 2 {maxpos=$4} END {print maxpos}' FS="\t" /dev/shm/${ts}_current_ring_reads_with_transition_tmp.txt)
				
				ring_width_ew=$(echo "scale=3;$ring_start_pos_ew-$ring_end_pos_ew+$step"|bc)
				ring_width_lw=$(echo "scale=3;$ring_start_pos_lw-$ring_end_pos_lw+$step"|bc)
				pct_ew=$(echo "scale=3;($ring_width_ew/$ring_width)*100"|bc|awk '{printf "%g\n", $1}')
				pct_lw=$(echo "scale=3;($ring_width_lw/$ring_width)*100"|bc|awk '{printf "%g\n", $1}')
				
				#printf "done\n" #For debugging only
				#if [ $ring_no -le 14 ];then break;fi # For debugging only
				

				printf "\tpct_lw: ${pct_lw}\n"
			



			#If no transition was found or the minimal number of reads was not reached
			#----------------------------------------------------------------------------------------------------------
			else
				min_ew_dens="\N"
				min_lw_dens="\N"
				max_ew_dens="\N"
				max_lw_dens="\N"
				avg_ew_dens="\N"
				avg_lw_dens="\N"
				reads_ew="\N"
				reads_lw="\N"
				ring_end_pos_ew="\N"
				ring_end_pos_lw="\N"
				ring_start_pos_ew="\N"
				ring_start_pos_lw="\N"
				ring_width_ew="\N"
				ring_width_lw="\N"
				pct_ew="\N"
				pct_lw="\N"
			fi

			#Check W7 (.sum/.dat): density values less than minimum limit.
			#	[20180706] ===> No longer in use, replaced with W16
			#Note: even after removal of low-density values above in first (pith) or last (bark) rings, there still may be some low-density values remaining.
			#if [ $(printf "${min_dens}\t${min_allowed_density}\n"|awk -F "\t" '{if ($1 < $2) print "1";else printf "2"}') -eq 1 ]
			#then
			#	ring_error_message="There are density values of less than ${min_allowed_density}."
			#	ring_error_code="W7"
			#	#Add ring error code and message to the file
			#	printf "${sample_name}\t${ring_no}\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
			#fi
		
		else	#No reads found in .dat file for that ring!
			#When no reads found in .dat between start and end positions of .sum:
			#	W23 (zero start/end position ring in .sum file) - added 2023-03-09
			#		or
			#	E12 (valid start/end position values in .sum file, just nothing corresponding found in .dat)
			#----------------------------------------------------------------------------------------------------------
				#NOTE: this might be because:
				#	1) there really weren't any reads in .dat file corresponding to the range in .sum file
				#	2) all reads were removed because they were low-density reads
				#	3) [2023-03-09]: zero-width rings were inserted in the .sum file following tree-ring dating
				#Here, the ring_end_pos and ring_start_pos refer to those from the *_corr_ring_tmp.file
				
				
				#2023-03-09: Zero-width ring found. This represents case #3 above
				#2023-03-13: No longer uniquely for zero values of start/end positions. Any equality between the two will be considered as zero-width ring.
				#The following line check if end position and start position in current .sum line are equal to 0.
				#If they are, it will generate a line, which will then be row-counted as 1
				#Line before 2023-03-13: if [ $(echo ${rings_line}|awk -F "\t" '{if ($4 == 0 && $5 == 0) print}'|wc -l) -eq 1 ]
				if [ $(echo ${rings_line}|awk -F "\t" '{if ($4 == $5 ) print}'|wc -l) -eq 1 ]
				#ex: E60-A-2-032-6-177       36      2013    0.00    0.00    0
				then
					ring_error_message="Zero-width ring found in .sum file."
					ring_error_code="W23"
					#Add ring to /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
					printf "${sample_name}\t${ring_no}\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
				
					#Add a line to /dev/shm/${ts}_other_invalid_rings.txt
					#Column 1: sample name
					#Column 2: ring number
					#Col 3: error message
					#Col 4: 9 = invalid_rings_determination_methods.id 
					#Col 5: FALSE = invalid_rings.is_pith
					#Col 6: NULL = invalid_rings.team_id (no team, auto-generated)
					printf "${sample_name}\t${ring_no}\t${ring_error_message} Auto-flagged by $0 on ${pgf_date}.\t9\tFALSE\t\\N\n" >> /dev/shm/${ts}_other_invalid_rings.txt
					current_sample_invalid_rings+=1
				
				
				else # Just no corresponding reads found in the .dat file
				
					ring_error_message="No reads found between end (${ring_end_pos}) and start (${ring_start_pos}) positions in .dat file corresponding to .sum file ring number ${ring_no}. THE WHOLE .sum FILE SHOULD BE REDONE."
					ring_error_code="E12"
					#Add ring error code and message to the file
					printf "${sample_name}\t${ring_no}\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
				
					#[20190626]: The next 4 lines had been forgotten.
					#With the command "continue" below, the rest of the "for" loop is skipped to go directly to the next sample
					#Thus, we must write the /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt file to the rings_errors_and_warnings.txt and samples_errors_and_warnings.txt files
					fnct_write_warning_and_errors_to_stats_files
					continue
				fi
		fi

		#Onscreen reporting of warning/errors for the current ring
		#If there are error or warning messages related to current ring in /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt, show them onscreen.
		if [ $(awk -F "\t" -v rn=${ring_no} '{if ($2 == rn) print $3"\t"$4}' /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt|wc -l) -ge 1 ]
		then
			#Show all warning/error lines
			#	If a warning 	---> yellow-colored text
			#	If an error		---> red-colored text
			awk -F "\t" -v rn=${ring_no} '{if ($2 == rn ) print $3"\t"$4}' /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt|awk -F "\t" -v rc=${red_color} -v yc=${yellow_color} -v nc=${normal_color} '{if ($1 ~ /E/) printf rc"\t%s\t%s\n"nc, $1, $2; else printf yc"\t%s\t%s\n"nc, $1, $2}'
		fi

		
		#[29/6/2017] Calculate concatenated error codes for the current ring (e.g. E6,W1,W2), to be put instead of $ring_error_message in the ${temp_f}/corrected_files/${sample_name}_corr_ring_stats.txt" file.
		error_codes_concat_per_ring=$(awk -F "\t" -v rn=${ring_no} '{if($2 == rn) print $3}' /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt|sort -u|perl -pe 's/\n/,/g'|perl -pe 's/,$/\n/g')
		
		#Put current ring's info into corrected ring stats file ("${temp_f}/corrected_files/${sample_name}_corr_ring_stats.txt")
		printf "${sample_name}\t${ring_year}\t${ring_no}\t${ring_start_pos}\t${ring_end_pos}\t${number_of_reads}\t${ring_width}\t${avg_dens}\t${min_dens}\t${max_dens}\t${transition_dens}\t${ring_start_pos_ew}\t${ring_end_pos_ew}\t${reads_ew}\t${ring_width_ew}\t${avg_ew_dens}\t${min_ew_dens}\t${max_ew_dens}\t${pct_ew}\t${ring_start_pos_lw}\t${ring_end_pos_lw}\t${reads_lw}\t${ring_width_lw}\t${avg_lw_dens}\t${min_lw_dens}\t${max_lw_dens}\t${pct_lw}\t${error_codes_concat_per_ring}\n" >> "${temp_f}/corrected_files/${sample_name}_corr_ring_stats.txt"
		
		#sample_name	ring_year	ring_no	ring_start_pos	ring_end_pos	number_of_reads	ring_width	ring_dens_avg	ring_dens_min	ring_dens_max	ring_dens_median	ew_start_pos	ew_end_pos	reads_ew	ew_width	ew_dens_avg	ew_dens_min	ew_dens_max	ew_pct	lw_start_pos	lw_end_pos	reads_lw	lw_width	lw_dens_avg	lw_dens_min	lw_dens_max	lw_pct	note
		#A2			2014		11		6.20			1.72			113			4.52		358.01		276.65		774.05		328.22		6.200		4.040		55		2.200		300.751	276.65	334.64		.486		4.000		1.720		58		2.320		412.307	320.73	774.05	.513	
		
		
		#[Added 3/10/2017] IMPORTANT: remove all current ring-specific files to avoid them interfering from ring to ring
		rm -f /dev/shm/${ts}_current_ring*
#exit
		
	done #All rings done


	
	#Check if the full sample must be flagged as invalid, if more than the accepted % of invalid rings is achieved
	#[20190625] If there are invalid rings, get the percentage:
	if [ ${current_sample_invalid_rings} -gt 0 ]
	then
		
		pct_invalid_rings=$(echo "scale=3; ${current_sample_invalid_rings}/${number_of_rings}*100"|bc)
		
		#If pct invalid rings is above threshold
		if [ ! -z $(printf "${pct_invalid_rings}\t${max_pct_invalid_rings_for_invalid_sample}\n"|awk -F "\t" '{if($1 > $2) print $1}') ]
		then
			
			#Set warning/error message and code
			ring_error_message="${pct_invalid_rings}%% (${current_sample_invalid_rings}/${number_of_rings}) of the rings are invalid."
			ring_error_code="W20"
			
			#Add ring warning/error code and message to the file
			printf "${sample_name}\tMANY\t${ring_error_code}\t${ring_error_message}\n" >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt

			#Display the warning/error code and message	
			echo
			printf "${yellow_color}${ring_error_code}. ${ring_error_message}\n"
			printf "The sample is considered as invalid. See the file SQL_UPDATE_invalid_samples.txt.${normal_color}\n"
			
			#Append to SQL_UPDATE_invalid_samples.txt
			
				#Get sample id from equivalency list
				sample_id=$(awk -v sn=${sample_name} -F "\t" '{if ($1 == sn) print $2}' ${eq_list})
				
				#Generate  SQL UPDATE command
				printf "UPDATE germplasms SET sample_is_invalid=TRUE, sample_invalidity_reason='Sample automatically flagged on ${pgf_date} by $0 because ${current_sample_invalid_rings} out of ${number_of_rings} rings (${pct_invalid_rings}%%) are invalid.' WHERE id=${sample_id};" >> ${temp_f}/for_import/SQL_UPDATE_invalid_samples.txt
		
		fi
		
		
		
		
	fi
	
	



	printf "=----------------------------\n"

#exit

	
	#Calculate the pith-to-bark positions (inverted) to be inserted into TreeSource
	#Calculate the sample maximum position from the ring start column.
	#[13/6/2017]
	sample_max_pos=$(cut -f4 "${temp_f}/corrected_files/${sample_name}_corr_ring_stats.txt"|tail -n+2|sort -n|tail -1)
	#echo "sample_max_pos $sample_max_pos"
	
	#13/6/2017: Add inverted positions (ring_start_pos_inv = 0 for ring_no=1), to a temporary file in memory
	#rings file
		#	ring_start_pos_inv, ring_end_pos_inv, ew_start_pos_inv, ew_end_pos_inv, lw_start_pos_inv, lw_end_pos_inv
		awk -F "\t" -v maxpos=${sample_max_pos} '{print $0"\t"maxpos-$4"\t"maxpos-$5"\t"maxpos-$12"\t"maxpos-$13"\t"maxpos-$20"\t"maxpos-$21}' "${temp_f}/corrected_files/${sample_name}_corr_ring_stats.txt" > /dev/shm/${ts}_rings_tmp2.txt
		
		#Add header and put back in corrected rings final file in the ${temp} folder
		cat /dev/shm/${ts}_header_corr_ring_stats.txt /dev/shm/${ts}_rings_tmp2.txt > "${temp_f}/corrected_files/${sample_name}_corr_ring_stats.txt"
		
	
	#reads file
		#
		awk -F "\t" -v maxpos=${sample_max_pos} '{print $0"\t"maxpos-$4}' "${temp_f}/corrected_files/${sample_name}_corr_reads.txt" > /dev/shm/${ts}_reads_tmp2.txt
		#Add header and put back in corrected reads final file in the ${temp} folder
		cat /dev/shm/${ts}_header_corr_reads.txt /dev/shm/${ts}_reads_tmp2.txt > "${temp_f}/corrected_files/${sample_name}_corr_reads.txt"



	#If made it this far, means that no error codes (E) were encountered.
	#Must launch the function to write any warning codes (W) encountered to rings_errors_and_warnings.txt and samples_errors_and_warnings.txt.
	#[3/7/2017] Now uses a function
	fnct_write_warning_and_errors_to_stats_files

done # All samples (.dat files) done



#*_corr_reads.txt file actual format
#------------------------------------------
#sample_name	ring_year_sum	ring_no_sum	pos_dat	density_dat	ring_no_dat	transition_dat	line_no	transition	pos_p2b
#ASS_1_2508_2_A	2017	15	1.800	249.56	15	E	  1205	2	47.68
#ASS_1_2508_2_A	2017	15	1.840	495.74	15	L	  1204	2	47.64
#ASS_1_2508_2_A	2017	15	1.880	460.99	15	L	  1203	2	47.6
#ASS_1_2508_2_A	2017	15	1.920	387.81	15	E	  1202	2	47.56
#ASS_1_2508_2_A	2017	15	1.960	381.11	15	E	  1201	2	47.52
#ASS_1_2508_2_A	2017	15	2.000	366.26	15	E	  1200	2	47.48
#ASS_1_2508_2_A	2017	15	2.040	375.26	15	E	  1199	2	47.44
#
#Column:
#1. sample_name 				(from .dat file name)					
#2. ring_year_sum 				(from .sum file)							===> Unless cross-dating has been simultaneously done, no use to keep
#																	the year here, as it will be deducted from harvest date and last ring (bark side).
#3. ring_no_sum: 				ring number from PITH to bark (from .sum file)	===> x_ray_dens_msmts_per_read.ring_pith_to_bark
#4. pos_dat: 					position, mm from BARK to pith (from .dat file)	===> WILL BE IGNORED. Will use pos_p2b (field #9 below) instead.
#5. density_dat: 					wood density, kg/m3 (from .dat file)			===> x_ray_dens_msmts_per_read.density
#6. ring_no_dat:														===> WILL BE IGNORED, the ring number from the .SUM file will be taken instead.
#7. transition_dat: 				original wood type: E=Early, L=Late (from .dat file). ===> WILL BE IGNORED. Calculated transition (field #8 below) will be used instead.
#8. line_no:					line number, from PITH to bark, based on .dat file.	===> x_ray_dens_msmts_per_read.read_no
#							In the current file, there might be missing line numbers, because lines were excluded from the original .dat files based on .sum files ring delimitations.
#9. transition: 					transition calculated by current script. 			===> x_ray_dens_msmts_per_read.transition
#							1= Early wood, 2= Late wood, \N=no transition could be calculated.
#10. pos_p2b:					position, mm from PITH to bark. 				===> x_ray_dens_msmts_per_read.position
#							Calculated from current script, based on the highest value for the first ring start position of the *_corr_ring_stats.txt file.



echo "====================================================================================="
printf "ALL SAMPLES COMPLETED!\n\n"

printf "Putting together reads for all samples..."

#If there are *_corr_reads.txt files, prepare the FINAL FILE, ALL SAMPLES TOGETHER
if [ $(ls -1 ${temp_f}/corrected_files/|grep '_corr_reads.txt'|wc -l) -gt 0 ]
then
	#1. put together header and all regrouped *_corr_reads.txt files
	#2. keep only required fields (1. sample_name, 8. line_no, 10. pos_p2b, 5. density_dat, 3. ring_no_sum, 9. transition
	#3. join with equivalency table
	join -t $'\t' <(cat /dev/shm/${ts}_header_corr_reads.txt <(tail -q -n+2 ${temp_f}/corrected_files/*_corr_reads.txt)|awk -F "\t" '{print $1"\t"$8"\t"$10"\t"$5"\t"$3"\t"$9}'|sort -k1,1) <(sort -k1,1 ${eq_list}|cut -f1-3 -d $'\t' ) > /dev/shm/${ts}_corr_reads_with_ids.txt
		#/dev/shm/${ts}_corr_reads_with_ids.txt
		#	14	  1000	16.64	486.91	7	1	544346	523
		#	14	  1001	16.66	510.32	7	1	544346	523
		#	14	  1002	16.68	544.82	7	1	544346	523
		#	14	  1003	16.7	564.51	7	2	544346	523
		#1. sample_name
		#2. line_no
		#3. pos_p2b
		#4. density_dat
		#5. ring_no_sum
		#6. transition
		#7. germplasm_id
		#8. data_source_id
	
	
	#4. Reorder fields: 1. germplasm_id, 2. line_no, 3. pos_p2b, 4. density_dat, 5. ring_no_sum, 6. transition, 7. data_source_id
	#5. Reorder lines by germplasm_id, position
	awk -F "\t" '{print $7"\t"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$8}' /dev/shm/${ts}_corr_reads_with_ids.txt|sort -k1,1n -k3,3n > ${temp_f}/for_import/all_samples_ready4import.txt
		#all_samples_ready4import.txt
		#	544307	    50	0	510.60	2	1	523
		#	544307	    51	0.02	511.94	2	1	523
		#	544307	    52	0.04	511.85	2	1	523
		#	544307	    53	0.06	495.73	2	1	523
		#	544307	    54	0.08	485.47	2	1	523
		#	544307	    55	0.1	509.98	2	1	523
		#1. germplasm_id
		#2. line_no
		#3. pos_p2b
		#4. density_dat
		#5. ring_no_sum
		#6. transition
		#7. data_source_id
fi

printf "done.\n"

#====> FINAL reads FILE (ALL SAMPLES) completed.


#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
#Compute stats on samples using 1) *_corr_ring_stats.txt files, 2) samples_info_from_dat_parameters.txt
#Also get samples where last ring year in data differs from expected last ring year
#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
#Create 
#	---> ${temp_f}/logs_and_summaries/sample_stats_and_comments.txt
#	---> ${temp_f}/logs_and_summaries/sample_stats_and_comments_fields.txt

#If there are some *_ring_stats.txt files, get stats on ring numbers and years, and join with sample info from .dat files:
if [ $(ls -1 ${temp_f}/corrected_files/|grep '_corr_ring_stats.txt'|wc -l) -gt 0 ]
#if [ -e ${temp_f}/*_corr_ring_stats.txt ]
then
	
	printf "Computing stats on samples using corrected ring stats and info from .dat parameters..."
	
	
	#Get ring number and years for the last (bark side) and first (pith side) rings of each sample (Modified: 27/11/2018)
	join -t $'\t' <(tail -n1 -q ${temp_f}/corrected_files/*_corr_ring_stats.txt|grep -v 'sample'|cut -f1-3 -d $'\t'|sort -k1,1) <(head -n2 -q ${temp_f}/corrected_files/*_corr_ring_stats.txt|grep -v 'sample'|cut -f1-3 -d $'\t'|sort -k1,1)|awk -F "\t" '{print $1"\t"$3"\t"$5"\t"$2"\t"$4}'|cat <(printf "#Obtained from .sum files\n#sample_name\tfirst_ring_no\tlast_ring_no\tfirst_ring_year\tlast_ring_year\n") - > ${temp_f}/logs_and_summaries/intermediate/all_samples_ring_nos_and_years.txt
	#all_samples_ring_nos_and_years.txt
		#Obtained from .sum files
		#sample_name	first_ring_no	last_ring_no	first_ring_year	last_ring_year
		#14			2			34			1986			2018
		#2			2			32			1988			2018
		#57			2			33			1986			2017
	
	#[27/11/2018] Join with samples_info_from_dat_parameters.txt from .dat files to create sample_stats_and_comments.txt
	join -t $'\t' <(sort -k1,1 ${temp_f}/logs_and_summaries/intermediate/all_samples_ring_nos_and_years.txt) <(sort -k1,1 ${temp_f}/logs_and_summaries/intermediate/samples_info_from_dat_parameters.txt) > ${temp_f}/logs_and_summaries/sample_stats_and_comments.txt
	#sample_stats_and_comments.txt
	#E60-A-1-002-7-186	2	29	1983	2010	2019-07-26	Christine Simard	106	Yes	0	2012-11 passent pas		954371	627	2017	t
	#E60-A-1-005-4-001	2	33	1985	2016	2019-07-19	Christine Simard	106	Yes	0	2017 passe pas, commence en 2016		954372	627	2017	t
	
	
	#[2019-05-29]: add description of fields for sample_stats_and_comments.txt: sample_stats_and_comments_fields.txt
	#Corrected 2023-03-22 to add op_team_id
		printf "1\tSample name\t.dat (parameters)\tSample ID, extracted from file name.\n"  > ${temp_f}/logs_and_summaries/sample_stats_and_comments_fields.txt
		printf "2\tfirst_ring_no\t.sum\tFirst ring number (pith to bark). Not reliable, rather use first_ring_year.\n"  >> ${temp_f}/logs_and_summaries/sample_stats_and_comments_fields.txt
		printf "3\tlast_ring_no\t.sum\tLast ring number (pith to bark). Not reliable, rather use last_ring_year.\n"  >> ${temp_f}/logs_and_summaries/sample_stats_and_comments_fields.txt
		printf "4\tfirst_ring_year\t.sum\tFirst ring year (pith to bark).\n"  >> ${temp_f}/logs_and_summaries/sample_stats_and_comments_fields.txt
		printf "5\tlast_ring_year\t.sum\tLast ring year (pith to bark).\n"  >> ${temp_f}/logs_and_summaries/sample_stats_and_comments_fields.txt
		printf "6\tanalysis_date\t.dat (parameters)\tDate formatted from the \"Time/Date of Scan\" parameter.\n"  >> ${temp_f}/logs_and_summaries/sample_stats_and_comments_fields.txt
		printf "7\top_fullname\t.dat (parameters)\tOperator full name converted from \"Operator\" parameter.\n"  >> ${temp_f}/logs_and_summaries/sample_stats_and_comments_fields.txt
		printf "8\top_team_id\t.dat (parameters)\tOperator team id converted from \"Operator\" parameter.\n"  >> ${temp_f}/logs_and_summaries/sample_stats_and_comments_fields.txt
		printf "9\tis_pith_present\t.dat (parameters)\tPresence of pith, obtainted from \"Is pith present\" parameter. DO NOT rely on this parameter, rather look at any comments made on the sample, either on the .dat \"Description\" parameter, or in an Excel file.\n"  >> ${temp_f}/logs_and_summaries/sample_stats_and_comments_fields.txt
		printf "10\tno_pith_rings_missing\t.dat (parameters)\tNumber of missing pith rings, from \"No. pith rings missing\" parameter.\n"  >> ${temp_f}/logs_and_summaries/sample_stats_and_comments_fields.txt
		printf "11\tdescription\t.dat (parameters)\tDescription from \"Description\" parameter. Usually identifies the sample.\n"  >> ${temp_f}/logs_and_summaries/sample_stats_and_comments_fields.txt
		printf "12\tcomments\t.dat (parameters)\tComments from \"Commentaires\" parameter. Comments on the sample.\n"  >> ${temp_f}/logs_and_summaries/sample_stats_and_comments_fields.txt
		printf "13\tsample_id\t${eq_list}\tUnique identifier of the sample in TreeSource, coming from the provided equivalency list between sample names in Quintek and germplasm_id's.\n"  >> ${temp_f}/logs_and_summaries/sample_stats_and_comments_fields.txt
		printf "14\tdata_source_id\t${eq_list}\tData source id.\n" >> ${temp_f}/logs_and_summaries/sample_stats_and_comments_fields.txt
		printf "15\tgrowth year\t${eq_list}\tGrowth year at harvest time.\n" >> ${temp_f}/logs_and_summaries/sample_stats_and_comments_fields.txt
		printf "16\tharv_in_growing_season\t${eq_list}\tWas the sample harvested during growing season?\n" >> ${temp_f}/logs_and_summaries/sample_stats_and_comments_fields.txt

	printf "done.\n"
	
	
	#[20190626] Get the samples where last ring year in data (.sum) is different from last ring year expected from harvest date (${eq_list}).
	#NOTE: this could be checked much earlier in the script using the provided ${eq_list} and raw .sum files.
	printf "Checking the last year in .sum files compared to the last ring year expected from harvest date..."
	
	comment_p1="Automatically added on ${pgf_date} by $0 because last ring year in .sum file ("
	comment_p2=") is lower than expected year from harvest date ("
	comment_p3=")."
	#Prepare the file to import.
	#Col 1: data_source_id
	#Col 2: germplasm_id
	#Col 3: last_scanned_ring_year
	#Col 4: comments
	#Col 5: team_id (set to NULL, because generated by script)
	#Col 6: flag_date (set to today)
	#Line before 2023-03-22: awk -F "\t" -v cp1="${comment_p1}" -v cp2="${comment_p2}" -v cp3="${comment_p3}" -v pgfdate="${pgf_date}" '{if ($5 < $14) print $13"\t"$12"\t"$5"\t"cp1 $5 cp2 $14 cp3"\t\\N\t"pgfdate}' ${temp_f}/logs_and_summaries/sample_stats_and_comments.txt > ${temp_f}/for_import/last_ring_year_in_densitometry_data.txt
	awk -F "\t" -v cp1="${comment_p1}" -v cp2="${comment_p2}" -v cp3="${comment_p3}" -v pgfdate="${pgf_date}" '{if ($5 < $15) print $14"\t"$13"\t"$5"\t"cp1 $5 cp2 $15 cp3"\t\\N\t"pgfdate}' ${temp_f}/logs_and_summaries/sample_stats_and_comments.txt > ${temp_f}/for_import/last_ring_year_in_densitometry_data.txt
	#523     544343  2017    Automatically added on 2019-07-15 by -bash because last ring year in .sum file (2017) is lower than expected year from harvest date (2018).     \N    2019-07-15
	#523     544394  2017    Automatically added on 2019-07-15 by -bash because last ring year in .sum file (2017) is lower than expected year from harvest date (2018).     \N    2019-07-15
	#523     544324  2017    Automatically added on 2019-07-15 by -bash because last ring year in .sum file (2017) is lower than expected year from harvest date (2018).     \N    2019-07-15
	#523     544418  2017    Automatically added on 2019-07-15 by -bash because last ring year in .sum file (2017) is lower than expected year from harvest date (2018).     \N    2019-07-15

	#If there were last rings in ­.sum data which year was lower than expected
	if [ -s ${temp_f}/for_import/last_ring_year_in_densitometry_data.txt ]
	then
		echo
		printf "\tThere are samples where the last ring year differs from the expected last ring year:\n"
		#Line before 2023-03-22: cat <(printf "${yellow_color}sample_name\tsample_id\tlast_ring_year_sum\tlast_ring_year_expected\n") <(awk -F "\t" '{if ($5 < $14) print $1"\t"$12"\t"$5"\t"$14}' ${temp_f}/logs_and_summaries/sample_stats_and_comments.txt)|perl -pe 's/^/\t\t/g'
		cat <(printf "${yellow_color}sample_name\tsample_id\tlast_ring_year_sum\tlast_ring_year_expected\n") <(awk -F "\t" '{if ($5 < $15) print $1"\t"$13"\t"$5"\t"$15}' ${temp_f}/logs_and_summaries/sample_stats_and_comments.txt)|perl -pe 's/^/\t\t/g'
		
		printf "${normal_color}"
		printf "\t\t- Most of the time, this indicates that some rings are missing at bark side, possibly because of a broken core.\n"
		printf "\t\t- A file has been created to import those last rings into last_ring_year_in_densitometry_data.\n"
		#printf "\t\t- Otherwise, ignore this list.\n"
		#Note: in the absence of values in last_ring_year_in_densitometry_data, fnct_add_info_to_mv_rings_and_mv_woods takes care of calculating year of the last ring depending on harvest date and growing season period.

	fi
	
	#[20190627]: E9 : last ring year in data is newer (problem!) than expected year from harvest date
	#NOTE: this could be checked much earlier in the script using the provided ${eq_list} and raw .sum files.
	#Line before 2023-03-22: awk -F "\t" '{if ($5 > $14) print $1"\t"$12"\t"$3"\t"$5"\t"$14}' ${temp_f}/logs_and_summaries/sample_stats_and_comments.txt > ${temp_f}/logs_and_summaries/intermediate/last_ring_year_in_data_newer_than_harvest_year.txt
	awk -F "\t" '{if ($5 > $15) print $1"\t"$13"\t"$3"\t"$5"\t"$15}' ${temp_f}/logs_and_summaries/sample_stats_and_comments.txt > ${temp_f}/logs_and_summaries/intermediate/last_ring_year_in_data_newer_than_harvest_year.txt
	
	if [ -s ${temp_f}/logs_and_summaries/intermediate/last_ring_year_in_data_newer_than_harvest_year.txt ]
	then
		#Display error onscreen
		#printf "${red_color}\tSome last rings years in .sum file are newer than expected from the harvest date:\n"
		#cat <(printf "sample_name\tsample_id\tlast_ring_no_sum\tlast_ring_year_sum\tlast_ring_year_expected\n") ${temp_f}/logs_and_summaries/intermediate/last_ring_year_in_data_newer_than_harvest_year.txt|perl -pe 's/^/\t\t/g'
		#printf "${normal_color}"
		
		#Add to /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		ring_error_message_p1="Last ring year in .sum is newer ("
		ring_error_message_p2=") than expected from harvest date ("
		ring_error_message_p3="). THE WHOLE .sum FILE SHOULD BE REDONE."
		ring_error_code="E9"
		
		
		#Added to /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt, all rings at once
		awk -F "\t" -v rem1="${ring_error_message_p1}" -v rem2="${ring_error_message_p2}" -v rem3="${ring_error_message_p3}" -v rec=${ring_error_code} '{print $1"\t"$3"\t"rec"\t"rem1 $4 rem2 $5 rem3}' ${temp_f}/logs_and_summaries/intermediate/last_ring_year_in_data_newer_than_harvest_year.txt >> /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
		#10      35      E9      Last ring year in .sum is newer (2019) than expected from harvest date (2018). THE WHOLE .sum FILE SHOULD BE REDONE.
		
		#Write to other ring and sample stats files
		fnct_write_warning_and_errors_to_stats_files
			
	fi
	
	printf "done.\n"
	
	
	
	#[20190627] Flagging the last ring as incomplete if sample was harvested during growing season
	printf "Automatically flagging the last ring as incomplete if sample was harvested during growing season and last ring year in .sum is as expected by harvest date..."

	#Get the samples where last ring year in .sum = last ring expected year, and harvest has been made during growing season
	#Line before 2023-03-22: awk -F "\t" '{if ($5 == $14 && $15 == "t") print $12"\t"$3"\t"$13"\t"$5"\t"$14"\t"$15}' ${temp_f}/logs_and_summaries/sample_stats_and_comments.txt > ${temp_f}/logs_and_summaries/intermediate/samples_with_incomplete_last_ring.txt
	awk -F "\t" '{if ($5 == $15 && $16 == "t") print $13"\t"$3"\t"$14"\t"$5"\t"$15"\t"$16}' ${temp_f}/logs_and_summaries/sample_stats_and_comments.txt > ${temp_f}/logs_and_summaries/intermediate/samples_with_incomplete_last_ring.txt
	#	544346  34      523     2018    2018    t
	#	544307  32      523     2018    2018    t
	#
	
	#If there are such sampls with incomplete last rings, warn and prepare incomplete_rings.txt file
	if [ -s ${temp_f}/logs_and_summaries/intermediate/samples_with_incomplete_last_ring.txt ]
	then
		echo
		#warn
		printf "\tThere are $(cat ${temp_f}/logs_and_summaries/intermediate/samples_with_incomplete_last_ring.txt|wc -l) samples where last ring is automatically considered as incomplete because sample was harvested during growing season.\n"
		#create comment
		comment_p1="Automatically added on ${pgf_date} by $0 because it is the last ring and sample was harvested during growing season."
		
		#create the file incomplete_rings.txt
		awk -F "\t" -v cp1="${comment_p1}" -v pgfdate=${pgf_date} '{print $1"\t"$2"\t"$3"\t"cp1"\t\\N\t"pgfdate}' ${temp_f}/logs_and_summaries/intermediate/samples_with_incomplete_last_ring.txt > ${temp_f}/for_import/incomplete_rings.txt
	fi
	
	printf "done.\n"
	
fi

#exit		



#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
#[2017-06-29], updated 6/12/218: add ring error codes descriptions to a separate file: error_and_warning_codes.txt
#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
printf "\n\nError codes descriptions:\n-------------------------\n" > ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "***NOTE***: If these errors occur, .sum and/or .dat files SHOULD BE REDONE for the sample before running the script again.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "E1\t.dat file is empty/without proper header.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "E2\t.dat file has duplicated positions.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "E3\t.dat file has disordered positions.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "E4\t.dat file has missing rings.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "E5\t.dat file has large gaps (>= 10x step) between some reads.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "E6\t.sum file is empty/without proper header.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "E7\t.sum has disordered ring numbers.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "E8\t.sum has missing rings.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "E9\tLast ring year in .sum is newer than expected from harvest date.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "E10\t.sum file has ring start position lower than ring end position.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "E11\tThe .dat file reads are spaced differently from expected the step (${step}).\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "E12\tNo reads found in .dat file between end and start positions of .sum file.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "E13\tSome ring numbers are replicated in the .sum file.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "E14\tThe .sum file has an irregular number of columns.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "E15\tThe .dat file is missing the POSITION column.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "E16\tThe .dat file is missing the DENSITY column.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt

printf "\n\nWarning codes descriptions:\n-------------------------\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W1\t.dat file has less reads than allowed in min_reads_per_ring_dat.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W2\t.dat file has minor gaps (< 10x step) between some reads.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W3\tThere are too few reads in the ring.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W4\tNo clear shift in density could be found.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W5\tNo early wood reads at the start of the ring.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W6\tNumber of early wood reads is too low.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W7\t(not assigned)\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W8f\tThere is inconsistency between the ring's end position and the next ring's start position.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W8r\tThere is inconsistency between the ring's start position and the provious ring's end position.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W9\tSeveral early to late wood transitions were found throughout the ring.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W10\tRings from .dat file are missing in .sum file.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W11\tThe .sum file has ring width > ${max_ring_width_factor}x the median ring width for that sample.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W12\tReads removed from .dat file at pith end, due to low density (<${min_allowed_density} kg/m3), even if included within the .sum file range.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W13\tReads removed from .dat file at bark end, due to low density (<${min_allowed_density} kg/m3), even if included within the .sum file range.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W14\tRing has too few read after removal of low-density reads (first or last ring). The minimum number of allowed reads per ring in .dat files is ${min_reads_per_ring_dat} (min_reads_per_ring_dat).\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W15\tRing has no reads left after removal of low-density reads. This will lead to an E12 error.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W16\tThere are some extreme density (< ${min_allowed_density} OR > ${max_allowed_density} kg/m3) reads in the .DAT file. These reads will be removed before calculating stats (min/mx/avg/median), but will be kept in the final file.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W17\tNot enough (<2) valid density reads after extreme values (< ${min_allowed_density} OR > ${max_allowed_density} kg/m3) were removed from the the .DAT file. Transition will NOT be calculated.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W18\tRings from .sum file are missing in .dat file.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W19\tInvalid ring (contains abnormally low or high density).\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W20\tInvalid sample (contains a high percentage of invalid rings).\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W21\tThe .dat file is missing the RING NO column.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W22\tThe .dat file is missing the WOOD TYPE column.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W23\tZero-width ring found in .sum file.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt
printf "W24\tThe .dat file is missing some rings.\n" >> ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt




#Add the error codes to the end of samples_errors_and_warnings.txt
cat ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt >> ${temp_f}/logs_and_summaries/samples_errors_and_warnings.txt


#-----------------------------------------------------------------------------------------------------------------------------------------------------------
#Statistiques sur les erreurs et avertissements
#-----------------------------------------------------------------------------------------------------------------------------------------------------------
echo "-----------------------------------"
printf "Reporting on warnings/errors..."
#Pour compiler des stats, on reprend le fichier listant tous les codes d'erreurs/avertissements:

#	rings_errors_and_warnings.txt
#	A100    1       W9      3 transition points were found within the ring. Only the last transition found (nearer the ring end) was kept (multiple_transitions_option=1).
#	A100    2       W9      2 transition points were found within the ring. Only the last transition found (nearer the ring end) was kept (multiple_transitions_option=1).
#	A100    3       W9      5 transition points were found within the ring. Only the last transition found (nearer the ring end) was kept (multiple_transitions_option=1).
#	A100    4       W9      3 transition points were found within the ring. Only the last transition found (nearer the ring end) was kept (multiple_transitions_option=1).
#	A100    5       W9      2 transition points were found within the ring. Only the last transition found (nearer the ring end) was kept (multiple_transitions_option=1).
#	A100    6       W9      3 transition points were found within the ring. Only the last transition found (nearer the ring end) was kept (multiple_transitions_option=1).
#	A100    7       W9      3 transition points were found within the ring. Only the last transition found (nearer the ring end) was kept (multiple_transitions_option=1).
#	A100    8       W9      3 transition points were found within the ring. Only the last transition found (nearer the ring end) was kept (multiple_transitions_option=1).
#	A100    9       W9      3 transition points were found within the ring. Only the last transition found (nearer the ring end) was kept (multiple_transitions_option=1).
#	A101    1       W9      2 transition points were found within the ring. Only the last transition found (nearer the ring end) was kept (multiple_transitions_option=1).
#	(...52 062)


#Voir les échantillons par erreur
grep -v '^$' ${temp_f}/logs_and_summaries/intermediate/rings_errors_and_warnings.txt|cut -f1,3 |sort -u|cut -f2|sort|uniq -c|perl -pe 's/^ +(\d+) (\S+)/\2\t\1/g' > /dev/shm/${ts}_samples_count_per_w_e.txt

#	/dev/shm/${ts}_samples_count_per_w_e.txt                                                                                                  
#	E10     60
#	E11     40
#	E13     1
#	E9      4
#	W1      67
#	W10     23
#	W3      76
#	W4      8
#	W7      58
#	W8f     2520
#	W8r     2520
#	W9      4921

#Voir les cernes par erreur
grep -v '^$' ${temp_f}/logs_and_summaries/intermediate/rings_errors_and_warnings.txt|cut -f3 |sort|uniq -c|perl -pe 's/^ +(\d+) (\S+)/\2\t\1/g' > /dev/shm/${ts}_rings_count_per_w_e.txt
#	/dev/shm/${ts}_rings_count_per_w_e.txt
#	E10     61
#	E11     71
#	E13     16
#	E9      6
#	W1      126
#	W10     27
#	W3      130
#	W4      8
#	W7      61
#	W8f     5261
#	W8r     5261
#	W9      41018

#	NOTE: Dès que le script détecte une erreur (E) pour un échantillon, il passe à l'échantillon suivant sans faire les calculs par cerne.
#		Cependant, il est possible qu'il décompose l'erreur par cerne dans le fichier all_samples_ring_errors_and_warnings.txt,
#		...c'est pourquoi le nombre de cernes est parfois > que le nombre d'échantillons pour ces erreurs.
#		
#		Pour les avertissements (W), le script liste habituellement tous les cernes impliqués, d'où le nombre de cernes > nombre d'échantillons.


#Joindre les comptes d'erreurs par échantillon et ceux par cerne
join -t $'\t' <(sort -k1,1 /dev/shm/${ts}_samples_count_per_w_e.txt) <(sort -k1,1 /dev/shm/${ts}_rings_count_per_w_e.txt)|join -t $'\t' - <(grep -E '^(E|W)[0-9]' ${temp_f}/logs_and_summaries/intermediate/error_and_warning_codes.txt|sort -k1,1) > ${temp_f}/logs_and_summaries/sample_and_ring_w_e_stats.txt
#	W10	3	3	Rings from .dat file are missing in .sum file.
#	W16	2	18	There are some extreme density (< 100 OR > 2000 kg/m3) reads in the .DAT file. These reads will be removed before calculating stats (min/mx/avg/median), but will be kept in the final file.
#	W17	2	14	Not enough (<2) valid density reads after extreme values (< 100 OR > 2000 kg/m3) were removed from the the .DAT file. Transition will NOT be calculated.
#	W18	2	17	Rings from .sum file are missing in .dat file.
#	W19	2	16	Invalid ring (contains abnormally low or high density).
#	W20	1	1	Invalid sample (contains a high percentage of invalid rings).
#	W4	2	3	No clear shift in density could be found.
#	W9	3	9	Several early to late wood transitions were found throughout the ring.


#-----------------------------------------------------------------------------------------------------------------------------------------------------------
#From the samples_errors_and_warnings.txt file, keep only error (E) codes
#-----------------------------------------------------------------------------------------------------------------------------------------------------------
# i.e. that REQUIRE WHOLE FILES REDO. 
#Keep only samples containing error (E) codes
#All warning codes (W) and messages are ignored.
awk -F "\t" '{if( $3 ~ /E[[:digit:]]/) print}' ${temp_f}/logs_and_summaries/intermediate/rings_errors_and_warnings.txt > ${temp_f}/logs_and_summaries/samples_with_errors.txt

#If any errors were found, list them onscreen (NEW: 27/11/2018)
if [ -s ${temp_f}/logs_and_summaries/samples_with_errors.txt ]
then
	
	printf "${red_color}\n\tWARNING: there are .dat and/or .sum files with critical ERRORS requiring that these files be redone:\n"
	cat ${temp_f}/logs_and_summaries/samples_with_errors.txt|perl -pe 's/^/\t\t/g'
	printf "\tSee more details in rings_errors_and_warnings.txt ${normal_color}\n"
fi

printf "done.\n"
echo








#-----------------------------------------------------------------------------------------------------------------------------------------------------------
#Display messages on files to import:
#-----------------------------------------------------------------------------------------------------------------------------------------------------------
printf "${green_color}FILES FOR IMPORT:\n-------------------------------------------\n"

#Corrected reads
#-----------------------------------------------------------------------------------------
printf "\tCorrected reads (all_samples_ready4import.txt):\n"
printf "\t\tpsql -U cleseb -h 132.156.208.30 -d ts_d -c \"\copy x_ray_dens_msmts_per_read FROM 'all_samples_ready4import.txt'\"\n${normal_color}"


#Invalid rings
#-----------------------------------------------------------------------------------------
#Put together both pith rings ( /dev/shm/${ts}_pith_rings.txt) and exterme density rings (/dev/shm/${ts}_invalid_rings_due_to_extreme_densities.txt)
#...with the method id's from invalid_rings_determination_methods (8 for pith, 7 for extreme density reads), the boolean for is_pith (TRUE for pith, FALSE for extrement density reads) and the team_id (\N in both cases because auto-generated).
#...making a sort key sample-ring_no-priority (A or B), where a ring flagged twice will appear only for the pith flag (A)

#Step 1: creating the key to sort, pith rings (A) arriving before extreme density rings (B)
#	cat <(awk -F "\t" '{print $1"_"$2"_A\t"$0"\t8\tTRUE\t\\N"}' /dev/shm/${ts}_pith_rings.txt) <(awk -F "\t" '{print $1"_"$2"_B\t"$0"\t7\tFALSE\t\\N"}' /dev/shm/${ts}_invalid_rings_due_to_extreme_densities.txt)|sort -k1,1
#14_19_B 14      19      Invalid ring. Percent extreme density reads ( 100%) is above the accepted limit (50%). Average density for extreme reads: 10.9771 kg/m3. Auto-flagged by recalc_Quintek_densitometry_files_20190715.txt on 2019-07-15.  7       FALSE   \N
#14_2_A  14      2       Ring auto. flagged as the pith (invalid ring) on 2019-07-15 by recalc_Quintek_densitometry_files_20190715.txt, because piths are assumed to be systematically left in the results (parameter first_ring_is_pith=1).     8       TRUE    \N
#14_2_B  14      2       Invalid ring. Percent extreme density reads ( 100%) is above the accepted limit (50%). Average density for extreme reads: 9.81722 kg/m3. Auto-flagged by recalc_Quintek_densitometry_files_20190715.txt on 2019-07-15.  7       FALSE   \N
#15_2_A  15      2       Ring auto. flagged as the pith (invalid ring) on 2019-07-15 by recalc_Quintek_densitometry_files_20190715.txt, because piths are assumed to be systematically left in the results (parameter first_ring_is_pith=1).     8       TRUE    \N

#Step 2: key removed, keeping only first occurrence when >1 lines with same sample and ring no are successive
#	cut -f1 --complement|sort -t $'\t' -k1,1 -k2,2 -u
#14      19      Invalid ring. Percent extreme density reads ( 100%) is above the accepted limit (50%). Average density for extreme reads: 10.9771 kg/m3. Auto-flagged by recalc_Quintek_densitometry_files_20190715.txt on 2019-07-15.  7       FALSE   \N
#14      2       Ring auto. flagged as the pith (invalid ring) on 2019-07-15 by recalc_Quintek_densitometry_files_20190715.txt, because piths are assumed to be systematically left in the results (parameter first_ring_is_pith=1).     8       TRUE    \N
#15      2       Ring auto. flagged as the pith (invalid ring) on 2019-07-15 by recalc_Quintek_densitometry_files_20190715.txt, because piths are assumed to be systematically left in the results (parameter first_ring_is_pith=1).     8       TRUE    \N
cat <(awk -F "\t" '{print $1"_"$2"_A\t"$0"\t8\tTRUE\t\\N"}' /dev/shm/${ts}_pith_rings.txt) <(awk -F "\t" '{print $1"_"$2"_B\t"$0"\t7\tFALSE\tNULL"}' /dev/shm/${ts}_invalid_rings_due_to_extreme_densities.txt)|sort -k1,1|cut -f1 --complement|sort -t $'\t' -k1,1 -k2,2 -u > /dev/shm/${ts}_combined_invalid_rings.txt

#Step 3: add any other invalid ring [Added 2023-03-09]
cat /dev/shm/${ts}_other_invalid_rings.txt >> /dev/shm/${ts}_combined_invalid_rings.txt



#Invalid rings: [20190618] If there are some invalid rings due to extreme density reads or pith rings, prepare a file to import into invalid_rings
#------------------------------------------------------------------------------------------------------------------------------------------------------------
if [ -s /dev/shm/${ts}_combined_invalid_rings.txt ]
then
	
	#Obtenir les germplasms_id's, les data_source_id's, à partir de la table d'équivalence.
	join -t $'\t' <(sort -k1,1 -t $'\t' ${eq_list}|cut -f1-3 -d $'\t') <(sort -k1,1 -t $'\t' /dev/shm/${ts}_combined_invalid_rings.txt)|awk -v pgfdate=${pgf_date} -F "\t" '{print $2"\t"$4"\t"$3"\t"$5"\t"$6"\t"$7"\t"$8"\t"pgfdate}'|sort -k1,1 -k2,2n -t $'\t' > ${temp_f}/for_import/invalid_rings.txt
	
	#${temp_f}/for_import/invalid_rings.txt
		#544306  2       523     Ring auto. flagged as the pith (invalid ring) on 2019-07-15 by recalc_Quintek_densitometry_files_20190715.txt, because piths are assumed to be systematically left in the results (parameter first_ring_is_pith=1).     8       TRUE    \N       2019-07-15
		#544307  2       523     Ring auto. flagged as the pith (invalid ring) on 2019-07-15 by recalc_Quintek_densitometry_files_20190715.txt, because piths are assumed to be systematically left in the results (parameter first_ring_is_pith=1).     8       TRUE    \N       2019-07-15
		#544308  2       523     Ring auto. flagged as the pith (invalid ring) on 2019-07-15 by recalc_Quintek_densitometry_files_20190715.txt, because piths are assumed to be systematically left in the results (parameter first_ring_is_pith=1).     8       TRUE    \N  		#(...)
		#544346  10      523     Invalid ring. Percent extreme density reads (85.1%) is above the accepted limit (50%). Average density for extreme reads: 15.8467 kg/m3. Auto-flagged by recalc_Quintek_densitometry_files_20190715.txt on 2019-07-15.  7       FALSE   \N       2019-07-15
		#544346  11      523     Invalid ring. Percent extreme density reads ( 100%) is above the accepted limit (50%). Average density for extreme reads: 9.46304 kg/m3. Auto-flagged by recalc_Quintek_densitometry_files_20190715.txt on 2019-07-15.  7       FALSE   \N       2019-07-15
		#544346  12      523     Invalid ring. Percent extreme density reads ( 100%) is above the accepted limit (50%). Average density for extreme reads: 10.7214 kg/m3. Auto-flagged by recalc_Quintek_densitometry_files_20190715.txt on 2019-07-15.  7       FALSE   \N       2019-07-15
	
	echo
	printf "${green_color}\tInvalid rings:\n"
	printf "\t\tALTER TABLE invalid_rings DISABLE TRIGGER trg_invalid_rings_01;\n"
	printf "\t\tpsql -U cleseb -h 132.156.208.30 -d ts_d -c \"\copy invalid_rings FROM 'invalid_rings.txt'\"\n"
	printf "\t\tALTER TABLE invalid_rings ENABLE TRIGGER trg_invalid_rings_01;\n${normal_color}"
	#exit

fi


#Incomplete rings
#-----------------------------------------------------------------------------------------
if [ -s ${temp_f}/for_import/incomplete_rings.txt ]
then
	echo
	printf "${green_color}\tIncomplete rings:\n"
	printf "\t\tALTER TABLE incomplete_ringss DISABLE TRIGGER trg_incomplete_rings_01;\n"
	printf "\t\tpsql -U cleseb -h 132.156.208.30 -d ts_d -c \"\copy incomplete_rings FROM 'incomplete_rings.txt'\"\n"
	printf "\t\tALTER TABLE incomplete_ringss ENABLE TRIGGER trg_incomplete_rings_01;\n${normal_color}"
fi



#exit

#Invalid samples
#-----------------------------------------------------------------------------------------
#If there are invalid samples
if [ -s ${temp_f}/for_import/SQL_UPDATE_invalid_samples.txt ]
then
	echo
	printf "${green_color}\tInvalid samples:\n"
	printf "\t\tpsql -U cleseb -h 132.156.208.30 -d ts_d -f \"SQL_UPDATE_invalid_samples.txt\"\n${normal_color}"
fi




#Comments and descriptions from .dat parameters
#-----------------------------------------------------------------------------------------
#2023-03-23: Descriptions also kept, as E60A cores for 2017 had most densitometry observations on missing rings put in .dat descriptions rather than in .dat comments.
#If there are comments and descriptions in sample_stats_and_comments.txt

#${temp_f}/logs_and_summaries/sample_stats_and_comments.txt
#E60-A-1-002-7-186	2	29	1983	2010	2019-07-26	Christine Simard	106	Yes	0	2012-11 passent pas		954371	627	2017	t
#E60-A-1-005-4-001	2	33	1985	2016	2019-07-19	Christine Simard	106	Yes	0	2017 passe pas, commence en 2016		954372	627	2017	t

#Col 1: sample name
#Col 2: first ring no
#Col 3: last ring no
#Col 4: first ring year
#Col 5: last ring year
#Col 6: analysis date
#Col 7: Operator full name
#Col 8:  operator team id
#Col 9: Is the pith present?
#Col 10: Number of pith rings missing
#Col 11: Description in .dat
#Col 12: Comments in .dat
#Col 13: Sample Id (TreeSource)
#Col 14: data_source_id
#Col 15: Growth year
#Col 16: Was the sample harvested during growing season ?

#[NEW 2023-03-23]:
description_lines_count=$(cut -f11 -d $'\t' ${temp_f}/logs_and_summaries/sample_stats_and_comments.txt|sort -u|grep -v '^$'|wc -l)
comment_lines_count=$(cut -f12 -d $'\t' ${temp_f}/logs_and_summaries/sample_stats_and_comments.txt|sort -u|grep -v '^$'|wc -l)


#2023-03-23
#If either descriptions or comments are present in .dat files
if [ ${description_lines_count} -gt 0 ] || [ ${comment_lines_count} -gt 0 ]
then
	
	#Create the file for import
	printf "" > ${temp_f}/for_import/comments_on_germplasms.txt
	
	#If there are descriptions from .dat
	if [ ${description_lines_count} -gt 0 ]
	then
		#Create the file. Now converts in UTF-8 format [2019-07-17]
		#Note: "9" is for contexts_for_comments_on_germplasms.id=9 ---> context='Densitométrie'
		awk -F "\t" '{if ($11 != "") print $13"\t"$6"\tFALSE\t"$11" (from .dat description)\t9\t"$14"\tFALSE\t"$8}' ${temp_f}/logs_and_summaries/sample_stats_and_comments.txt|iconv -f iso-8859-1 -t utf-8 > ${temp_f}/logs_and_summaries/intermediate/comments_on_germplasms_from_dat_descriptions_utf.txt
	
		#Add to comments_on_germplasms.txt file
		cat ${temp_f}/logs_and_summaries/intermediate/comments_on_germplasms_from_dat_descriptions_utf.txt >> ${temp_f}/for_import/comments_on_germplasms.txt
		#head ${temp_f}/logs_and_summaries/intermediate/comments_on_germplasms_from_dat_descriptions_utf.txt
	
	fi

	if [ ${comment_lines_count} -gt 0 ]
	then
		#Create the file. Now converts in UTF-8 format [2019-07-17]
		awk -F "\t" '{if ($12 != "") print $13"\t"$6"\tFALSE\t"$12" (from .dat comment)\t9\t"$14"\tFALSE\t"$8}' ${temp_f}/logs_and_summaries/sample_stats_and_comments.txt|iconv -f iso-8859-1 -t utf-8 > ${temp_f}/logs_and_summaries/intermediate/comments_on_germplasms_from_dat_comments_utf.txt
		
		#Add to comments_on_germplasms.txt file
		#Note: "9" is for contexts_for_comments_on_germplasms.id=9 ---> context='Densitométrie'
		cat ${temp_f}/logs_and_summaries/intermediate/comments_on_germplasms_from_dat_comments_utf.txt >> ${temp_f}/for_import/comments_on_germplasms.txt
		#head ${temp_f}/logs_and_summaries/intermediate/comments_on_germplasms_from_dat_comments_utf.txt
	fi


	echo
	printf "${green_color}\tComments and description on samples from .dat files:\n"
	printf "\t\tpsql -U cleseb -h 132.156.208.30 -d ts_d -c \"\copy comments_on_germplasms (germplasm_id, date, date_is_approximate, comment, context_id, data_source_id, action_required, team_id) FROM 'comments_on_germplasms.txt'\"\n"
	echo

fi





#last_ring_year_in_densitometry_data
#-----------------------------------------------------------------------------------------
if [ -s ${temp_f}/for_import/last_ring_year_in_densitometry_data.txt ]
then
	echo
	printf "${green_color}\tSamples where last ring year differs than that expected from harvest date:\n"
	
	printf "\t\tALTER TABLE last_ring_year_in_densitometry_data DISABLE TRIGGER trg_last_ring_year_in_densitometry_data_01;\n"
	printf "\t\tpsql -U cleseb -h 132.156.208.30 -d ts_d -c \"\copy last_ring_year_in_densitometry_data FROM 'last_ring_year_in_densitometry_data.txt'\"\n"
	printf "\t\tALTER TABLE last_ring_year_in_densitometry_data ENABLE TRIGGER trg_last_ring_year_in_densitometry_data_01;\n${normal_color}"
	echo
fi

#phys_msmt_experiments
#-----------------------------------------------------------------------------------------------------------------------------------------------------------
#Get a variable containing all operator fullnames separated by a comma
all_distinct_operators=$(cut -f3 -d $'\t' ${temp_f}/logs_and_summaries/intermediate/samples_info_from_dat_parameters.txt|tail -n+2|sort -u|perl -pe 's/\n/, /g'|perl -pe 's/, $/\n/g')

#INSERT INTO
#-----------------------------------------------------------------------------------------------------------------------------------------------------------
printf "INSERT INTO phys_msmt_experiments (data_source_id, samples_analyzed, team_id, msmt_date, density_type, density_is_basic_specific_gravity, msmts_mc, technology, date_data_added, table_where_data_put, ew_lw_treshold_method, script_version, script_parameters,	ring_dating_method_id)\n" > ${temp_f}/for_import/SQL_INSERT_INTO_phys_msmt_experiments.txt
printf "VALUES (\n" >> ${temp_f}/for_import/SQL_INSERT_INTO_phys_msmt_experiments.txt
printf "\t${data_source_id},\n" >> ${temp_f}/for_import/SQL_INSERT_INTO_phys_msmt_experiments.txt
printf "\t${number_of_dat_sum_files},\n" >> ${temp_f}/for_import/SQL_INSERT_INTO_phys_msmt_experiments.txt	#Computed above
printf "\tfnct_get_team_id_from_employee_names('${all_distinct_operators}'),\n" >> ${temp_f}/for_import/SQL_INSERT_INTO_phys_msmt_experiments.txt
printf "\t'$(tail -1 ${temp_f}/logs_and_summaries/intermediate/distinct_scan_dates.txt)',\n" >> ${temp_f}/for_import/SQL_INSERT_INTO_phys_msmt_experiments.txt	#Get the latest date from distinct_scan_dates.txt
printf "\t1,\n" >> ${temp_f}/for_import/SQL_INSERT_INTO_phys_msmt_experiments.txt
printf "\tFALSE,\n" >> ${temp_f}/for_import/SQL_INSERT_INTO_phys_msmt_experiments.txt
printf "\t$(if [ $(echo ${sample_moisture_contents}|grep ', '|wc -l) -eq 1 ];then printf "NULL"; else printf "${sample_moisture_contents}";fi),\n" >> ${temp_f}/for_import/SQL_INSERT_INTO_phys_msmt_experiments.txt	#if there are > 1 MC levels, print NULL, else print the MC.
printf "\t'Quintek',\n" >> ${temp_f}/for_import/SQL_INSERT_INTO_phys_msmt_experiments.txt
printf "\t'${pgf_date}',\n" >> ${temp_f}/for_import/SQL_INSERT_INTO_phys_msmt_experiments.txt
printf "\t'x_ray_dens_msmts_per_read',\n" >> ${temp_f}/for_import/SQL_INSERT_INTO_phys_msmt_experiments.txt
printf "\t'$(if [ $ewlw_transition_method -eq 1 ];then printf "Mid-range density"; else printf "Median density";fi)',\n" >> ${temp_f}/for_import/SQL_INSERT_INTO_phys_msmt_experiments.txt
printf "\t'${0} (${version})',\n" >> ${temp_f}/for_import/SQL_INSERT_INTO_phys_msmt_experiments.txt
printf "\t'first_ring_is_pith=${first_ring_is_pith}, ewlw_transition_method=${ewlw_transition_method}, multiple_transitions_option=${multiple_transitions_option}, low_density_reads_removal_choice=${low_density_reads_removal_choice}, step=${step}, min_reads_per_ring_dat=${min_reads_per_ring_dat}, min_reads_for_transition=${min_reads_for_transition}, min_ew_proportion=${min_ew_proportion}, max_ring_width_factor=${max_ring_width_factor}, max_pct_invalid_rings_for_invalid_sample=${max_pct_invalid_rings_for_invalid_sample}, min_allowed_density=${min_allowed_density}, max_allowed_density=${max_allowed_density}, extreme_densities_max_pct_allowed=${extreme_densities_max_pct_allowed}, reads_to_check_for_density_pithside=${reads_to_check_for_density_pithside}, reads_to_check_for_density_barkside=${reads_to_check_for_density_barkside}, lowest_density_threshold=${lowest_density_threshold}, highest_density_threshold=${highest_density_threshold}, varying_threshold_step=${varying_threshold_step}.',\n"  >> ${temp_f}/for_import/SQL_INSERT_INTO_phys_msmt_experiments.txt
printf "\t'999'\n" >> ${temp_f}/for_import/SQL_INSERT_INTO_phys_msmt_experiments.txt
printf ")\n" >> ${temp_f}/for_import/SQL_INSERT_INTO_phys_msmt_experiments.txt
printf ";\n" >> ${temp_f}/for_import/SQL_INSERT_INTO_phys_msmt_experiments.txt

iconv -f iso-8859-1 -t utf-8 ${temp_f}/for_import/SQL_INSERT_INTO_phys_msmt_experiments.txt > ${temp_f}/for_import/SQL_INSERT_INTO_phys_msmt_experiments_utf.txt
rm ${temp_f}/for_import/SQL_INSERT_INTO_phys_msmt_experiments.txt

#UPDATE
#-----------------------------------------------------------------------------------------------------------------------------------------------------------
printf "UPDATE phys_msmt_experiments\nSET\n" > ${temp_f}/for_import/SQL_UPDATE_phys_msmt_experiments.txt
printf "\tsamples_analyzed=${number_of_dat_sum_files},\n" >> ${temp_f}/for_import/SQL_UPDATE_phys_msmt_experiments.txt	#Computed above
printf "\tteam_id=fnct_get_team_id_from_employee_names('${all_distinct_operators}'),\n" >> ${temp_f}/for_import/SQL_UPDATE_phys_msmt_experiments.txt
printf "\tmsmt_date='$(tail -1 ${temp_f}/logs_and_summaries/intermediate/distinct_scan_dates.txt)',\n" >> ${temp_f}/for_import/SQL_UPDATE_phys_msmt_experiments.txt	#Get the latest date from distinct_scan_dates.txt
printf "\tdensity_type=1,\n" >> ${temp_f}/for_import/SQL_UPDATE_phys_msmt_experiments.txt
printf "\tdensity_is_basic_specific_gravity=FALSE,\n" >> ${temp_f}/for_import/SQL_UPDATE_phys_msmt_experiments.txt
printf "\tmsmts_mc=$(if [ $(echo ${sample_moisture_contents}|grep ', '|wc -l) -eq 1 ];then printf "NULL"; else printf "${sample_moisture_contents}";fi),\n" >> ${temp_f}/for_import/SQL_UPDATE_phys_msmt_experiments.txt	#if there are > 1 MC levels, print NULL, else print the MC.
printf "\ttechnology='Quintek',\n" >> ${temp_f}/for_import/SQL_UPDATE_phys_msmt_experiments.txt
printf "\tdate_data_added='${pgf_date}',\n" >> ${temp_f}/for_import/SQL_UPDATE_phys_msmt_experiments.txt
printf "\ttable_where_data_put='x_ray_dens_msmts_per_read',\n" >> ${temp_f}/for_import/SQL_UPDATE_phys_msmt_experiments.txt
printf "\tew_lw_treshold_method='$(if [ $ewlw_transition_method -eq 1 ];then printf "Mid-range density"; else printf "Median density";fi)',\n" >> ${temp_f}/for_import/SQL_UPDATE_phys_msmt_experiments.txt
printf "\tscript_version='${0} (${version})',\n" >> ${temp_f}/for_import/SQL_UPDATE_phys_msmt_experiments.txt
printf "\tscript_parameters='first_ring_is_pith=${first_ring_is_pith}, ewlw_transition_method=${ewlw_transition_method}, multiple_transitions_option=${multiple_transitions_option}, low_density_reads_removal_choice=${low_density_reads_removal_choice}, step=${step}, min_reads_per_ring_dat=${min_reads_per_ring_dat}, min_reads_for_transition=${min_reads_for_transition}, min_ew_proportion=${min_ew_proportion}, max_ring_width_factor=${max_ring_width_factor}, max_pct_invalid_rings_for_invalid_sample=${max_pct_invalid_rings_for_invalid_sample}, min_allowed_density=${min_allowed_density}, max_allowed_density=${max_allowed_density}, extreme_densities_max_pct_allowed=${extreme_densities_max_pct_allowed}, reads_to_check_for_density_pithside=${reads_to_check_for_density_pithside}, reads_to_check_for_density_barkside=${reads_to_check_for_density_barkside}, lowest_density_threshold=${lowest_density_threshold}, highest_density_threshold=${highest_density_threshold}, varying_threshold_step=${varying_threshold_step}.',\n"  >> ${temp_f}/for_import/SQL_UPDATE_phys_msmt_experiments.txt
printf "\tring_dating_method_id=999'\n" >> ${temp_f}/for_import/SQL_UPDATE_phys_msmt_experiments.txt
printf "WHERE data_source_id=${data_source_id}\n" >> ${temp_f}/for_import/SQL_UPDATE_phys_msmt_experiments.txt #data_source_id from the $eq_list file
printf ";\n" >> ${temp_f}/for_import/SQL_UPDATE_phys_msmt_experiments.txt

iconv -f iso-8859-1 -t utf-8 ${temp_f}/for_import/SQL_UPDATE_phys_msmt_experiments.txt > ${temp_f}/for_import/SQL_UPDATE_phys_msmt_experiments_utf.txt
rm ${temp_f}/for_import/SQL_UPDATE_phys_msmt_experiments.txt


printf "${green_color}\tDetails on the dataset:\n"
printf "\t\tpsql -U cleseb -h 132.156.208.30 -d ts_d -f \"SQL_INSERT_INTO_phys_msmt_experiments_utf.txt\"\n"
printf "\t\tpsql -U cleseb -h 132.156.208.30 -d ts_d -f \"SQL_UPDATE_phys_msmt_experiments_utf.txt\"\n"
printf "\tNote: replace the ring_dating_method_id value (set by default to 999) with the appropriate one.\n${normal_color}"





echo "-------------------"

#-----------------------------------------------------------------------------------------------------------------------------------------------------------
#Print some other stats (27/11/2018)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------
echo
printf "Other stats:\n"
printf "\n\tScan dates range: $(head -n1 ${temp_f}/logs_and_summaries/intermediate/distinct_scan_dates.txt) - $(tail -n1 ${temp_f}/logs_and_summaries/intermediate/distinct_scan_dates.txt); operator(s): ${operators}; sample moisture content(%%): ${sample_moisture_contents}\n"
#If sample moisture contents is empty, warn!
if [ -z ${sample_moisture_contents} ];then printf "${red_color}CAUTION! No sample moisture was found throughout the samples!\n${normal_color}";fi
#If there are > 1 sample moisture contents, warn!
if [ $(echo ${sample_moisture_contents}|grep ', '|wc -l) -eq 1 ];then printf "\t${red_color}CAUTION! Sample moisture content is not uniform throughout the samples!\n${normal_color}";fi

echo
printf "${blue_color}NOTE: also add data to the following tables as needed:\n"
#printf "\tcoded_observations_on_germplasms: Bark/Nobark/Pith/NoPith.\n"
printf "\tcomments_on_germplasms OTHER than those from .dat files, for example, from Excel files.\n"
printf "\tinvalid_rings OTHER THAN AUTOMATICALLY DETECTED, for instance using density profiles, core images and comments on samples.\n"
#printf "\tincomplete_rings: when sample was harvested during growth season, add to last rings to this table.\n"
#printf "\tlast_ring_year_in_densitometry_data: if the last scanned ring year differs from sample growth year (see above).\n"
printf "\tphys_msmt_experiments: complete the information on these datasets.\n"
printf "${normal_color}" 


date +%Y-%m-%d\ %Hh%Mm%Ss > /dev/shm/${ts}_all_analyses_end_timestamp.txt

echo
printf "SCRIPT COMPLETED!\n"
echo "Total duration: $(fnct_calc_time_between_2_files /dev/shm/${ts}_all_analyses_start_timestamp.txt /dev/shm/${ts}_all_analyses_end_timestamp.txt)"


#END OF LOGGING
} 2>&1| tee ${temp_f}/logs_and_summaries/script_log.txt

#Remove ANSI color codes from the script log [20190716]
perl -pe 's/\x1b\[[0-9;]*m//g' ${temp_f}/logs_and_summaries/script_log.txt > ${temp_f}/logs_and_summaries/script_log_no_colors.txt


#Copy script to temporary folder
cp ${0} ${temp_f}/${0}

#delete temporary files
rm /dev/shm/${ts}_*.txt

exit



==============================================================================================================================
<<"Errors and warnings reporting"
==============================================================================================================================
for loop through samples
do (line ~ 1533)
	Note: if an error (E) is found, fnct_write_warning_and_errors_to_stats_files is executed and the script skips to the next sample
	Per sample checks (E1, E2, E3, E4, E5, E6, E7, E8, E10, E13, E14, W1, W2, W8, W10, W11, W18
	---> Written to /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt 
	---> Only E codes trigger fnct_write_warning_and_errors_to_stats_files
	
	for loop through rings
	do (line ~ 2041)
		
		Per ring checks (E12, W3, W4, W5, W6, W9, W12, W13, W14, W15, W16, W17, W19)
		---> Written to /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt 
		---> Only E codes trigger fnct_write_warning_and_errors_to_stats_files
		Onscreen reporting
	
	done (line ~ 2952)
	
	Per sample checks based on per ring checks (W20 - invalid sample, based on W19 - invalid rings)
	---> Written to /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
	
	---> fnct_write_warning_and_errors_to_stats_files
done (line ~ 3031)
Check for .sum last ring years that are above expected year from harvest date (E9) (line ~ 3204)
Create a file with all error/warning descriptions (error_and_warning_codes.txt) (line 3264)
Add error/warning descriptions (error_and_warning_codes.txt) to samples_errors_and_warnings.txt (line ~ 3307)
Compute warning/error stats (line ~ 3313):
	rings_errors_and_warnings.txt (2) ---> _samples_count_per_w_e.txt (4)
	rings_errors_and_warnings.txt (2) ---> _rings_count_per_w_e.txt (5)
	_samples_count_per_w_e.txt (4) + _rings_count_per_w_e.txt (5)	---> sample_and_ring_w_e_stats.txt (6)
Generate a list of samples with errors (line ~ 3389)
	samples_errors_and_warnings.txt (3)	---> samples_with_errors.txt (7)
------------------------------------------------------------------------------------------------------------------
(1) /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt
------------------------------------------------------------------------------------------------------------------
RECYCLED FOR EACH NEW SAMPLE.
Every time a warning or error is encountered, it is written to this file.
One row per ring and warning/error code. A single ring may have several warning/error codes.
Note: when all rings are involved (e.g. E7, disordered ring numbers in .sum file), "ALL" is written as the ring number (col 2).
	
	57	1	W10	Ring in the .dat file ABSENT from the .sum file.
	57	28	W18	Ring in the .sum file ABSENT from the .dat file.
	57	29	W18	Ring in the .sum file ABSENT from the .dat file.
	57	30	W18	Ring in the .sum file ABSENT from the .dat file.
	Col1: Sample name
	Col2: Ring number
	Col3: Warning/error code
	Col4: Warning/error description
	
If a warning (W) code happens:
	- nothing more is done.
If an error (E) code happens:
	- fnct_write_warning_and_errors_to_stats_files is executed
		- It copies /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt (1)
			to ${temp_f}/logs_and_summaries/intermediate/rings_errors_and_warnings.txt (2)
		
		- It also concatenates the rings for each warning/error code (e.g. W18 (28,29,30,31,32,33)) and puts them 
			into ${temp_f}/logs_and_summaries/samples_errors_and_warnings.txt (3)
At the end of the for...do...done loop on each sample, if no error (E) codes were found (e.g. only warning codes, or no codes at all)
	- fnct_write_warning_and_errors_to_stats_files is executed and does as above
------------------------------------------------------------------------------------------------------------------
(2) ${temp_f}/logs_and_summaries/intermediate/rings_errors_and_warnings.txt
------------------------------------------------------------------------------------------------------------------
ALL SAMPLES. 
One row per ring and warning/error.
Simply all /dev/shm/${ts}_current_sample_ring_errors_and_warnings.txt put together.
Generated by fnct_write_warning_and_errors_to_stats_files.
At the end of the script, rings_errors_and_warnings.txt (2) is used to compute stats per warning/error code:
	/dev/shm/${ts}_samples_count_per_w_e.txt (4)
	/dev/shm/${ts}_rings_count_per_w_e.txt (5)
	
	14	1	W10	Ring in the .dat file ABSENT from the .sum file.
	14	2	W9	3 transition points were found within the ring. Only the last transition found (nearer the ring end) was kept (multiple_transitions_option=1).
	14	6	W9	2 transition points were found within the ring. Only the last transition found (nearer the ring end) was kept (multiple_transitions_option=1).
	14	10	W16	There are some extreme density (< 100 OR > 2000 kg/m3) reads in the .DAT file. These reads will be removed before calculating stats (min/mx/avg/median), but will be kept in the final file.
	14	10	W19	Invalid ring. Percent extreme density reads (85.1%) is above the accepted limit (50%). Average density for extreme reads: 15.8467
	14	10	W4	Early to late wood transition could not be calculated because no clear shift in density could be found.
	14	11	W16	There are some extreme density (< 100 OR > 2000 kg/m3) reads in the .DAT file. These reads will be removed before calculating stats (min/mx/avg/median), but will be kept in the final file.
	14	11	W17	Not enough (<2) valid density reads after extreme values (< 100 OR > 2000 kg/m3) were removed from the the .DAT file. Transition will NOT be calculated.
	14	11	W19	Invalid ring. Percent extreme density reads ( 100%) is above the accepted limit (50%). Average density for extreme reads: 9.46304
	
	Col1: sample name
	Col2: ring number
	Col3: warning/error code
	Col4: Warning/error description
	
------------------------------------------------------------------------------------------------------------------
(3) ${temp_f}/logs_and_summaries/samples_errors_and_warnings.txt
------------------------------------------------------------------------------------------------------------------
One row per sample.	
Generated by fnct_write_warning_and_errors_to_stats_files.
	
	14		14.dat	...Ring errors/warnings: W10 (1), W16 (10,11,12,13,14,15,16,17,18,19,20,21), W17 (11,12,13,14,15,16,17,18,19,20), W18 (24,25,26,27,28,29,30,31,32,33,34), W19 (10,11,12,13,14,15,16,17,18,19,20), W20 (MANY), W4 (10), W9 (2,6).
	2		2.dat		...Ring errors/warnings: W10 (1), W9 (4,5,7).
	57		57.dat	...Ring errors/warnings: W10 (1), W16 (12,13,14,15,16,17), W17 (13,14,15,16), W18 (28,29,30,31,32,33), W19 (12,13,14,15,16), W4 (12,18), W9 (3,6,9,11).
	
	Col1: sample name
	Col2: file name
	Col3: list of concatenated ring numbers for each error.
	
------------------------------------------------------------------------------------------------------------------
(4) /dev/shm/${ts}_samples_count_per_w_e.txt
------------------------------------------------------------------------------------------------------------------
	W10	3
	W16	2
	W17	2
	W18	2
	W19	2
	W20	1
	W4	2
	W9	3
------------------------------------------------------------------------------------------------------------------
(5) /dev/shm/${ts}_rings_count_per_w_e.txt
------------------------------------------------------------------------------------------------------------------
	E10     61
	E11     71
	E13     16
	E9      6
	W1      126
	W10     27
	W3      130
	W4      8
	W7      61
	W8f     5261
	W8r     5261
	W9      41018
------------------------------------------------------------------------------------------------------------------
(6) ${temp_f}/logs_and_summaries/sample_and_ring_w_e_stats.txt
------------------------------------------------------------------------------------------------------------------
One row per warning/error code.	
	
	W10	3	3	Rings from .dat file are missing in .sum file.
	W16	2	18	There are some extreme density (< 100 OR > 2000 kg/m3) reads in the .DAT file. These reads will be removed before calculating stats (min/mx/avg/median), but will be kept in the final file.
	W17	2	14	Not enough (<2) valid density reads after extreme values (< 100 OR > 2000 kg/m3) were removed from the the .DAT file. Transition will NOT be calculated.
	W18	2	17	Rings from .sum file are missing in .dat file.
	W19	2	16	Invalid ring (contains abnormally low or high density).
	W20	1	1	Invalid sample (contains a high percentage of invalid rings).
	W4	2	3	No clear shift in density could be found.
	W9	3	9	Several early to late wood transitions were found throughout the ring.
	Col1: warning/error code
	Col2: number of samples
	Col3: number of rings
	Col4: Warning/error description
------------------------------------------------------------------------------------------------------------------
(7) ${temp_f}/logs_and_summaries/samples_with_errors.txt
------------------------------------------------------------------------------------------------------------------
List of samples where whole files (.dat/.sum) need to be redone
==============================================================================================================================
Errors and warnings reporting